---
title: 机器学习笔记（二）：常识性知识 #标题
categories: 机器学习 #分类，可多个；若单个去掉括号
tags: [深度学习, 算法] #标签，可多个；若单个去掉括号
mathjax: true #是否引用公式
kewords: #本文关键词
description: #本文描述，若为空就自动全文前150字)
copyright: true #是否需要版权申明，默认有
reward: true #是否需要打赏，默认有
toc: true #是否需要目录，默认有
password: #是否加密，为空不加密
date: 2018-1-24 21:50:02 #日期
---


# 计算输出特征图大小

Q： 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为多少？

公式：输出尺寸=(输入尺寸-filter尺寸+2*padding）/stride+1

A: 输出为97×97

1层卷积,输出为99×99：（200-5+2）/2+1=99.5

池化,输出为97×97： （99-3+0）/1+1=97

2层卷积,输出为97×97： （97-3+2）/1+1=97

1. 计算尺寸不被整除只在GoogLeNet中遇到过。卷积向下取整，池化向上取整。

2. 研究过网络的话看到stride为1的时候，当kernel为 3 padding为1或者kernel为5 padding为2 一看就是卷积前后尺寸不变。

3. 计算GoogLeNet全过程的尺寸也一样。
      

# SPSS（Statistical Product and Service Solutions）

1. 统计产品与服务解决方案

2. SPSS为IBM公司推出的一系列用于统计学分析运算、数据挖掘、预测分析和决策支持任务的软件产品及相关服务的总称。

3. SPSS是世界上最早采用图形菜单驱动界面的统计软件，它最突出的特点就是操作界面极为友好，输出结果美观漂亮。。

4. SPSS的界面中，主窗口是: 数据编辑窗口。

5. 在spss的基础分析模块中，作用是“以行列表的形式揭示数据之间的关系”的是交叉表。

spss中交叉分析主要用来检验两个变量之间是否存在关系，或者说是否独立，其零假设为两个变量之间没有关系。在实际工作中，经常用交叉表来分析比例是否相等。例如分析不同的性别对不同的报纸的选择有什么不同。

---

# 有关过拟合与逻辑回归

Q: 在Logistic Regression 中,如果同时加入L1和L2范数,会产生什么效果？

A: 可以做特征选择,并在一定程度上防止过拟合.

做特征选择看可以使用L1，L2范数，具体如下：

1. L1范数具有系数解的特性，但是要注意的是，L1没有选到的特征不代表不重要，原因是两个高相关性的特征可能只保留一个。如果需要确定哪个特征重要，再通过交叉验证。

2. 在代价函数后面加上正则项，Ｌ１即是Ｌｏｓｓｏ回归，Ｌ２是岭回归.

3. 但是它为什么能防止过拟合呢？

奥卡姆剃刀原理：能很好的拟合数据且模型简单

模型参数在更新时，正则项可使参数的绝对值趋于０，使得部分参数为０，降低了模型的复杂度（模型的复杂度由参数决定），从而防止了过拟合。提高模型的泛化能力.

4. L1范数是指向量中各个元素绝对值之和，用于特征选择

5. L2范数 是指向量各元素的平方和然后求平方根，用于 防止过拟合，提升模型的泛化能力

---
# 矩阵相乘

Q: 现在需要计算三个稠密矩阵A,B,C的乘积ABC，假设三个矩阵的尺寸分别为m*n,n*p,p*q,且m<n<p<q，以下计算顺序效率最高的是：
A. A(BC)    B.(AB)C     C.(AC)B     D.所有效率都相同
A: B

1. a*b,b*c两矩阵相乘效率为a*c*b
ABC=(AB)C=A(BC).
(AB)C = m*n*p + m*p*q,
A(BC)=n*p*q + m*n*q.
$$m*n*p<m*n*q,m*p*q< n*p*q$$
所以 (AB)C 最小

2. 首先，根据简单的矩阵知识，因为 A*B ， A 的列数必须和 B 的行数相等。因此，排除C ;
然后，再看 A 、 B 选项。在 A 选项中， m*n 的矩阵 A 和 n*p 的矩阵 B 的乘积，得到 m*p 的矩阵 A*B ，而 A*B 的每个元素需要 n 次乘法和 n-1 次加法，忽略加法，共需要 m*n*p 次乘法运算。同样情况分析 A*B 之后再乘以 C 时的情况，共需要 m*p*q次乘法运算。因此， A 选项的(AB)C 需要的乘法次数是 m*n*p+m*p*q 。同理分析， B 选项的 A (BC)需要的乘法次数是 n*p*q+m*n*q 。


# k-NN最近邻方法
Q: 一般，k-NN最近邻方法在(B)的情况下效果较好
A. 样本较多但典型性不好
B. 样本较少但典型性好
C. 样本呈团状分布
D. 样本呈链状分布

A: 样本呈团状颇有迷惑性，这里应该指的是整个样本都是呈团状分布，这样kNN就发挥不出其求近邻的优势了，整体样本应该具有典型性好，样本较少，比较适宜。

常见分类方法（监督学习）：k-NN最近邻方法，支持向量机，决策树

# kmeans

1. Kmeans是聚类方法，典型的无监督学习方法

2. 复习一下K-means算法，主要分为赋值阶段和更新阶段。

算法步骤：

（1）随机选择K个点作为初始的质心

（2）将每个点指配到最近的质心

（3）重新计算簇的质心，直到质心不再发生变化。

K均值容易陷入局部最小值，无法表示类的形状，大小和宽度，是一种硬分类算法，针对它的这些缺点，提出了二分K均值和软K均值

  

# CRF模型HMM和MEMM模型
Q: 下列哪个不属于CRF模型对于HMM和MEMM模型的优势(B)
A. 特征灵活
B. 速度快
C. 可容纳较多上下文信息
D. 全局最优

CRF模型:条件随机场（Conditional Random Field，CRF）
隐马尔可夫模型（Hidden Markov Model，HMM）
最大熵马尔可夫模型（Maximum Entropy Markov Model，MEMM）

1. CRF没有HMM那样严格的独立性假设条件，因而可以容纳任意的上下文信息。特征设计灵活（与ME一样） -与HMM比较

2. 同时，由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔可夫模型标记偏置（Label-bias）的缺点。 ­­——与MEMM比较

3. CRF是在给定需要标记的观察序列的条件下，计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布。—与ME比较

4. 缺点：训练代价大、复杂度高

5.  CRF 的优点：特征灵活，可以容纳较多的上下文信息，能够做到全局最优
    CRF 的缺点：速度慢

# 时间序列模型

时间序列模型中,哪一个模型可以较好地拟合波动性的分析和预测（D）

A. AR模型
B. MA模型
C. ARMA模型
D. GARCH模型

AR模型：自回归模型，是一种线性模型
MA模型：移动平均法模型，其中使用趋势移动平均法建立直线趋势的预测模型
ARMA模型：自回归滑动平均模型，拟合较高阶模型
GARCH模型：广义回归模型，对误差的方差建模，适用于波动性的分析和预测

1. AR模型是一种线性预测，即已知N个数据，可由模型推出第N点前面或后面的数据（设推出P点），所以其本质类似于插值。

2. MA模型(moving average model)滑动平均模型，模型参量法谱分析方法之一。

3. ARMA模型(auto regressive moving average model)自回归滑动平均模型，模型参量法高分辨率谱分析方法之一。这种方法是研究平稳随机过程有理谱的典型方法。它比AR模型法与MA模型法有较精确的谱估计及较优良的谱分辨率性能，但其参数估算比较繁琐。

4. GARCH模型称为广义ARCH模型，是ARCH模型的拓展,GARCH对误差的方差进行了进一步的建模，特别适用于波动性的分析和 预测。GARCH模型是一个专门针对金融数据所量体订做的回归模型，除去和普通回归模型相同的之处，GARCH对误差的方差进行了进一步的建模。特别适用于波动性的分析和预测，这样的分析对投资者的决策能起到非常重要的指导性作用，其意义很多时候超过了对数值本身的分析和预测。

# Naive Bayesian（NB）
Q: 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是:

1. 模型效果相比无重复特征的情况下精确度会降低

2. 当两列特征高度相关时，无法用两列特征相同时所得到的结论来分析问题

A: NB的核心在于它假设向量的所有分量之间是独立的。

1. 在贝叶斯理论系统中，都有一个重要的条件独立性假设：假设所有特征之间相互独立，这样才能将联合概率拆分.

2. 主要原因就是由于存在重复的类别之后，破坏了原本的独立性假设。

Q: 位势函数法的积累势函数K(x)的作用相当于Bayes判决中的:

1.后验概率

2.类概率密度与先验概率的乘积(其实二者含义相同)

## 在贝叶斯决策中
对于先验概率p(y)，分为已知和未知两种情况。

1. p(y)已知，直接使用贝叶斯公式求后验概率即可；

2. p(y)未知，可以使用聂曼-皮尔逊决策(N-P决策)来计算决策面。

而最大最小损失规则主要就是使用解决最小损失规则时先验概率未知或难以计算的问题的。

# 高维数据进行降维:

1. LASSO
2. PCA
3. 聚类分析
4. 小波分析
5. 线性判别法
6. 拉普拉斯特征映射
