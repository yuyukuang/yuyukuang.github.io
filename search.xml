<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2.python处理.csv文件]]></title>
    <url>%2Farchives%2Fb810f7cc.html</url>
    <content type="text"><![CDATA[1.python 读取.csv中指定行列123456789101112131415161718192021222324import csv csvfile=open('last.csv','r') reader=csv.reader(csvfile) i=0 train=[] label=[] for line in reader: if i&lt;1: i+=1 #这里的作用是把第一行去掉 else: train.append(line[5:]) #读取第五列以后的数据 label.append(line[0]) #读取第一列的数据 csvfile.close() #以下为把train,label的内容写进csv文件，验证读取是否正确 csvfile = open('csv_test.csv','w',newline='') writer = csv.writer(csvfile) for line in train: writer.writerow(line) csvfile.close() #csvfile = open('csv_testt.csv', 'w',newline='') # writer = csv.writer(csvfile) # for line in label: # writer.writerow(line) csvfile.close() 2.python使用reader读文件123456789#reader import csv csvfile = file(r'ByRow.csv', 'rb') reader = csv.reader(csvfile) for line in reader: print line csvfile.close() 3.python写文件12345678#write multiple rows csvfile = file(r'newWritten.csv', 'wb') writer = csv.writer(csvfile) res = [] res.append(['a','b','c','d','e']) res.append(['a','b','c','d','e']) writer.writerows(res) csvfile.close() 其中，writerows：用来写多行 writerow：用来写一行 我们用writerow来替换writerows试试看：12345678#write single rows csvfile = file(r'newWritten.csv', 'wb') writer = csv.writer(csvfile) res = [] res.append(['a','b','c','d','e']) res.append(['a','b','c','d','e']) writer.writerow(res) csvfile.close() 运行结果: 也就是将一个list写入到了一行中。 由此，我们也可以发现，每次使用writer，写的都是整个文件。 那么，如果我们只是想修改已经存在的csv文件中的部分内容呢？ 这里要用到的思路是:先读取csv文件，将读取的内容保存下来，例如以list的形式保存，再对list进行修改。 1234567891011121314151617181920212223#modify exist file #first read res = [] csvreadfile = file(r'ByRow.csv', 'rb') reader = csv.reader(csvreadfile) for line in reader: print line res.append(line) csvreadfile.close() #modify first row csvfile = file(r'ByRow.csv', 'wb') writer = csv.writer(csvfile) res[0] = ['A','B','C','D','E'] writer.writerows(res) csvfile.close() #read again csvreadfile = file(r'ByRow.csv', 'rb') reader = csv.reader(csvreadfile) for line in reader: print line csvreadfile.close() 运行结果: 四.实例我现在要将一个有60张图片的打点坐标,每一行代表一张图片的二维坐标,从一个csv文件中提取出来[….&lt;x0, x1,x2,…&gt;, &lt;y0, y1,y2,…&gt;, ……],得到大概就这种形式的数据结构 [&lt;x0, y0&gt;, &lt;x1, y1&gt;, ……] 首先,剔除无用行和列;其次,把数据转成list,在list里面处理数据结构最后,写进去 大概就是这个意思,附上我男票写的代码(因为我不会处理那个list…) 12345678910111213from itertools import islicelist = []with open("test.csv", "r") as fr: for line in islice(fr, 1, None): str = line.strip().split(',') I = range(5, 73) J = range(73, 141) for i, j in zip(I, J): list.append(str[i].strip() + ',' + str[j] + "\n")with open("result.csv", "w") as fw: fw.writelines(list) 然后就完美的处理成想要的数据结构]]></content>
      <categories>
        <category>python图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP-1.用LSA,PLSA,LDA和ida2vec进行主题建模]]></title>
    <url>%2Farchives%2F684e7e95.html</url>
    <content type="text"><![CDATA[用LSA,PLSA,LDA和ida2vec进行主题建模在自然语言理解任务中，我们可以通过一系列的层次来提取含义——从单词、句子、段落，再到文档。在文档层面，理解文本最有效的方式之一就是分析其主题。 在文档集合中学习、识别和提取这些主题的过程被称为主题建模。 在本文中，我们将通过 4 种最流行的技术来探讨主题建模，它们分别是：LSA、pLSA、LDA，以及最新的、基于深度学习的 lda2vec。 概述所有主题模型都基于相同的基本假设： 每个文档包含多个主题；每个主题包含多个单词。 换句话说，主题模型围绕着以下观点构建：实际上，文档的语义由一些我们所忽视的隐变量或「潜」变量管理。 因此，主题建模的目标就是揭示这些潜在变量——也就是主题，正是它们塑造了我们文档和语料库的含义。 LSA潜在语义分析（LSA）是主题建模的基础技术之一。 其核心思想是把我们所拥有的文档-术语矩阵分解成相互独立的文档-主题矩阵和主题-术语矩阵。 第一步是生成文档-术语矩阵。如果在词汇表中给出 m 个文档和 n 个单词，我们可以构造一个 m×n 的矩阵 A，其中每行代表一个文档，每列代表一个单词。在 LSA 的最简单版本中，每一个条目可以简单地是第 j 个单词在第 i 个文档中出现次数的原始计数。然而，在实际操作中，原始计数的效果不是很好，因为它们无法考虑文档中每个词的权重。例如，比起「test」来说，「nuclear」这个单词也许更能指出给定文章的主题。 因此，LSA 模型通常用 tf-idf 得分代替文档-术语矩阵中的原始计数。tf-idf，即词频-逆文本频率指数，为文档 i 中的术语 j 分配了相应的权重，如下所示： 直观地说，术语出现在文档中的频率越高，则其权重越大；同时，术语在语料库中出现的频率越低，其权重越大。 一旦拥有文档-术语矩阵 A，我们就可以开始思考潜在主题。问题在于：A 极有可能非常稀疏、噪声很大，并且在很多维度上非常冗余。因此，为了找出能够捕捉单词和文档关系的少数潜在主题，我们希望能降低矩阵 A 的维度。 这种降维可以使用截断 SVD 来执行。 SVD，即奇异值分解，是线性代数中的一种技术。该技术将任意矩阵 M 分解为三个独立矩阵的乘积：M=USV，其中 S 是矩阵 M 奇异值的对角矩阵。 很大程度上，截断 SVD 的降维方式是：选择奇异值中最大的 t 个数，且只保留矩阵 U 和 V 的前 t 列。在这种情况下，t 是一个超参数，我们可以根据想要查找的主题数量进行选择和调整。 直观来说，截断 SVD 可以看作只保留我们变换空间中最重要的 t 维。 在这种情况下，U∈ℝ^（m⨉t）是我们的文档-主题矩阵，而 V∈ℝ^（n⨉t）则成为我们的术语-主题矩阵。在矩阵 U 和 V 中，每一列对应于我们 t 个主题当中的一个。在 U 中，行表示按主题表达的文档向量；在 V 中，行代表按主题表达的术语向量。 通过这些文档向量和术语向量，现在我们可以轻松应用余弦相似度等度量来评估以下指标： 不同文档的相似度 不同单词的相似度 术语（或「queries」）与文档的相似度（当我们想要检索与查询最相关的段落，即进行信息检索时，这一点将非常有用） 代码实现在 sklearn 中，LSA 的简单实现可能如下所示：12345678910111213141516171819from sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.decomposition import TruncatedSVDfrom sklearn.pipeline import Pipelinedocuments = ["doc1.txt", "doc2.txt", "doc3.txt"] # raw documents to tf-idf matrix: vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)# SVD to reduce dimensionality: svd_model = TruncatedSVD(n_components=100, // num dimensions algorithm='randomized', n_iter=10)# pipeline of tf-idf + SVD, fit to and applied to documents:svd_transformer = Pipeline([('tfidf', vectorizer), ('svd', svd_model)])svd_matrix = svd_transformer.fit_transform(documents)# svd_matrix can later be used to compare documents, compare words, or compare queries with documents LSA 方法快速且高效，但它也有一些主要缺点： 缺乏可解释的嵌入（我们并不知道主题是什么，其成分可能积极或消极，这一点是随机的） 需要大量的文件和词汇来获得准确的结果 表征效率低 PLSApLSA，即概率潜在语义分析，采取概率方法替代 SVD 以解决问题。其核心思想是找到一个潜在主题的概率模型，该模型可以生成我们在文档-术语矩阵中观察到的数据。特别是，我们需要一个模型 P(D,W)，使得对于任何文档 d 和单词 w，P(d,w) 能对应于文档-术语矩阵中的那个条目。 让我们回想主题模型的基本假设：每个文档由多个主题组成，每个主题由多个单词组成。pLSA 为这些假设增加了概率自旋： 给定文档 d，主题 z 以 P(z|d) 的概率出现在该文档中 给定主题 z，单词 w 以 P(w|z) 的概率从主题 z 中提取出来 从形式上看，一个给定的文档和单词同时出现的联合概率是： 直观来说，等式右边告诉我们理解某个文档的可能性有多大；然后，根据该文档主题的分布情况，在该文档中找到某个单词的可能性有多大。 在这种情况下，P(D)、P(Z|D)、和 P(W|Z) 是我们模型的参数。P(D) 可以直接由我们的语料库确定。P(Z|D) 和 P(W|Z) 利用了多项式分布建模，并且可以使用期望最大化算法（EM）进行训练。EM 无需进行算法的完整数学处理，而是一种基于未观测潜变量（此处指主题）的模型找到最可能的参数估值的方法。 有趣的是，P(D,W) 可以利用不同的的 3 个参数等效地参数化： 可以通过将模型看作一个生成过程来理解这种等价性。在第一个参数化过程中，我们从概率为 P(d) 的文档开始，然后用 P(z|d) 生成主题，最后用 P(w|z) 生成单词。而在上述这个参数化过程中，我们从 P(z) 开始，再用 P(d|z) 和 P(w|z) 单独生成文档。 这个新参数化方法非常有趣，因为我们可以发现 pLSA 模型和 LSA 模型之间存在一个直接的平行对应关系： 其中，主题 P(Z) 的概率对应于奇异主题概率的对角矩阵，给定主题 P(D|Z) 的文档概率对应于文档-主题矩阵 U，给定主题 P(W|Z) 的单词概率对应于术语-主题矩阵 V。 那么，这说明了什么？尽管 pLSA 看起来与 LSA 差异很大、且处理问题的方法完全不同，但实际上 pLSA 只是在 LSA 的基础上添加了对主题和词汇的概率处理罢了。pLSA 是一个更加灵活的模型，但仍然存在一些问题，尤其表现为： 因为我们没有参数来给 P(D) 建模，所以不知道如何为新文档分配概率 pLSA 的参数数量随着我们拥有的文档数线性增长，因此容易出现过度拟合问题 我们将不会考虑任何 pLSA 的代码，因为很少会单独使用 pLSA。一般来说，当人们在寻找超出 LSA 基准性能的主题模型时，他们会转而使用 LDA 模型。LDA 是最常见的主题模型，它在 pLSA 的基础上进行了扩展，从而解决这些问题。 LDALDA 即潜在狄利克雷分布，是 pLSA 的贝叶斯版本。它使用狄利克雷先验来处理文档-主题和单词-主题分布，从而有助于更好地泛化。 我不打算深入讲解狄利克雷分布，不过，我们可以对其做一个简短的概述：即，将狄利克雷视为「分布的分布」。本质上，它回答了这样一个问题：「给定某种分布，我看到的实际概率分布可能是什么样子？」 考虑比较主题混合概率分布的相关例子。假设我们正在查看的语料库有着来自 3 个完全不同主题领域的文档。如果我们想对其进行建模，我们想要的分布类型将有着这样的特征：它在其中一个主题上有着极高的权重，而在其他的主题上权重不大。如果我们有 3 个主题，那么我们看到的一些具体概率分布可能会是： 混合 X：90% 主题 A，5% 主题 B，5% 主题 C 混合 Y：5% 主题 A，90% 主题 B，5% 主题 C 混合 Z：5% 主题 A，5% 主题 B，90% 主题 C 如果从这个狄利克雷分布中绘制一个随机概率分布，并对单个主题上的较大权重进行参数化，我们可能会得到一个与混合 X、Y 或 Z 非常相似的分布。我们不太可能会抽样得到这样一个分布：33％的主题 A，33％的主题 B 和 33％的主题 C。 本质上，这就是狄利克雷分布所提供的：一种特定类型的抽样概率分布法。我们可以回顾一下 pLSA 的模型： 在 pLSA 中，我们对文档进行抽样，然后根据该文档抽样主题，再根据该主题抽样一个单词。以下是 LDA 的模型： 根据狄利克雷分布 Dir(α)，我们绘制一个随机样本来表示特定文档的主题分布或主题混合。这个主题分布记为θ。我们可以基于分布从θ选择一个特定的主题 Z。 接下来，从另一个狄利克雷分布 Dir(𝛽)，我们选择一个随机样本来表示主题 Z 的单词分布。这个单词分布记为φ。从φ中，我们选择单词 w。 从形式上看，从文档生成每个单词的过程如下（注意，该算法使用 c 而不是 z 来表示主题）： 通常而言，LDA 比 pLSA 效果更好，因为它可以轻而易举地泛化到新文档中去。在 pLSA 中，文档概率是数据集中的一个固定点。如果没有看到那个文件，我们就没有那个数据点。然而，在 LDA 中，数据集作为训练数据用于文档-主题分布的狄利克雷分布。即使没有看到某个文件，我们可以很容易地从狄利克雷分布中抽样得来，并继续接下来的操作。 代码实现LDA 无疑是最受欢迎（且通常来说是最有效的）主题建模技术。它在 gensim 当中可以方便地使用： 1234567891011121314from gensim.corpora.Dictionary import load_from_text, doc2bowfrom gensim.corpora import MmCorpusfrom gensim.models.ldamodel import LdaModeldocument = "This is some document..."# load id-&gt;word mapping (the dictionary)id2word = load_from_text('wiki_en_wordids.txt')# load corpus iteratormm = MmCorpus('wiki_en_tfidf.mm')# extract 100 LDA topics, updating once every 10,000lda = LdaModel(corpus=mm, id2word=id2word, num_topics=100, update_every=1, chunksize=10000, passes=1)# use LDA model: transform new doc to bag-of-words, then apply ldadoc_bow = doc2bow(document.split())doc_lda = lda[doc_bow]# doc_lda is vector of length num_topics representing weighted presence of each topic in the doc 通过使用 LDA，我们可以从文档语料库中提取人类可解释的主题，其中每个主题都以与之关联度最高的词语作为特征。例如，主题 2 可以用诸如「石油、天然气、钻井、管道、楔石、能量」等术语来表示。此外，在给定一个新文档的条件下，我们可以获得表示其主题混合的向量，例如，5％ 的主题 1，70％ 的主题 2，10％的主题 3 等。通常来说，这些向量对下游应用非常有用。 深度学习中的 LDA：lda2vec那么，这些主题模型会将哪些因素纳入更复杂的自然语言处理问题中呢？ 在文章的开头，我们谈到能够从每个级别的文本（单词、段落、文档）中提取其含义是多么重要。在文档层面，我们现在知道如何将文本表示为主题的混合。在单词级别上，我们通常使用诸如 word2vec 之类的东西来获取其向量表征。lda2vec 是 word2vec 和 LDA 的扩展，它共同学习单词、文档和主题向量。 以下是其工作原理。 lda2vec 专门在 word2vec 的 skip-gram 模型基础上建模，以生成单词向量。skip-gram 和 word2vec 本质上就是一个神经网络，通过利用输入单词预测周围上下文词语的方法来学习词嵌入。 通过使用 lda2vec，我们不直接用单词向量来预测上下文单词，而是使用上下文向量来进行预测。该上下文向量被创建为两个其它向量的总和：单词向量和文档向量。 单词向量由前面讨论过的 skip-gram word2vec 模型生成。而文档向量更有趣，它实际上是下列两个组件的加权组合： 文档权重向量，表示文档中每个主题的「权重」（稍后将转换为百分比） 主题矩阵，表示每个主题及其相应向量嵌入 文档向量和单词向量协同起来，为文档中的每个单词生成「上下文」向量。lda2vec 的强大之处在于，它不仅能学习单词的词嵌入（和上下文向量嵌入），还同时学习主题表征和文档表征。]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>主题建模</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.python程序打包成.exe可执行文件]]></title>
    <url>%2Farchives%2F1616918e.html</url>
    <content type="text"><![CDATA[一.pyinstaller简介pyinstaller将Python脚本打包成可执行程序，使在没有Python环境的机器上运行 最新版是pyinstaller 3.1.1。支持python2.7和python3.3+。可运行在Windows，Mac和Linux操作系统下。但它不是跨编译的，也就是说在Windows下用PyInstaller生成的exe只能运行在Windows下，在Linux下生成的只能运行在Linux下。 二.pyinstaller在windows下的安装使用命令pip install pyinstaller即可在windows下，pyinstaller需要PyWin32的支持。当用pip安装pyinstaller时未找到PyWin32，会自动安装pypiwin32 出现Successfully installed pyinstaller-3.1.1 pypiwin32-219即表示安装成功 三.打包打包的app里并不包含任何源码，但将脚本的.pyc文件打包了。 基本语法：pyinstaller options myscript.py常用的可选参数如下：–onefile 将结果打包成一个可执行文件–onedir 将所有结果打包到一个文件夹中，该文件夹包括一个可执行文件和可执行文件执行时需要的依赖文件（默认）–paths=DIR 设置导入路径–distpath=DIR 设置将打包的结果文件放置的路径–specpath=DIR 设置将spec文件放置的路径–windowed 使用windows子系统执行，不会打开命令行（只对windows有效）–nowindowed 使用控制台子系统执行（默认）（只对windows有效）–icon=&lt;FILE.ICO&gt; 将file.ico添加为可执行文件的资源(只对windows有效） 如pyinstaller –paths=”C:\demo” run.py 四.实例比如上述,我要将c盘demo文件夹下的run.py打包成.exe可执行文件. 首先进入你安装的pyinstall目录下,比如我的是:c:users\Anaconda3\envs\py3\Scripts然后,将你的run.py拷贝到当前目录下最后,打开命令行,1activate source py3 1cd ~/Anaconda3/envs/py3/Scripts 12pyinstaller --paths="C:\Users\Desktop\run" run.py# 这里路径要写你希望读入的路径,我的python文件写好的就放在这里的,虽然我后面也有把这个文件拷贝过去 最终,回到c:users\Anaconda3\envs\py3\Scripts 就会在当前文件下形成build文件夹、dist文件夹和.spec文件。dist里就是run.exe可执行文件。 如果有打包错误，具体看build里的warn***.txt文档，里面详细记载了错误的原因。一般都是库丢失。spec文件告诉PyInstaller如何去处理脚本。它对脚本名以及大多数pyinstaller的可选参数进行加密。PyInstaller就是通过执行spec文件的内容来build the app。]]></content>
      <categories>
        <category>python图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理5-视频-图片切换ffmpeg]]></title>
    <url>%2Farchives%2F2530a991.html</url>
    <content type="text"><![CDATA[视频-图像切换需要将一段视频文件转成gif，偶遇ffmpeg，于是就学习了一下，它真的很强大。 几个概念比特率比特率，英文为 bit rate，描述每秒钟输出多少 KB 的参数，单位是 Kbps，也就是 kbit/s，8Kbit/s = 1KB/s。也就是说800Kbps意思就是每秒视频就要占用100KB磁盘空间。对于音频文件也存在比特率，同理。压缩同一个视频，视频编码率越大，文件体积越大。视频编码率越大，画质越好，马赛克越少。 MP3一般使用的比特率为 8~320kbps。 可变码率可变码率叫做 Variable Bitrate (VBR)，VBR 指的是编码器的输出码率可以根据编码器输入源信号的复杂度自适应调整，目的是为了达到输出质量保持不变。VBR 适用于存储，不太适用流式传输，可以更有效的地利用有限空间。 固定码率固定码率叫做 Constant Bitrate (CBR)，CBR 指的是编码器输出码率固定，CBR 不适合存储，CBR 对于复杂内容可能没有足够码率进行编码，从而导致质量下降，同时会在简单内容部分浪费一些码率。 帧数每秒钟播放的图片数，单位 fps（英文：Frames Per Second），每秒的帧数或者帧率表示视频文件或者图形处理器场景时每秒钟能够更新的次数。 高的帧率可以得到更流畅、更逼真的画面。一般来说30fps就是可以接受的，但是将性能提升至60fps则可以明显提升交互感和逼真感，但是一般来说超过75fps一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为显示器不能以这么快的速度更新，这样超过刷新率的帧率就浪费掉了。 在同一视频，同一码率的情况下，帧数越大，则画质越不好。尤其是运动的画面。因为每张画面会分担每秒有限的文件体积，如果画面越多，那么每张画面所能表现的内容就越有限。 当画面的FPS达到60帧/秒时，已经能满足绝大部分应用需求。一般情况下，如果能够保证游戏画面的平均FPS能够达到30帧/秒，那么画面已经基本流畅；能够达到50帧/秒，就基本可以体会到行云流水的感觉了。一般人很难分辨出60 帧/秒与100帧/秒有什么不同。 分辨率最好理解的概念了，表示画面的大小，单位是像素 px。 和编码率的关系：越高的分辨率，需要越高的编码率，因为图像的细节多了，需要的文件体积也应该增大，否则还不如画面小一些，你会发现同一码率，画面越大，图像的马赛克程度越明显。 采样率每秒钟对音频信号的采样次数，采样频率越高声音还原度越高，声音更加自然。单位是赫兹 Hz。音频文件一般使用的采样率是 44100 Hz ，也就是一秒钟采样 44100 次，之所以使用这个数值是因为经过了反复实验，人们发现这个采样精度最合适，低于这个值就会有较明显的损失，而高于这个值人的耳朵已经很难分辨，而且增大了数字音频所占用的空间。我们所使用的CD的采样标准就是44.1k，目前44.1k还是一个最通行的标准。 安装ffmpegDebian/Ubuntu/Linux Mint 下安装ffmpeg很简单： 1apt-get install ffmpeg windows比较头疼,分享一个我觉得还挺简单的:首先你需要知道 你的电脑是 32 位还是 64 位。 然后访问 http://ffmpeg.zeranoe.com/builds/ ，你可以看到许多灰色的按钮。如果你的电脑是 32 位，点最上面一行左边的按钮 “Download FFmpeg git-xxxxxxx 32-bit Static” ，如果是 64 位，点右边的 “Download FFmpeg git-xxxxxxx 64-bit Static” 。 解压。 双击 ff-prompt.bat ，如果出现了如下的界面，并且最后一行可以进行输入，则表示没有问题。 它是一个绿色软件，你可以直接在这个窗口中执行接下来会讲到的命令。但为了方便，我推荐你进行“手动安装”。 双击解压出来的 bin 目录，可以看到 3 个 .exe 文件，将它们选中，复制到 C:\Windows\system32\ 中，此操作可能需要管理员权限。然后在命令提示符中输入 ffmpeg ，如果出来的不是 “ffmpeg” 不是一个文件或内部命令，则说明安装成功！ ffmpeg用法举例显示文件信息 显示视频信息1ffmpeg -i input.mp4 批量截图将视频拆分多张图片，每一帧图片，保存到 frames 文件夹下，命名 frame001.png 这种。可以加上-r 参数以用来限制每秒的帧数，-r 10 就表示每秒10帧。1ffmpeg -i input.mp4 frames/frame%03d.png 图片合成视频将多张图片合成视频1ffmpeg -i frames/frame%3d.png output.mp4 从视频中提取音频从视频文件中提取音频并保存为 mp31ffmpeg -i input.mp4 -f mp3 output.mp3 如果需要可以在中间加上 -ar 44100 -ac 2 -ab 192 系数，表示采样率 44100 ，通道2立体声，码率192 kb/s. 将声音合成到视频将声音合成到视频中1ffmpeg -i input_music.mp3 -i input_video.mp4 output.mp4 转化格式格式之间转换 大部分的情况下直接运行一下即可1ffmpeg -i input.mp4 output.avi 将 flv 转码 MP41ffmpeg -i input.flv -vcodec copy -acodec copy out.mp4 -vcodec copy 和 -acodec copy 表示所使用的视频和音频编码格式，为原样拷贝。 转换文件格式1ffmpeg -y -i input_video.mp4 -bitexact -vcodec h263 -b 128 -r 15 -s 176x144 -acodec aac -ac 2 -ar 22500 -ab 24 -f 3gp test.3gp 或1ffmpeg -y -i test.wmv -ac 1 -acodec libamr_nb -ar 8000 -ab 12200 -s 176x144 -b 128 -r 15 test.3gp 视频切片操作对视频切片操作 比如需要从视频第1分45秒地方，剪10秒画面，-ss 表示开始位置，-t 表示延长时间1ffmpeg -i input.mp4 -ss 00:01:45 -t 10 output.mp4 加速减速视频加速视频1ffmpeg -i input.mp4 -vf “setpts=0.5*PTS” output.mp4 减速视频1ffmpeg -i input.mp4 -vf “setpts=2.0*PTS” output.mp4 此操作对音频无影响 视频截图视频10秒的地方(-ss 参数)截取一张1920x1080尺寸大小的，格式为jpg的图片 -ss后跟的时间单位为秒 1ffmpeg -i input_video.mp4 -y -f image2 -t 0.001 -ss 10 -s 1920x1080 output.jpg 或者1ffmpeg -i input_video.mp4 -ss 00:00:06.000 -vframes 1 output.png 合成 gif把视频的前30帧转换成一个Gif1ffmpeg -i input_video.mp4 -vframes 30 -y -f gif output.gif 将视频转成 gif 1ffmpeg -ss 00:00:00.000 -i input.mp4 -pix_fmt rgb24 -r 10 -s 320x240 -t 00:00:10.000 output.gif 将输入的文件从(-ss)设定的时间开始以10帧频率，输出到320x240大小的 gif 中，时间长度为-t 设定的参数。通过这样转换出来的 gif 一般都比较大，可以使用 ImageMagick 来优化图片的大小。 1convert -layers Optimize output.gif output_optimized.gif 把frame.[001-100].jpg序列帧和bg.mp3音频文件利用mpeg4编码方式合成分辨率720p的视频文件output.avi： 1ffmpeg -i bg.mp3 -i frame.%3d.jpg -s hd720 -vcodec mpeg4 output.avi 查看ffmpeg支持格式要查看你的ffmpeg支持哪些格式，可以用如下命令： 1ffmpeg -formats | less 设置输出文件编码率 64 kbit/s, To set the video bitrate of the output file to 64 kbit/s:1ffmpeg -i input.avi -b:v 64k -bufsize 64k output.avi 设置输出文件帧率为24 fps，To force the frame rate of the output file to 24 fps:1ffmpeg -i input.avi -r 24 output.avi 强制输入文件以1帧，输出文件24帧 ， To force the frame rate of the input file (valid for raw formats only) to 1 fps and the frame rate of the output file to 24 fps:1ffmpeg -r 1 -i input.mp4 -r 24 output.avi 下面几步分别是，创建frames文件夹，利用 ffmpeg 将视频文件以每秒10帧输出成图像保存到 frames 文件夹中，再利用 ImageMagick 将图片组成 gif。其中 convert 命令来自 ImageMagick。123mkdir framesffmpeg -i input.mp4 -r 10 frames/frame%03d.pngconvert -delay 5 -loop 0 frames/frame*.png output.gif Source: http://superuser.com/a/556031 利用ffmpeg屏幕录制参考：https://trac.ffmpeg.org/wiki/Capture/Desktop 添加水印1ffmpeg -i input.mp4 -i picture.png -filter_complex overlay="(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2" output.mp4 picture.png 为水印图片， overlay 为水印位置 ffmpeg使用语法ffmpeg使用语法：1ffmpeg [global_options] &#123;[input_file_options] -i input_file&#125; ... &#123;[output_file_options] output_file&#125; ... 如果没有输入文件，那么视音频捕捉就会起作用。 作为通用的规则，选项一般用于下一个特定的文件。如果你给 –b 64选项，改选会设置下一个视频速率。对于原始输入文件，格式选项可能是需要的。 缺省情况下，ffmpeg试图尽可能的无损转换，采用与输入同样的音频视频参数来输出。 通用选项12345-L license 显示协议 -h 帮助 -formats 显示可用的格式，编解码的，协议的 -decoders 可用解码器 -encoders 可用编码器 主要选项12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364-i filename 输入文件 -y 覆盖输出文件 -n 不覆盖输出文件，如果输出文件存在则退出 -t duration (input/output) 设置纪录时间 hh:mm:ss[.xxx]格式的记录时间也支持,在 `-i` 之前使用，则对输入文件限制记录时间；如果对输出文件使用，则是限制输出文件的时长。 -ss position 搜索到指定的时间 [-]hh:mm:ss[.xxx]的格式也支持 ，更多[参考](https://ffmpeg.org/ffmpeg-utils.html#time-duration-syntax) -title string 设置标题 -author string 设置作者 -copyright string 设置版权 -comment string 设置评论 -f fmt 强迫采用格式fmt 输出 -c[:stream_specifier] codec (input/output, per-stream) -codec[:stream_specifier] codec (input/output, per-stream) 给输入文件指定解码器，给输出文件指定编码器， codec 为编码器名字，如果 codec 值为 `copy` 则默认为和原视频一致。 -vcodec codec vcodec 是 -codec:v 的一个别称，强制使用codec编解码方式，未设定时使用与输入流相同的编码器。如果用copy表示原始编解码数据必须被拷贝。-target type 设置目标文件类型(vcd,svcd,dvd) 所有的格式选项（比特率，编解码以及缓冲区大小）自动设置，只需要输入如下的就可以了： ffmpeg -i input.avi -target vcd /tmp/vcd.mpg-hq 激活高质量设置 -itsoffset offset 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件。该偏移被加到输入文件的时戳，定义一个正偏移意味着相应的流被延迟了 offset秒。 [-]hh:mm:ss[.xxx]的格式也支持 ### 视频选项 &#123;#video-options&#125;-vframes number (output) 设置视频输出帧数，是`-frames:v`的别称。 -b bitrate 设置比特率，缺省200kb/s -r fps 设置帧率 缺省25 -s size 设置画面的宽高 设置帧大小,分辨率， 格式为wxh 缺省为原视频大小。下面的简写也可以直接使用： ntsc 720x480 snits 640x480 hd720 1280x720 hd1080 1920x1080 更多[参考](https://ffmpeg.org/ffmpeg-utils.html#toc-Video-size)-aspect aspect 设置画面比例 4:3 16:9 或 1.3333 1.7777 -croptop size 设置顶部切除带大小 像素单位 -cropbottom size –cropleft size –cropright size -padtop size 设置顶部补齐的大小 像素单位 -padbottom size –padleft size –padright size –padcolor color 设置补齐条颜色(hex,6个16进制的数，红:绿:兰排列，比如 000000代表黑色)-vn 不做视频记录，输出无视频内容 -bt tolerance 设置视频码率容忍度kbit/s -maxrate bitrate设置最大视频码率容忍度 -minrate bitreate 设置最小视频码率容忍度-bufsize size 设置码率控制缓冲区大小-sameq 使用同样视频质量作为源（VBR）-pass n 选择处理遍数（1或者2）。两遍编码非常有用。第一遍生成统计信息，第二遍生成精确的请求的码率-passlogfile file 选择两遍的纪录文件名为file 高级视频选项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384-g gop_size 设置图像组大小-intra 仅适用帧内编码-qscale q 使用固定的视频量化标度(VBR)-qmin q 最小视频量化标度(VBR)-qmax q 最大视频量化标度(VBR)-qdiff q 量化标度间最大偏差 (VBR)-qblur blur 视频量化标度柔化(VBR)-qcomp compression 视频量化标度压缩(VBR)-rc_init_cplx complexity 一遍编码的初始复杂度-b_qfactor factor 在p和b帧间的qp因子-i_qfactor factor 在p和i帧间的qp因子-b_qoffset offset 在p和b帧间的qp偏差-i_qoffset offset 在p和i帧间的qp偏差-rc_eq equation 设置码率控制方程 默认tex^qComp-rc_override override 特定间隔下的速率控制重载-me method 设置运动估计的方法 可用方法有 zero phods log x1 epzs(缺省) full-dct_algo algo 设置dct的算法 可用的有 0 FF_DCT_AUTO 缺省的DCT 1 FF_DCT_FASTINT 2 FF_DCT_INT 3 FF_DCT_MMX 4 FF_DCT_MLIB 5 FF_DCT_ALTIVEC-idct_algo algo 设置idct算法。可用的有 0 FF_IDCT_AUTO 缺省的IDCT 1 FF_IDCT_INT 2 FF_IDCT_SIMPLE 3 FF_IDCT_SIMPLEMMX 4 FF_IDCT_LIBMPEG2MMX 5 FF_IDCT_PS2 6 FF_IDCT_MLIB 7 FF_IDCT_ARM 8 FF_IDCT_ALTIVEC 9 FF_IDCT_SH4 10 FF_IDCT_SIMPLEARM-er n 设置错误残留为n 1 FF_ER_CAREFULL 缺省 2 FF_ER_COMPLIANT 3 FF_ER_AGGRESSIVE 4 FF_ER_VERY_AGGRESSIVE-ec bit_mask 设置错误掩蔽为bit_mask,该值为如下值的位掩码 1 FF_EC_GUESS_MVS (default=enabled) 2 FF_EC_DEBLOCK (default=enabled)-bf frames 使用frames B 帧，支持mpeg1,mpeg2,mpeg4-mbd mode 宏块决策 0 FF_MB_DECISION_SIMPLE 使用mb_cmp 1 FF_MB_DECISION_BITS 2 FF_MB_DECISION_RD-4mv 使用4个运动矢量 仅用于mpeg4-part 使用数据划分 仅用于mpeg4-bug param 绕过没有被自动监测到编码器的问题-strict strictness 跟标准的严格性-aic 使能高级帧内编码 h263+-umv 使能无限运动矢量 h263+-deinterlace 不采用交织方法-interlace 强迫交织法编码仅对mpeg2和mpeg4有效。当你的输入是交织的并且你想要保持交织以最小图像损失的时候采用该选项。可选的方法是不交织，但是损失更大-psnr 计算压缩帧的psnr-vstats 输出视频编码统计到vstats_hhmmss.log-vhook module 插入视频处理模块 module 包括了模块名和参数，用空格分开### 音频选项 &#123;#audio-options&#125;-aframes number (output) 设置输出文件音频帧数，是`-frames:a` 的别名-ab bitrate 设置音频码率，声音比特率，-ac 设为立体声时要以一半比特率来设置，比如192kbps 的就设置成96，高品质音乐建议160kbps(80) 一上-ar freq 设置音频采样率，一般设置44100-ac channels 设置通道，声道数， 缺省为1, 1为单声道，2为立体声-an 不使用音频纪录-acodec codec 使用codec编解码，是`-codec:a`的别名 音频/视频捕获选项123456789101112131415161718192021222324252627-vd device 设置视频捕获设备。比如/dev/video0-vc channel 设置视频捕获通道 DV1394专用-tvstd standard 设置电视标准 NTSC PAL(SECAM)-dv1394 设置DV1394捕获-av device 设置音频设备 比如/dev/dsp### 高级选项 &#123;#advance-option&#125;-map file:stream 设置输入流映射-debug 打印特定调试信息-benchmark 为基准测试加入时间-hex 倾倒每一个输入包-bitexact 仅使用位精确算法 用于编解码测试-ps size 设置包大小，以bits为单位-re 以本地帧频读数据，主要用于模拟捕获设备-loop 循环输入流。只工作于图像流，用于ffserver测试 附录1：ffmpeg 简略帮助123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104Hyper fast Audio and Video encoderusage: ffmpeg [options] [[infile options] -i infile]... &#123;[outfile options] outfile&#125;...Getting help: -h -- print basic options -h long -- print more options -h full -- print all options (including all format and codec specific options, very long) -h type=name -- print all options for the named decoder/encoder/demuxer/muxer/filter See man ffmpeg for detailed description of the options.Print help / information / capabilities:-L show license-h topic show help-? topic show help-help topic show help--help topic show help-version show version-buildconf show build configuration-formats show available formats-devices show available devices-codecs show available codecs-decoders show available decoders-encoders show available encoders-bsfs show available bit stream filters-protocols show available protocols-filters show available filters-pix_fmts show available pixel formats-layouts show standard channel layouts-sample_fmts show available audio sample formats-colors show available color names-sources device list sources of the input device-sinks device list sinks of the output device-hwaccels show available HW acceleration methodsGlobal options (affect whole program instead of just one file:-loglevel loglevel set logging level-v loglevel set logging level-report generate a report-max_alloc bytes set maximum size of a single allocated block-y overwrite output files-n never overwrite output files-ignore_unknown Ignore unknown stream types-stats print progress report during encoding-max_error_rate ratio of errors (0.0: no errors, 1.0: 100% error maximum error rate-bits_per_raw_sample number set the number of bits per raw sample-vol volume change audio volume (256=normal)Per-file main options:-f fmt force format-c codec codec name-codec codec codec name-pre preset preset name-map_metadata outfile[,metadata]:infile[,metadata] set metadata information of outfile from infile-t duration record or transcode "duration" seconds of audio/video-to time_stop record or transcode stop time-fs limit_size set the limit file size in bytes-ss time_off set the start time offset-sseof time_off set the start time offset relative to EOF-seek_timestamp enable/disable seeking by timestamp with -ss-timestamp time set the recording timestamp ('now' to set the current time)-metadata string=string add metadata-program title=string:st=number... add program with specified streams-target type specify target file type ("vcd", "svcd", "dvd", "dv" or "dv50" with optional prefixes "pal-", "ntsc-" or "film-")-apad audio pad-frames number set the number of frames to output-filter filter_graph set stream filtergraph-filter_script filename read stream filtergraph description from a file-reinit_filter reinit filtergraph on input parameter changes-discard discard-disposition dispositionVideo options:-vframes number set the number of video frames to output-r rate set frame rate (Hz value, fraction or abbreviation)-s size set frame size (WxH or abbreviation)-aspect aspect set aspect ratio (4:3, 16:9 or 1.3333, 1.7777)-bits_per_raw_sample number set the number of bits per raw sample-vn disable video-vcodec codec force video codec ('copy' to copy stream)-timecode hh:mm:ss[:;.]ff set initial TimeCode value.-pass n select the pass number (1 to 3)-vf filter_graph set video filters-ab bitrate audio bitrate (please use -b:a)-b bitrate video bitrate (please use -b:v)-dn disable dataAudio options:-aframes number set the number of audio frames to output-aq quality set audio quality (codec-specific)-ar rate set audio sampling rate (in Hz)-ac channels set number of audio channels-an disable audio-acodec codec force audio codec ('copy' to copy stream)-vol volume change audio volume (256=normal)-af filter_graph set audio filtersSubtitle options:-s size set frame size (WxH or abbreviation)-sn disable subtitle-scodec codec force subtitle codec ('copy' to copy stream)-stag fourcc/tag force subtitle tag/fourcc-fix_sub_duration fix subtitles duration-canvas_size size set canvas size (WxH or abbreviation)-spre preset set the subtitle options to the indicated preset 附录2：常用视频文件格式详解常见的视频格式： AVI格式 它的英文全称为Audio Video Interleaved，即音频视频交错格式。它于1992年被Microsoft公司推出，随Windows3.1一起被人们所认识和熟知。所谓“音频视频交错”，就是可以将视频和音频交织在一起进行同步播放。这种视频格式的优点是图像质量好，可以跨多个平台使用，但是其缺点是体积过于庞大，而且更加糟糕的是压缩标准不统一，因此经常会遇到高版本Windows媒体播放器播放不了采用早期编码编辑的AVI格式视频，而低版本Windows媒体播放器又播放不了采用最新编码编辑的AVI格式视频。其实解决的方法也非常简单，我们将在后面的视频转换、视频修复部分中给出解决的方案。 DV-AVI格式 DV的英文全称是Digital Video Format，是由索尼、松下、JVC等多家厂商联合提出的一种家用数字视频格式。目前非常流行的数码摄像机就是使用这种格式记录视频数据的。它可以通过电脑的IEEE 1394端口传输视频数据到电脑，也可以将电脑中编辑好的的视频数据回录到数码摄像机中。这种视频格式的文件扩展名一般也是.avi，所以我们习惯地叫它为DV-AVI格式。 MPEG格式 它的英文全称为Moving Picture Expert Group，即运动图像专家组格式，家里常看的VCD、SVCD、DVD就是这种格式。MPEG文件格式是运动图像压缩算法的国际标准，它采用了有损压缩方法从而减少运动图像中的冗余信息。MPEG的压缩方法说的更加深入一点就是保留相邻两幅画面绝大多数相同的部分，而把后续图像中和前面图像有冗余的部分去除，从而达到压缩的目的。目前MPEG格式有三个压缩标准，分别是MPEG-1、MPEG-2、和MPEG-4，另外，MPEG-7与MPEG-21仍处在研发阶段。 MPEG-1：制定于1992年，它是针对1.5Mbps以下数据传输率的数字存储媒体运动图像及其伴音编码而设计的国际标准。也就是我们通常所见到的VCD制作格式。这种视频格式的文件扩展名包括.mpg、.mlv、.mpe、.mpeg及VCD光盘中的.dat文件等。 MPEG-2：制定于1994年，设计目标为高级工业标准的图像质量以及更高的传输率。这种格式主要应用在DVD/SVCD的制作（压缩）方面，同时在一些HDTV（高清晰电视广播）和一些高要求视频编辑、处理上面也有相当的应用。这种视频格式的文件扩展名包括.mpg、.mpe、.mpeg、.m2v及DVD光盘上的.vob文件等。 MPEG-4：制定于1998年，MPEG-4是为了播放流式媒体的高质量视频而专门设计的，它可利用很窄的带度，通过帧重建技术，压缩和传输数据，以求使用最少的数据获得最佳的图像质量。MPEG-4最有吸引力的地方在于它能够保存接近于DVD画质的小体积视频文件。这种视频格式的文件扩展名包括.asf、.mov和DivX 、AVI等。 DivX格式 这是由MPEG-4衍生出的另一种视频编码（压缩）标准，也即我们通常所说的DVDrip格式，它采用了MPEG4的压缩算法同时又综合了MPEG-4与MP3各方面的技术，说白了就是使用DivX压缩技术对DVD盘片的视频图像进行高质量压缩，同时用MP3或AC3对音频进行压缩，然后再将视频与音频合成并加上相应的外挂字幕文件而形成的视频格式。其画质直逼DVD并且体积只有DVD的数分之一。 MOV格式 美国Apple公司开发的一种视频格式，默认的播放器是苹果的QuickTimePlayer。具有较高的压缩比率和较完美的视频清晰度等特点，但是其最大的特点还是跨平台性，即不仅能支持MacOS，同样也能支持Windows系列。 ASF格式 它的英文全称为Advanced Streaming format，它是微软为了和现在的Real Player竞争而推出的一种视频格式，用户可以直接使用Windows自带的Windows Media Player对其进行播放。由于它使用了MPEG-4的压缩算法，所以压缩率和图像的质量都很不错。 WMF格式 它的英文全称为Windows Media Video，也是微软推出的一种采用独立编码方式并且可以直接在网上实时观看视频节目的文件压缩格式。WMV格式的主要优点包括：本地或网络回放、可扩充的媒体类型、可伸缩的媒体类型、多语言支持、环境独立性、丰富的流间关系以及扩展性等。 RM格式 Networks公司所制定的音频视频压缩规范称之为Real Media，用户可以使用RealPlayer或RealOne Player对符合RealMedia技术规范的网络音频/视频资源进行实况转播，并且RealMedia还可以根据不同的网络传输速率制定出不同的压缩比率，从而实现在低速率的网络上进行影像数据实时传送和播放。这种格式的另一个特点是用户使用RealPlayer或RealOne Player播放器可以在不下载音频/视频内容的条件下实现在线播放。 RMVB格式 这是一种由RM视频格式升级延伸出的新视频格式，它的先进之处在于RMVB视频格式打破了原先RM格式那种平均压缩采样的方式，在保证平均压缩比的基础上合理利用比特率资源，就是说静止和动作场面少的画面场景采用较低的编码速率，这样可以留出更多的带宽空间，而这些带宽会在出现快速运动的画面场景时被利用。这样在保证了静止画面质量的前提下，大幅地提高了运动图像的画面质量，从而图像质量和文件大小之间就达到了微妙的平衡。 参考https://mrhanlon.com/posts/convert-an-mp4-to-gif-with-ffmpeg/http://superuser.com/questions/436056/how-can-i-get-ffmpeg-to-convert-a-mov-to-a-gifhttp://blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.htmlRelated Posts]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理3-裁剪图片]]></title>
    <url>%2Farchives%2Ffd12ced4.html</url>
    <content type="text"><![CDATA[裁剪图片完整python代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# -*- coding: utf-8 -*-import cv2import osimport reimport numpy as np#这里h,w分别是height和widthh,w = (600,500)sp = [0,0]bd = FalseSCALE_FACTOR=1def click_and_crop(event, x, y, flags, param): global sp if event == cv2.EVENT_MOUSEMOVE: sp = [y,x]#这里感谢我bf写了一个for循环遍历要读的图片,如果你只有一两张的情况下就不用#n1 = 'h'#fn1 = n1 + '1.jpg'#fn2 = n1 + '2.jpg'#im1 = cv2.imread('./' + fn1)#im2 = cv2.imread('./' + fn2)for i in range(1,61): # 这里的h是指,以h开口的图片名,比如h1,h2一直到h60,便于我读 locals()['fn' + str(i)] = 'h' + str(i) + '.jpg' locals()['im' + str(i)] = cv2.imread('./' + locals()['fn' + str(i)])cv2.namedWindow("image")cv2.setMouseCallback("image", click_and_crop)# keep looping until the 'q' key is pressedwhile True:# display the image and wait for a keypress &amp;(sp[0]+h&lt;im.shape[0])&amp;(sp[1]+w&lt;im.shape[1]) cv2.imshow("image", im2) cim2 = im2[sp[0]:sp[0]+h,sp[1]:sp[1]+w] cv2.imshow("ROI", cim2) key = cv2.waitKey(10) &amp; 0xFF if (key == ord("y"))&amp;(sp[0]+h&lt;im2.shape[0])&amp;(sp[1]+w&lt;im2.shape[1]): #依然是按y保存,c终止 cim1 = im1[sp[0]:sp[0]+h,sp[1]:sp[1]+w] #同样的,如果你只有两张图片,那么下面的for循环可以不要,我这里是遍历60张图片 for i in range(3, 61): locals()['cim' + str(i)] = locals()['im' + str(i)][sp[0]:sp[0]+h,sp[1]:sp[1]+w] #cv2.imwrite('./c_' + fn1,cim1) #cv2.imwrite('./c_' + fn2,cim2) for i in range(1, 61): cv2.imwrite('./c_' + locals()['fn' + str(i)], locals()['cim' + str(i)]) #最终是在原图片的名字之前加上c_;比如之前是h1,那么裁剪之后的图片就是c_h1 break print 'done' elif key == ord("c"): break cv2.destroyAllWindows()]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理4-添加边框]]></title>
    <url>%2Farchives%2F391f3507.html</url>
    <content type="text"><![CDATA[添加边框有时候在裁剪的时候发现,图片不够大,但是又不想放大图片导致图片分辨率变低,那就可以加边框 完整python代码如下: 123456789101112131415161718192021222324# -*- coding: utf-8 -*-import cv2import numpy as npimname = 'd1.jpg'im = cv2.imread(imname)h,w,c = im.shapecv2.namedWindow("image")cv2.imshow("image", im)th=1000tw=1200bd = np.ones((th,tw,c),np.uint8)*253sh = (th-h)/2sw = (tw-w)/2bd[sh:sh+h,sw:sw+w,:] = imcv2.namedWindow("bd")cv2.imshow("bd", bd)cv2.waitKey(0)cv2.destroyAllWindows()cv2.imwrite('d.jpg',bd)]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理2-放缩图片]]></title>
    <url>%2Farchives%2Fc3b61494.html</url>
    <content type="text"><![CDATA[放缩图片在处理大量图像时,往往需要size归一化,这里就涉及放缩变化,加边框,裁剪,后面一一叙述;这里opencv发挥很大的作用. 完整python代码如下: 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-import cv2SCALE_FACTOR = 1#调整图像大小，点s键缩小图像，点b键放大图像，点y键确认保存def resize(fname): newname='d_'+fname global SCALE_FACTOR im = cv2.imread(fname, cv2.IMREAD_COLOR) print im.shape# if im == None:# print 'No such image'# else: cv2.imshow('Image',im) k = cv2.waitKey(0) &amp; 0xFF #这里0rd(121)就是代表 char y;0rd(115)是char s;0rd(98)是char b if k ==121: cv2.destroyAllWindows() else: while(k!=121): if k == 115: SCALE_FACTOR -=0.1 tm = cv2.resize(im, (int(im.shape[1] * SCALE_FACTOR),int(im.shape[0] * SCALE_FACTOR))) cv2.imshow('Image',tm) elif k==98: SCALE_FACTOR +=0.1 tm = cv2.resize(im, (int(im.shape[1] * SCALE_FACTOR),int(im.shape[0] * SCALE_FACTOR))) cv2.imshow('Image',tm) k = cv2.waitKey(0) &amp; 0xFF cv2.imwrite(newname, tm) cv2.destroyAllWindows()if __name__ == "__main__": fname = 'h1111.png' resize(fname)]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理1-打点]]></title>
    <url>%2Farchives%2F176dc8b7.html</url>
    <content type="text"><![CDATA[打点验证最终的输出点是否正确首先,读取.txt中的像素点的数据:import numpy as np; 其次,将像素点画到对应的图像中:import matplot.pyplot as plt; 最后,显示图片:from PIL import Image; 完整python代码如下: 12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltfrom PIL import Imagef= open("fit.txt","r")//改成你自己的文件名i=0arr=np.zeros((66,2),dtype=float)//改成你自己文件里面点的个数,维度for lines in f.readlines(): i=i+1 if(i&gt;2 and i&lt;69): line=lines.split("\t") arr[i-3][0]=line[0] arr[i-3][1]=line[1]filename="girl.jpg"//改成自己的图片名img=Image.open(filename)plt.figure()plt.imshow(img)plt.scatter(arr[:,0],arr[:,1], marker='+',color='green')plt.show()]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>图像处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gan（1）：GAN]]></title>
    <url>%2Farchives%2Fa5f2e45a.html</url>
    <content type="text"><![CDATA[GANGAN(Generative Adversarial Nets)简单的说GAN就是以下三点： （1）构建两个网络，一个G生成网络，一个D区分网络。两个网络的网络结构随意就好. （2）训练方式。G网络的loss是log(1-D(G(z))，而D的loss是-(log(D(x)) + log(1-D(G(z))) 注意这里并不是Cross Entropy。 （3）数据输入。G网络的输入是noise。而D的输入则混合G的输出数据及样本数据 深入GAN那么我们来分析一下这样的训练会产生什么情况？ G网络的训练是希望D(G(z))趋近于1，这样G的loss就会最小。 而D网络的训练就是一个2分类，目标是分清楚真实数据和生成数据，也就是希望真实数据的D输出趋近于1，而生成数据的输出即D(G(z))趋近于0。 OK，这就是GAN两个网络相互对抗的本质。 那么，这样相互对抗会产生怎样的效果呢？Ian Goodfellow用一个简单的图来描述： 我们也好好说一下上面这几个图。 第一个图是一开始的情况，黑色的线表示数据x的实际分布，绿色的线表示数据的生成分布，我们希望绿色的线能够趋近于黑色的线，也就是让生成的数据分布与实际分布相同。 然后蓝色的线表示生成的数据x对应于D的分布。 在a图中，D还刚开始训练，本身分类的能力还有限，因此有波动，但是初步区分实际数据和生成数据还是可以的。 到b图，D训练得比较好了，可以很明显的区分出生成数据，大家可以看到，随着绿色的线与黑色的线的偏移，蓝色的线下降了，也就是生成数据的概率下降了。 那么，由于绿色的线的目标是提升概率，因此就会往蓝色线高的方向移动，也就是c图。 那么随着训练的持续，由于G网络的提升，G也反过来影响D的分布。假设固定G网络不动，训练D，那么训练到最优，D^*g(x) = p{data}(x)/(p_{data}(x)+p_{g}(x)) 因此，随着p_g(x)趋近于p_{data}(x),D^*_g(x)会趋近于0.5，也就是到图d,是最终的训练结果。到这里，G网络和D网络就处于平衡状态，无法再进一步更新了。 作者在文章中花了很大的篇幅证明整个网络的训练最终会收敛到 p_g(x)=p_{data}(x)，我们这里就不探讨了. 算法实现还是看看具体的算法及实现。 这里面包含了一些重要的trick及训练方法： （1）G和D是同步训练的，但是两者的训练次数不一样，G训练一次，D训练k次。这主要还是因为初代的GAN训练不稳定。 （2）注意D的训练是同时输入生成的数据和样本数据计算loss，而不是cross entropy分开计算。实际上为什么GAN不用cross entropy是因为，使用cross entropy会使D(G(z))变为0，导致没有梯度，无法更新G，而GAN这里的做法D(G(z))最终是收敛到0.5。 （3）在实际训练中，文章中G网络使用了RELU和sigmoid，而D网络使用了Maxout和dropout。并且文章中作者实际使用-log(D(G(z))来代替log(1-D(G(z))，从而在训练的开始使可以加大梯度信息，但是改变后的loss将使整个GAN不是一个完美的零和博弈。 在这篇开山之作的最后，作者就分析了GAN的优缺点。 GAN可以任意采样，可以使用任意的可微模型（也就是任意神经网络都可以）。 GAN生成的图像更加sharp，也就是work更好，这个是最关键的，意味着它值得推广。 当然了，作者也直接说了GAN不好训练这一bug。 在Future work中，作者也提到了使用GAN的各种可能性，包括conditional GAN，半监督学习等等。也许Ian Goodfellow在发表这篇文章的时候就已经意识到这将开创一个新的领域了。 DCGAN(( Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks)) GAN开始出名恐怕是因为DCGAN这篇文章。该文章做出了让人难以置信的效果如上图所示。这是GAN在图像生成上的第一次非常成功的应用，也从此开始，一大堆和图像生成相关的paper就出来了。 改进那么这篇paper对GAN做了什么改造呢？核心可以说就一点，就是使用卷积神经网络，并且实现有效训练： GAN在开山之作中就提出了，不好训练。那么DCGAN不但训练成功了，还拓展了维度，这就比较厉害了。DCGAN一共做了一下几点改造： （1）去掉了G网络和D网络中的pooling layer。 （2）在G网络和D网络中都使用Batch Normalization （3）去掉全连接的隐藏层 （4）在G网络中除最后一层使用RELU，最后一层使用Tanh （5）在D网络中每一层使用LeakyRELU。 文章中作者也没有说为什么就这么做，只是因为看起来效果好。就是纯粹工程调出来了一个不错的效果。 模型那么具体说一下DCGAN的网络模型： （1）G网络：100 z-&gt;fc layer-&gt;reshape -&gt;deconv+batchNorm+RELU(4) -&gt;tanh 64x64 （2）D网络（版本1）：conv+batchNorm+leakyRELU (4) -&gt;reshape -&gt; fc layer 1-&gt; sigmoid D网络（版本2）：conv+batchNorm+leakyRELU (4) -&gt;reshape -&gt; fc layer 2-&gt; softmax G网络使用4层反卷积，而D网络使用了4层卷积。 基本上G网络和D网络的结构正好是反过来的。 那么D网络最终的输出有两种做法： 一种就是使用sigmoid输出一个0到1之间的单值作为概率， 另一种则使用softmax输出两个值，一个是真的概率，一个是假的概率。 两种方法本质上是一样的。 网上最出名的复现当属 carpedm20/DCGAN-tensorflow，而另一个极简版本是sugyan/tf-dcgan 经过GAN训练后的网络学到了怎样的特征表达首先是用DCGAN+SVM做cifar-10的分类实验，从D网络的每一层卷积中通过4x4 grid的max pooling获取特征并连起来得到28672的向量然后SVM，效果比K-means好。 然后将DCGAN用在SVHN门牌号识别中，同样取得不错的效果。 这说明D网络确实无监督的学到了很多有效特征信息。 然后就是比较有意思的了，看G可以通过改变z向量，生成怎样不同的图片。 不同的z向量可以生成不同的图像，那么，z向量可以线性加减，然后就可以输出新的图像，前面的图就是这种演示。 非常神奇，说明z向量确实对应了一些特别的特征，比如眼镜，性别等等。这也说明了G网络通过无监督学习自动学到了很多特征表达。 总的来说，DCGAN开创了图像生成的先河，让大家看到了一条崭新的做深度学习的路子，如何更好的生成更逼真的图像成为大家争相研究的方向，而这一路到BEGAN，已经可以生成超级逼真的图像了，真是难以置信 CGAN(Conditional Generative Adversarial Nets)GAN中输入是随机的数据，没有太多意义，那么我们很自然的会想到能否用输入改成一个有意义的数据，最简单的就是数字字体生成，能否输入一个数字，然后输出对应的字体。这就是CGAN要做的事。 做法是非常的简单的： 就是在G网络的输入在z的基础上连接一个输入y，然后在D网络的输入在x的基础上也连接一个y： 改变之后，整个GAN的目标变成 训练方式几乎就是不变的，但是从GAN的无监督变成了有监督。 只是大家可以看到，这里和传统的图像分类这样的任务正好反过来了，图像分类是输入图片，然后对图像进行分类，而这里是输入分类，要反过来输出图像。显然后者要比前者难。 基于这样的算法，作者做了两个任务：一个是MNIST的字体生成任务，另一个是图像多标签任务。 这里就谈MNIST字体生成任务，要求输入数字，输入对应字体。那么这里的数字是处理成one hot的形式，也就是如果是5，那么对应one hot就是[0,0,0,0,0,1,0,0,0,0]。然后和100维的z向量串联输入。 然后大家可以发现，这样的训练通过调整z向量，可以改变输出。这样就解决了多种输出问题 可以看到可以生成不同形状的字体，只是生成质量还是有待改进，但是这已经足够验证CGAN的有效性了。 InfoGAN有了CGAN，我们可以有一个单一输入y，然后通过调整z输出不同的图像。但是CGAN是有监督的，我们需要指定y。那么有没有可能实现无监督的CGAN？这个想法本身就比较疯狂，要实现无监督的CGAN，意味着需要让神经网络不但通过学习提取了特征，还需要把特征表达出来。对于MNIST，如何通过无监督学习让神经网络知道你输入y=2时就输出2的字体？或者用一个连续的值来调整字的粗细，方向？感觉确实是一个非常困难的问题，但是InfoGAN就这么神奇的做到了。 怎么做呢？作者引入了信息论的知识，也就是mutual information互信息。作者的思路就是G网络的输入除了z之外同样类似CGAN输入一个c变量，这个变量一开始神经网络并不知道是什么含义，但是没关系，我们希望c与G网络输出的x之间的互信息最大化，也就是让神经网络自己去训练c与输出之间的关系。mutual information在文章中定义如下： 其中的H为c的entropy熵，也就是log(c)*c，Q网络则是反过来基于X输出c。基于I，整个GAN的训练目标变成： 有了这样的理论之后，就具体如何训练的问题了。 相比CGAN，InfoGAN在网络上做了一定改变： （1）D网络的输入只有x，不加c。 （2）Q网络和D网络共享同一个网络，只是到最后一层独立输出。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（八）：面试中常问的问题]]></title>
    <url>%2Farchives%2F94801474.html</url>
    <content type="text"><![CDATA[机器学习方面SVM 支撑平面：和支持向量相交的平面；分割平面：支撑平面中间的平面。（最优分类平面） SVM不是定义损失，而是定义支持向量之间的距离。 正则化参数对支持向量数的影响： 在任一个机器学习模型的训练过程中，被最大化或者最小化的那个函数，叫作“目标函数”（objective function）。 目标函数可以有很多种，比如数据的（（负）对数）似然值，比如margin的大小，比如均方误差。如果目标函数是要最小化的，它就也常常被称为“损失函数”（loss function）或“费用函数”（cost function）。 使用上面这些目标函数时，有时会发生过拟合。此时常常对模型的参数做一定的限制，使得模型偏好更简单的参数，这就叫“正则化”（regularization）。 最常见的正则化方法，就是（软性地）限制参数的大小。设目标函数是要最小化的，所有参数组成向量w。 如果往目标函数上加上（参数向量w的L1范数），这就是L1正则化；如果往目标函数上加上（参数向量w的L2范数的平方的一半），这就是L2正则化。 L1正则化的优点是优化后的参数向量往往比较稀疏；L2正则化的优点是其正则化项处处可导。 现在再看SVM的推导过程。在这个推导过程中，SVM的训练被看作一个有约束的优化问题，其目标函数是，代表了margin的大小的倒数。 因为它是要最小化的，所以也是损失函数。而后面加上的反倒比较像正则化项，只不过它并不典型：一来它不是为了解决过拟合问题，而是为了容错；二来它并不是限制模型参数本身的大小，而是限制容错量的大小。 不过，SVM的训练也可以从另一个角度来理解。我们不再把margin的大小作为目标函数，而是考虑分类错误所带来的代价。 对于“+”类$（y_i =1）$的数据$x_i$，我们希望$w^Tx&gt;0$（同样省略了bias）；对于“-”类$（y_i =-1）$的数据$x_i$，我们希望$w^Tx&lt;0$：总之，我们希望$w^Tx_iy_i&gt;0$。 那么，如果实际上$w^Tx_iy_i$符号为负，或者虽然符号为正但离0不够远，具体来说是$w^Tx_iy_i&lt;1$，我们就认为这个分类错误（或“不够正确”）带来了大小为的损失。 于是目标函数（损失函数）就是，SVM的训练变成了这个目标函数下的无约束优化问题。 在数据线性可分的情况下，会有许多w使得L = 0。 为了选择一个合理的w，也需要加入正则化。加入L2正则化之后，目标函数就变成了。 可以验证，这个目标函数跟题干中的目标函数是等价的。 而正则化项恰巧具有物理意义；最小化正则化项，就是最大化margin。 总结一下，上述的推导过程的思路，是最大化margin（目标函数），顺便容错；而我这里给出的另一个角度，是最小化分类错误造成的损失（目标函数），顺便让margin尽可能大（正则化）。 西瓜书上SVM课后习题 线性判别分析和线性核支持向量机在何种条件下等价。 在线性可分的情况下,LDA求出的wl与线性核支持向量机求出的ws有wl∗ws=0，即垂直，此时两者是等价的。 当初在做这个题的时候也没细想，就想当然的认为在线性可分时两者求出来的w会垂直，现在看来并不一定。首先，如果可以使用软间隔的线性SVM，其实线性可分这个条件是不必要的，如果是硬间隔线性SVM，那么线性可分是必要条件。这个题只说了是线性SVM，就没必要关心数据是不是可分，毕竟LDA是都可以处理的。第二，假如当前样本线性可分，且SVM与LDA求出的结果相互垂直。当SVM的支持向量固定时，再加入新的样本，并不会改变求出的w，但是新加入的样本会改变原类型数据的协方差和均值，从而导致LDA求出的结果发生改变。这个时候两者的w就不垂直了，但是数据依然是可分的。所以我上面说的垂直是有问题的。我认为这个题的答案应该就是，当线性SVM和LDA求出的w互相垂直时，两者是等价的，SVM这个时候也就比LDA多了个偏移b而已。 试述高斯核SVM与RBF神经网络的联系。RBF网络的径向基函数与SVM都可以采用高斯核，也就分别得到了高斯核RBF网络与高斯核SVM. 神经网络是最小化累计误差，将参数作为惩罚项，而SVM相反，主要是最小化参数，将误差作为惩罚项。 在二分类问题中，如果将RBF中隐层数为样本个数，且每个样本中心就是样本参数，得出的RBF网络与核SVM基本等价，非支持向量将得到很小的W。 使用LIBSVM对异或问题训练一个高斯核SVM得到$\alpha$，修改第五章RBF网络的代码，固定$\beta$参数为高斯核SVM的参数，修改每个隐层神经元的中心为各个输入参数，得到结果W，w和$\alpha$各项成正比例。 上述第三条我不懂，有哪位大神看到了请给解释下，谢谢。 试析SVM对噪声敏感的原因。 SVM的目的是求出与支持向量有最大化距离的直线，以每个样本为圆心，该距离为半径做圆，可以近似认为圆内的点与该样本属于相同分类。如果出现了噪声，那么这个噪声所带来的错误分类也将最大化，所以SVM对噪声是很敏感的。 给定训练集，SVM最优决策边界由支持向量决定。当增加噪声时，那么该噪声有极高的可能是含噪声训练集的一个支持向量，这意味着决策边界需要改变。 LR LR的形式：h(x)=g(f(x))；其中x为原始数据；f（x）为线性/非线性回归得到的值，也叫判定边界；g（）为Sigmoid函数，最终h(x)输出范围为（0,1） LR对样本分布敏感。 LR与NB的区别？ LR是loss最优化求出的，NB是统计跳过LOSS最有，直接得到权重 NB比LR多了一个条件独立假设。 Naive Bayes是建立在条件独立假设基础之上的，设特征X含有n个特征属性（X1，X2，…Xn），那么在给定Y的情况下，X1，X2，…Xn是条件独立的。 Logistic Regression的限制则要宽松很多，如果数据满徐条件独立假设，Logistic Regression能够取得非常好的效果；当数据不满度条件独立假设时，Logistic Regression仍然能够通过调整参数让模型最大化的符合数据的分布，从而训练得到在现有数据集下的一个最优模型。 LR是判别模型，NB是生成模型。 Naive Bayes是一个生成模型，在计算P(y|x)之前，先要从训练数据中计算P(x|y)和P(y)的概率，从而利用贝叶斯公式计算P(y|x)。 Logistic Regression是一个判别模型，它通过在训练数据集上最大化判别函数P(y|x)学习得到，不需要知道P(x|y)和P(y)。 当数据集比较小的时候，应该选用Naive Bayes，为了能够取得很好的效果，数据的需求量为O(log n)当数据集比较大的时候，应该选用Logistic Regression，为了能够取得很好的效果，数据的需求量为O( n) Naive Bayes运用了比较严格的条件独立假设，为了计算P(y|x)，我们可以利用统计的方法统计数据集中P(x|y)和P(y)出现的次数，从而求得P(x|y)和P(y)。因而其所需的数据量要小一些，为O(log n). Logistic Regression在计算时，是在整个参数空间进行线性搜索的，需要的数据集就更大，为O( n) 什么是判别模型，什么是生成模型？ 判别模型是判别方法学到的模型，由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。 生成模型是生成方法学到的模型，由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类，就像上面说的那样。注意了哦，这里是先求出P(X,Y)才得到P(Y|X)的，然后这个过程还得先求出P(X)。P(X)就是你的训练数据的概率分布。 机器学习中，LR和SVM有什么区别？ 两者都可以处理非线性问题；LR和SVM最初都是针对二分类问题的。 SVM最大化间隔平面、LR极大似然估计；SVM只能输出类别，不能给出分类概率 两者loss function不同；LR的可解释性更强；SVM自带有约束的正则化 LR为什么用sigmoid函数，这个函数有什么优点和缺点？为什么不用其他函数？（sigmoid是伯努利分布的指数族形式） Logistic Regression 只能用于二分类,而sigmoid对于所有的输入，得到的输出接近0或1 Sigmoid存在的问题：梯度消失、其输出不是关于原点中心对称的（训练数据不关于原点对称时，收敛速度非常慢à输入中心对称，得到的输出中心对称时，收敛速度会非常快）、计算耗时 Tanh激活函数存在的问题：梯 度消失、计算耗时，但是其输出是中心对称的 ReLU：其输出不关于原点对称；反向传播时，输入神经元小于0时，会有梯度消失问题；当x=0时，该点梯度不存在（未定义）； ReLu失活（dead RELU）原因：权重初始化不当、初始学习率设置的非常大 Maxout：根据设置的k值，相应的增大了神经元的参数个数 Xavier权重初始化方法：对每个神经元的输入开根号 SVM原问题和对偶问题关系？ SVM对偶问题的获得方法：将原问题的目标函数L和约束条件构造拉格朗日函数，再对L中原参数和lambda、miu分别求导，并且三种导数都等于0；再将等于0的三个导数带入原目标函数中，即可获得对偶问题的目标函数 关系：原问题的最大值相对于对偶问题的最小值 KKT（Karysh-Kuhn-Tucker）条件有哪些，完整描述？KKT条件是思考如何把约束优化转化为无约束优化à进而求约束条件的极值点 凸优化满足三个条件： 在最小化（最大化）的要求下， 目标函数是一个凸函数（凹函数）， 同时约束条件所形成的可行域集合是一个凸集 为什么凸优化这么重要？局部最优即全局最优定理。 什么是凸函数？什么是凸集？什么是凸锥？ 对于一个集合，如果集合内的任意两点构成的线段仍在集合内，则称集合为凸集。 凸锥 凸函数 决策树过拟合哪些方法，前后剪枝决策树对训练属性有很好的分类能力；但对位置的测试数据未必有好的分类能力，泛化能力弱，即发生过拟合。 防止过拟合的方法：剪枝（把一些相关的属性归为一个大类，减少决策树的分叉）；随机森林 L1正则为什么可以把系数压缩成0，坐标回归的具体实现细节？L1正则化可以实现稀疏（即截断），使训练得到的权重为0； l1正则会产生稀疏解，即不相关的的特征对应的权重为0，就相当于降低了维度。但是l1的求解复杂度要高于l2,并且l1更为流行 正则化就是对loss进行惩罚（加了正则化项之后，使loss不可能为0,lambda越大惩罚越大–&gt;lambda较小时，约束小，可能仍存在过拟合；太大时，使loss值集中于正则化的值上） 正则化使用方法：L1/L2/L1+L2 LR在特征较多时可以进行怎样的优化？–&gt;L1正则有特征选择的作用如果是离线的话，L1正则可以有稀疏解，batch大点应该也有帮助，在线的解决思路有ftrl,rds,robots,还有阿里的mlr。当然还可以用gbdt,fm,ffm做一些特性选择和组合应该也有效果。 机器学习里面的聚类和分类模型有哪些？分类：LR、SVM、KNN、决策树、RandomForest、GBDT 回归：non-Linear regression、SVR（支持向量回归–&gt;可用线性或高斯核（RBF））、随机森林 聚类：Kmeans、层次聚类、GMM（高斯混合模型）、谱聚类]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（六）：19-23]]></title>
    <url>%2Farchives%2F987c2640.html</url>
    <content type="text"><![CDATA[剑19-包含min函数的栈定义栈的数据结构，请在该类型中实现一个能够得到栈最小元素的min函数。1234567891011class Solution: def __init__(self): self.stack = [] def push(self,node):#当前栈压入 self.stack.append(node) def pop(self): #当前栈、辅助栈全部要弹出 self.stack.pop() def top(self):#返回当前栈的栈顶元素 return self.stack[0] def min(self):#返回辅助栈的栈顶元素 return min(self.stack) 剑20-栈的压入弹出序列输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4，5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 思路：举例： 入栈1,2,3,4,5 出栈4,5,3,2,1 首先1入辅助栈，此时栈顶1≠4，继续入栈2 此时栈顶2≠4，继续入栈3# 此时栈顶3≠4，继续入栈4 此时栈顶3≠4，继续入栈4 此时栈顶4＝4，出栈4，弹出序列向后一位，此时为5，,辅助栈里面是1,2,3 此时栈顶3≠5，继续入栈5 *此时栈顶5=5，出栈5,弹出序列向后一位，此时为3，,辅助栈里面是1,2,3 1234567891011121314class Solution: def IsPopOrder(self, pushV,popV): stack = [] for i in pushV: stack.append(i) while(len(stack) and stack[-1] == popV[0]): stack.pop() popV.pop(0) else: continue if len(stack): return False return True 剑21-从上往下打印二叉树从上往下打印出二叉树的每个节点，同层节点从左至右打印。 123456789101112131415class Solution: def PrintFromTopToBottom(self, root): # write code here result = [] if not root: return [] stack = [root] while stack: current = stack.pop(0) result.append(current.val) if current.left: stack.append(current.left) if current.right: stack.append(current.right) return result 剑22-二叉搜索树的后序遍历序列题目描述输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。 1234567891011121314151617# Python 简单解法，找到第一个比根节点大的整数的坐标，左边肯定都比根小，不需要再进一步判断# 继续遍历坐标右边，如果有比根小的数说明不是搜索树 # -*- coding:utf-8 -*-class Solution: def VerifySquenceOfBST(self, sequence): # write code here if not sequence: return False root = sequence[-1] index = 0 while sequence[index] &lt; root: index += 1 for i in sequence[index:]: if i &lt; root: return False return True python:后序遍历 的序列中，最后一个数字是树的根节点 ，数组中前面的数字可以分为两部分：第一部分是左子树节点 的值，都比根节点的值小；第二部分 是右子树 节点的值，都比 根 节点 的值大，后面用递归分别判断前后两部分 是否 符合以上原则12345678910111213141516171819202122232425class Solution: def VerifySquenceOfBST(self, sequence): # write code here if sequence==None or len(sequence)==0: return False length=len(sequence) root=sequence[length-1] # 在二叉搜索 树中 左子树节点小于根节点 for i in range(length): if sequence[i]&gt;root: break # 二叉搜索树中右子树的节点都大于根节点 for j in range(i,length): if sequence[j]&lt;root: return False # 判断左子树是否为二叉树 left=True if i&gt;0: left=self.VerifySquenceOfBST(sequence[0:i]) # 判断 右子树是否为二叉树 right=True if i&lt;length-1: right=self.VerifySquenceOfBST(sequence[i:-1]) return left and right 另外一种解法123456789101112131415161718192021222324252627282930313233class Solution: def VerifySquenceOfBST(self, sequence): # write code here #数组的最后一个元素是根元素 #从右向左找到第一个小于根节点的元素node #把数组分成两部分，node左边表示左子树、node右边表示右子树， #检查node左边子树的点是否小于根（右边不需要在检查），如果是,递归处理左、右子树，否则返回false if not sequence: return False length=len(sequence) if length&lt;3: return True root=length-1 right=length-2 left=-1 for i in range(length-1,-1,-1): if sequence[i]&lt;sequence[root]: left=i break if left&gt;-1: for i in range(0,left+1): if sequence[i]&gt;sequence[root]: return False if left&lt;0: if right-left&lt;2: return True return self.VerifySquenceOfBST(sequence[left+1:right+1]) else: if left&lt;2 or right-left&lt;2: return True return self.VerifySquenceOfBST(sequence[:left+1]) and self.VerifySquenceOfBST(sequence[left+1:right+1]) 剑23-二叉树中和为某一值得路径输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。 123456789101112131415161718192021 class Solution: # 返回二维列表，内部每个列表表示找到的路径 def FindPath(self, root, expectNumber): # write code here if not root: return [] if not root.left and not root.right: if root.val == expectNumber: return [[root.val]] else: return [] lpath, rpath = [], [] if root.left: lpath = self.FindPath(root.left, expectNumber - root.val) if root.right: rpath = self.FindPath(root.right, expectNumber - root.val) res = lpath + rpath for p in res: p.insert(0, root.val) return res]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（五）：14-18]]></title>
    <url>%2Farchives%2Fe26fa12f.html</url>
    <content type="text"><![CDATA[剑14-反转链表输入一个链表，反转链表后，输出链表的所有元素。1234567891011121314151617class ListNode: def_init_(self,x): self.val = x self.next = Noneclass Solution: def ReverseList(self,pHead): #判断指针是否为空 if pHead == None or pHead.next == None: return pHead #反转链表 last = Nonep while pHead != None: tmp = pHead.next pHead.next = last last = pHead pHead = tmp return last 剑15-合并两个排序的链表输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 思路：比较两个链表的首结点，哪个小的的结点则合并到第三个链表尾结点，并向前移动一个结点。 步骤一结果会有一个链表先遍历结束，或者没有第三个链表尾结点指向剩余未遍历结束的链表 返回第三个链表首结点 分析： 123456789101112131415161718192021class ListNode: def __init__(self,x): self.val = x self.next = Noneclass Solution: def Merge(self, pHead1,pHead2): new = ListNode(1) last = new while pHead1 and pHead2: if pHead1.val &lt;= pHead2.val: new.next = pHead1 pHead1 = pHead1.next else: new.next = pHead2 pHead2 = pHead2.next new = new.next if pHead1: new.next = pHead1 else: new.next = pHead2 return last.next 剑16-树的子结构输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构）分析： 123456789101112class Solution: def HasSubtree(self, pRoot1, pRoot2): # write code here if not pRoot1 or not pRoot2: return False return self.is_subtree(pRoot1, pRoot2) or self.HasSubtree(pRoot1.left, pRoot2) or self.HasSubtree(pRoot1.right, pRoot2) def is_subtree(self, A, B): if not B: return True if not A or A.val != B.val: return False return self.is_subtree(A.left,B.left) and self.is_subtree(A.right, B.right) 剑17-二叉树的镜像题目描述操作给定的二叉树，将其变换为源二叉树的镜像。输入描述:二叉树的镜像定义：源二叉树 8 / \ 6 10 / \ / \ 5 7 9 11 镜像二叉树 8 / \ 10 6 / \ / \ 11 9 7 5 12345678910111213# -*- coding:utf-8 -*-# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: # 返回镜像树的根节点 def Mirror(self,root): if root != None: root.left,root.right=root.right,root.left self.Mirror(root.left) self.Mirroe(root.right) 剑18-顺时针打印矩阵输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 12345678910111213141516def printMatrix(self, matrix): if not matrix: return [] if len(matrix)==1: return matrix[0] target = [] while (1): target.extend(matrix[0]) del matrix[0] if len(matrix)==0: break tmp=[] for j in range(1,len(matrix[0])+1): tmp.append([m[-j] for m in matrix]) matrix=tmp return target 我觉得下面这个比较好理解一些： 可以模拟魔方逆时针旋转的方法，一直做取出第一行的操作例如1 2 34 5 67 8 9输出并删除第一行后，再进行一次逆时针旋转，就变成：6 95 84 7继续重复上述操作即可。Python代码如下1234567891011121314151617181920212223 class Solution: # matrix类型为二维列表，需要返回列表 def printMatrix(self, matrix): # write code here result = [] while(matrix): result+=matrix.pop(0) if not matrix or not matrix[0]: break matrix = self.turn(matrix) return result def turn(self,matrix): num_r = len(matrix) num_c = len(matrix[0]) newmat = [] for i in range(num_c): newmat2 = [] for j in range(num_r): newmat2.append(matrix[j][i]) newmat.append(newmat2) newmat.reverse() return newmat]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（七）：GAN]]></title>
    <url>%2Farchives%2Fe84feb7d.html</url>
    <content type="text"><![CDATA[前言生成对抗网络（GAN）一经提出就风光无限，更是被Yann Lecun誉为“十年来机器学习领域最有趣的想法”。 GAN“左右互搏”的理念几乎众所周知，但正如卷积神经网络（CNN）一样，GAN发展至今已经衍生出了诸多变化形态。 今天，文摘菌就来为大家盘点一下GAN大家庭中各具特色的成员们。 他们的名单如下： 1.DCGANs 2.Improved DCGANs 3.Conditional GANs 4.InfoGANs 5.Wasserstein GANs 6.Improved WGANs 7.BEGANs 8.ProGANs 9.CycleGANs 注意，这篇文章不会包含以下内容 • 复杂的技术分析 • 代码（但有代码链接） • 详细的研究清单 （你可以点击以下链接https://github.com/zhangqianhui/AdversarialNetsPapers） 想要了解更多GANs相关内容的也可以留言告诉文摘菌哦～ GANs概论如果你对GANs很熟悉的话，你可以跳过这部分的内容。 GANs最早由Ian Goodfellow提出，由两个网络构成，一个生成器和一个鉴别器。他们在同一时间训练并且在极小化极大算法（minimax）中进行竞争。生成器被训练来欺骗鉴别器以产生逼真的图像，鉴别器则在训练中学会不被生成器愚弄。 GAN 训练原理概览 首先，生成器通过从一个简单分布（例如正态分布）中抽取一个噪音向量Z，并且上行采样（upsample）这个向量来生成图像。在最初的循环中，这些图像看起来非常嘈杂。然后，鉴别器得到真伪图像并学习去识别它们。随后生成器通过反向传播算法（backpropagation）收到鉴别器的反馈，渐渐在生成图像时做得更好。我们最终希望伪图像的分布尽可能地接近真图像。或者，简单来说，我们想要伪图像尽可能看起来像真的一样。 值得一提的是，因为GANs是用极小化极大算法做优化的，所以训练过程可能会很不稳定。不过你可以使用一些“小技巧”来获得更稳健的训练过程。 在下面这个视频中，你可以看到GANs所生成图片的训练演变过程。 代码如果对GANs的基本实现感兴趣，可以参见代码的链接： Tensorflow（https://github.com/ericjang/genadv_tutorial/blob/master/genadv1.ipynb） Torch 和 Python (PyTorch)（https://github.com/devnag/pytorch-generative-adversarial-networks；https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f） Torch 和 Lua（https://github.com/lopezpaz/metal） 虽然这些不是最前沿的内容，但它们对于掌握理念很有帮助。 接下来我将按照粗略的时间顺序描述最近这些年来出现的GANs相关的一些进展和类型。 深度卷积生成式对抗网络（Deep Convolutional GANs, DCGANs）DCGANs是GAN结构的最早的重要发展。就训练和生成更高质量的样本来说，DCGANs更加稳定。 论文链接：https://arxiv.org/abs/1511.06434 DCGAN的作者们专注于提升初代GAN的框架结构。他们发现： 批次（Batch）的正态化在两个网络中都是必须要做的。 完全隐藏的连接层不是一个好的想法。 避免池化，只需卷积 修正线性单元（ReLU）激活函数非常有用。 DCGANs截至目前任然被时常提起，因为它们成为了实践和使用GANs的主要基准之一。 在这篇论文发布后不久，就在Theano, Torch, Tensorflow 和 Chainer 中出现了不同的可使用的实现方法，这些方法可以在你感兴趣的任何数据集上测试。所以，如果你遇到了生成后奇怪的数据集，你完全可以归咎于这些家伙。 DCGANs的使用场景如下：你想要比基础GANs表现更好（这是必须的）。基础GANs适用于简单的数据集，然而DCGANs比这要强得多。 你在寻找一种稳固的基准方法来比较你的新GAN算法。 从现在开始，除非特别说明，我接下来将要描述的所有GANs的类型都被假定为有DCGAN的结构。 提升深度卷积生成式对抗网络（Improved DCGANs）一系列提升先前的DCGAN的技术。例如，这一提升后的基准方法能够生成更好的高分辨率图像。 论文链接：https://arxiv.org/abs/1606.03498 GANs的主要问题之一是收敛性。收敛性不是一定的，而且尽管DCGAN做了结构细化，训练过程仍可能非常不稳定。 在这篇论文里，作者们针对GAN训练过程提出了不同的增强方法。以下是其中一部分： 特征匹配：他们提出了一种新的目标函数，而不是让生成器尽可能地去蒙骗鉴别器。这个目标函数需要生成器生成的数据能够跟真实数据的统计量相匹配。在这种情况下，鉴别器只被用来指定哪些才是值得去匹配的统计量。 历史平均：在更新参数值时，把它们过去的值也纳入考虑。 单侧标签平滑：这一项非常简单：只要把你的鉴别器的目标输出值从[0=假图像，1=真图像]改成[0=假图像，0.9=真图像]。不错，这样就提升了训练效果。 虚拟批次正态化：通过使用从其他批次计算的统计量来避免依赖于同一批次的数据。这样的计算成本很高，所以它仅仅被用在生成器当中。 所有这些技术都使得模型在生成高分辨率图像时能表现得更好，而这正是GANs的弱项之一。 作为对比，请看在128x128图像上原始DCGAN和提升后的DCGAN的表现差异： 这些本来都是狗的图片。正如你看到的，DCGAN表现很糟糕，而用improved DCGAN你至少可以看到一些包含狗的特征的内容。这也说明了GANs的另一局限——生成结构性的内容。 Improved DCGANs的使用场景如下生成更高分辨率的图像 条件生成式对抗网络（Conditional GANs， cGANs)条件式生成式对抗网络使用额外的标签信息用于生成更高质量图片，并且使图片的呈现可控制。 论文链接：https://arxiv.org/abs/1411.1784 CGANs是GAN框架的扩展。我们用条件信息Y来描述数据的某些特征。假设我们要处理面部图像，Y则可以用来描述头发颜色或者性别。然后这些属性被插入生成器和鉴别器。 使用脸部特征信息的条件生成网络如上图所示 条件式生成对抗网络有两个很有意思的地方： 1、随着你不断给模型提供更多信息，GAN学习探索这些信息，然后产生更好的样本。 2、我们用两种方法来控制图片的呈现，在没有CGAN的时候所有图片信息使用Z编码。在CGAN下，我们加入了条件信息Y，于是Z和Y对不同信息进行编码。 例如，我们假设Y对手写数字0-9进行编码。Z对其他变量编码，这些变量可以是数字的风格比如（大小，粗细，旋转角度等。） MNIST(Mixed National Institute of Standards and Technology database,简单机器视觉数据集)样本中Z和Y的区别如上图。Z是行，Y是列；Z对数字的风格编码，Y对数字本身编码。 最近的研究成果在这个领域有很多有趣的文章，我介绍2个： 1、使用生成对抗网络学习在指定位置画画 （论文：https://arxiv.org/abs/1610.02454；代码：https://github.com/reedscot/nips2016）：这篇论文里作者设计了一个本文描述的方法来告诉GAN画什么，同时使用方框和标记告诉GAN绘画主体的位置。如下图示： 堆栈式GAN （原文：https://arxiv.org/abs/1612.03242；代码：https://github.com/hanzhanggit/StackGAN） 这篇文章和上一篇比较类似，这里作者同时使用2个GAN网络（阶段1和阶段2）用于提升图片的质量。第1阶段用来获得包含图片“基本”概念的低分辨率图片。第2阶段用更多的细节和更高的分辨率提炼第1阶段的图片。 这篇文章据我所知是生成高质量图片最好的模型之一，不信请看下图。 条件式生成网络的使用场景如下：1、你有一个带标签的训练集，想提高生成图片的质量 2、你想对图片的某些特征进行精细的控制，比如在某个设定的位置生成特定大小的一只红色小鸟。 最大信息化生成对抗网络（InfoGANs）GANs可以在无监督模式下对噪声向量Z的一部分有意义的图像特征进行编码。比如对某一数字的旋转编码。 论文链接：https://arxiv.org/abs/1606.03657 你是否曾想过GAN里输入噪声Z对哪些信息进行编码？一般来说它对图片的不同类型的特征使用一种非常“嘈杂”的方式编码。例如，取Z向量的一个位置 并且插入一个-1到1之间的值。这是下图所示的MNIST数据集的训练模型。 左上图像是对Z插值取-1的时候，右下是插值为1的时候 上图中，生成的图片看似是从4慢慢变成“Y”（很像是4和9的混合体）。 这就是我之前所说的使用一种“嘈杂”的方式进行编码：Z的一个位置是图像多个特征的一个参数。 这种情况下，这个位置改变了数字自己（某种程度，从4变成9）和他的风格（从粗体变成斜体）。 然而，你无法定义Z的位置的确切含义。 如果使用Z的一些位置来代表唯一且受限的信息，正如CGAN里的条件信息Y呢？ 例如，第一个位置是0-9之间的数值来控制数字，第二个位置来控制数字的旋转，这就是文中作者想要表达的。 有意思的是，与CGANS不同，他们使用无监督的方法实现并不需要标签信息。 他们是这么做的，把Z向量拆分成两部分：C和Z C对数据分布的语义特征进行编码 Z对分布的所有非结构化噪声进行编码 如何用C对这些特征编码呢？ 通过改变损失函数避免C被GAN简单地忽略掉。所以他们使用一种信息论正则化确保C与生成器分布之间的互信息[z1] （mutual information）。 也就是说，如果C变化，生成的图像也会变化。这导致你不能明确的控制什么类型的信息将被引入C中。但是C的每一个位置都有独特的含义。 如下图所示： C的第一位置编码数字的类别，第二位置编码旋转方向。 然而，不使用标签信息的代价是，这些编码仅对非常简单的数据集有效比如MNIST库里的数字。 并且，你还需要手工设定C的每个位置。例如文章中作者需要定义C的第一位置是介于0-9的整数以对应数据集的十类数字。你会认为这样不是百分百的无监督，因为需要手动给模型提供一些细节。 你可能需要用到infoGANs的场景如下： 1、数据集不太复杂 2、你想训练一个CGAN模型但是缺少标签信息 3、你想知道数据集主要有意义的图像特征并且对他们进行控制 生成式对抗网络（Wasserstein GANs）修改损失函数以引入Wasserstein距离，这样以来WassGANs 的损失函数同图片质量建立联系。同时训练的稳定性有所提升而并非依赖于架构。 论文链接：https://arxiv.org/abs/1701.07875 GANs 经常存在收敛问题，所以你并不知道什么时候该停止训练。换句话说损失函数同图像质量无关，这可是个大难题。 因为： 你需要不断的查看样本来确认模型训练是否正确 因为不收敛，你不知道何时该停止训练 也没有数值指示你调参的效果如何 举个例子，看下面DCGAN的两个无信息损失函数完美的生成MNIST样本的迭代图[z2] 仅看上图你知道什么时候该停止训练吗？ 这种可解释性的问题也是Wasserstein GANs要解决的。 怎样解决呢？ 如果真实和伪造样本的分布不重叠（一般都是这样）GANs可以用来最小化JS散度(Jensen-Shannon divergence)直到0。 所以与其最小化JS散度，作者使用Wasserstein距离来描述不同分布中点之间的距离。 思路大概如此，如果你想了解更多，我强烈建议你看这篇文章（https://paper.dropbox.com/doc/Wasserstein-GAN-GvU0p2V9ThzdwY3BbhoP7）或者更深入分析或者阅读本论文。 WassGAN有和图像质量关联的损失函数并且能够收敛。同时他更加稳定而不依赖GAN的结构。比如，就算你去掉批标准化或者使用怪异的结构，它仍能很好的工作。 这就是他的损失函数图，损失越低，图像质量越好。完美！ Wasserstein GANs的应用场景如下： 你需要寻找最先进的且有最高训练稳定性的GAN 你想要一个有信息量且可以解读的损失函数。 加强版WGANs (Improved WGANs , WGAN-GP)这个模型使用的是Wasserstein GANs，并应用了梯度惩罚（gradient penalty）来代替权重剪辑（weight clipping）及其带来的一些不需要的行为。这个方法可以带来更高的聚合度、更高质量的样本和更稳定的训练。 论文：https://arxiv.org/abs/1704.00028 代码：https://github.com/igul222/improved_wgan_training 针对问题：WGANs有时候会生成一些质量不佳的样本，或者是无法在某些集合中生成聚集。这种现象主要是由于为了满足Lipschitz限制而在WGANs中应用权重剪辑（即把所有权重限制在一个由最小值和最大值组成的范围内）所造成的。如果你对这个限制不太了解，那么你只需要记住它是WGANs正常运行的一个必要条件。那么为什么权重剪辑会造成如上问题呢？这是因为它会使WGANs偏向于使用那些过于简单的函数，这意味着当WGANs想要模拟复杂的数据时，简单地估算近似值令其无法得到准确的结果（如下图所示）。另外，权重剪辑也使得梯度爆炸与消失更容易发生。 左图是使用了简单的函数导致无法正确模拟高斯为8的WGANs运行后的结果，而右图则是经过使用了更复杂的函数的WGAN-GP矫正后的图像。 梯度惩罚（Gradient penalty）：所以我们该如何摆脱权重剪辑带来的不良效果呢？ WGAN-GP的作者（GP表示梯度惩罚）提出了使用另一种叫梯度惩罚的办法来加强Lipschitz限制的建议。原则上，梯度惩罚的原理是对某些梯度实行了均值为1的限制。对于那些均值偏离于1的梯度将会实施惩罚（减少权重），这也是为什么它被称为梯度惩罚的原因。 优点：由于在训练中使用了梯度惩罚而不是权重剪辑，WGANs获得了更快的聚合。另外，因为不再必须对超参数进行调整，而且网络架构的使用也不再像之前那么重要，训练在某种程度上变得更加稳定。虽然很难说清楚到底有多少，但这些WGAN-GP确实产生了更高质量的样本。在已验证并测试的结构上，这些样本的质量和作为基线的WGANs产出的结果非常相似。 基于同一个网络架构，WGANs-GP明显在生成高质量样本上更有优势，而GANs则不然。 比如，据作者所知，这是首次GANs能够在残差网络的结构上运行： 为了不超出本篇博文的范畴，还有许多其他有趣的细节我这里就不一一阐述了。如果你对这个训练方式有兴趣想要了解更多（例如，为什么梯度惩罚只应用于“某些”特定梯度，又或者怎样才能把这个模型用于文本数据样本），我会建议你自行阅读一下该论文。 强化版的WGAN的优点如下： l 更快的聚合 l 可以在各种各样的网络架构和数据集中使用 l 不像其他的GANs一样需要太多的超参数调整 边界均衡GANs(Boundary Equilibrium GANs，BEGANs)GANs使用一个自动编码器作为均衡判别器。它们可在一个简单的架构上被训练出来，且合成一个动态的可以使得均衡器和生成器在训练中两者平衡的阶段。 论文：https://arxiv.org/abs/1703.10717 一个有趣的事实：BEGANs 和WGAN-GP几乎是同一天在论文上发表。 理念：让BEGAN区别于其他GANs的原因有两个，一是它们使用了一个自动编码器作为均衡判别器（这一点和EBGANs类似），二是为了适用于这个情境的一个特别的损失函数。这种选择背后的理由是什么呢？强迫我们使用像素重建损失函数来制造模糊生成样本的自动编码器是否也不是传说中那么“邪恶”呢？ 要回答这些问题，我们需要考虑以下两点： 为什么要重建像素损失？作者解释说这么做的原因是，对于那些符合对像素损失的重建分布模式的假设，我们可以依赖它们去匹配样本的分布模式。 而这又引出了下一个问题：如何才可以达到这一目的呢？一个重要的观点是，从自动编码器/均衡判别器形成的像素重建损失（换言之，就是基于某个图像输入，输出最优化的像素重建）并不是经BEGANs最小化后生成的最终损失。可以说，这个重建损失不过是为了计算最终损失的其中一个步骤。而最终损失的计算这是通过衡量基于真实数据的重建损失和基于生成数据的重建损失之间的Wasserstein距离（是的，现在它无处不在）。 这么一看似乎这其中的信息量非常大，但我可以保证，一旦我们看清损失函数是如何作用于生成器和判别器，这一切将会变得再明白不过了。 生成器专注于生成那些能够让判别器良好重建的图像 而判别器则致力于尽可能良好地重建真实图像，同时重建那些误差最大化的生成图像。 差异因数：另一个有趣的成分是所谓的差异因数。通过这个因子你能控制判别器不同程度的表现，决定它能只专注于形成对真实图像的完美重建（注重质量），又或是更侧重在区分真实图像和生成图像（注重多样性）。然后，它们就能更进一步地利用这个差异因数去保持生成器和判别器在训练中的平衡。如同WGANs,这一模型同样应用均衡状态作为调整和图像质量相关的聚合度的方法。然而，和WGANs (与 WGANs-GP)不尽相同的是，它们利用了Wasserstein 距离，而非Lipschitz限制，去测量均衡水平。 结论：BEGANs并不需要任何花里胡哨的网络架构就可以训练得当。如同在论文中所述的，“不批量标准化，不丢弃神经网络元，无反卷积，也没有卷积滤镜的指数化增长”，这些生成样本(128x128)的质量已经相当好了。 然而，在这篇论文中有一个重要的细节值得我们注意：论文中使用的未发表数据集的样本量是目前广为使用的 CelebA数据集的两倍之大。因此，为了得到更具有现实意义的定性比较，我邀请大家去查看那些使用了CelebA的公开模型（https://github.com/carpedm20/BEGAN-tensorflow），并看看那些由此生成的样本。 最后，如果你对BEGANs感兴趣想要了解更多，我建议你阅读一下这篇博文（https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/），里面对BEGANs有更多详细的介绍。 你需要BEGANs的原因一般会和需要使用WGANs-GP的情况差不多。这两个模型的结果往往非常相似（稳定的训练、简单的架构、和图像质量相关的损失函数），而两者的不同主要在于过程中使用的手段。由于评估生成式模型本身就不是一件容易的事，我们很难去说清楚孰优孰劣。但就像Theisetal在他们的论文（https://arxiv.org/abs/1511.01844）中所说的，选择一个评估的方法，不然就依据实际情况来做判定。在这种情况下，WGANs-GP具有更高的初始分数（Inception score）而BEGANs则能生成非常优质的图像，两者都是未来最值得研究和最具有革新意义的模型。 渐进式发展生成对抗网络（Progressive growing of GANs，ProGANs）在训练过程中,逐步嵌入新的高分辨率的层次，来生成相当逼真的图像。更多的进步以及新兴的考核机制也相继涌现。新生成的图片质量高得惊人。 论文：https://arxiv.org/abs/1710.10196 代码：https://github.com/tkarras/progressive_growing_of_gans 生成高分辨率的图像是个大挑战。图片越大，对生成对抗网络来说越可能失败。因为它要求模型学习辨别更细微、复杂的细节。为了使大家更好理解，在这篇文章发表之前，GANs产出图像的合理尺寸大概是256x256。渐进式生成对抗网络（ProGANs）将它提升到了一个全新水准-生成尺寸为1024x1024的图片。我们来看看它是如何实现的： 理念: ProGANs-建立于WFGANs-GP-引入了一种灵活地将新层次逐渐嵌入到训练时间的方式。每一层都利用上采样增强了生成器和判别器里的图像分辨率。 步骤分解如下： 1 首先，利用低像素图片训练生成器和判别器。 2 在一定时间点（开始聚合的时候），提高分辨率。这是通过“迁移阶段”/“平滑技术”非常完美地实现的。 新的层次是借助α控制的一系列细微的线性步骤添加，而不是简单粗暴地加上一层。 我们看看生成器里都发生了什么。最初，当α = 0，无变化。产出主要来自于前一低分辨率层（16x16）的贡献。 当提升α的值，新一层（32x32）开始通过反向传播调整它的权重。最后，当α趋近于1，我们几乎可以跳过32x32这一层的操作。同理适用于判别器，当然是以完全相反的方式：不是使图片更大，而是更小。 3 一旦转化完成，继续训练生成器与判别器。假如得到的图片质量分辨率不达标，请回到步骤2。 不过，等等……对新的高分辨率图像的上采样与串联不是已经在StackGANs（还有新StackGANs++）里实现了么？没错，也不全对。首先，StackGANs是将文字翻译为图像的条件GANs，它引入文字描述作为额外输入值。而ProGANs没有使用任何假定式的信息。更加有趣的是，尽管StackGANs和ProGANs都对更高分辨率的图片串联，StackGANs需要尽量多的根据上采样独立配对的GANs-需单独训练，你想进行上采样3次么？那你要训练3个GANs。另一方面，在ProGANs模型中只有一个单一的GAN被训练。在这一训练中，更多的上采样层被逐步叠加至上采样的图片，上采样3次的尝试只是增加更多的层在训练时间上，而不是抓3个新的GANs逐次训练。总而言之，ProGANs采用一种与StackGANs相似的理念，它完美地完成，而且在没有额外信息的情况下产出更好的结果。 结果。作为渐进训练的结果，ProGANs生成的图片有更高的质量，而针对1024x1024图像的训练时间也缩减了5.4倍。背后的理由是，ProGAN不需要一次性学习所有大、小规模的典型图片。在ProGAN模型里，小规模的图像最先被学习（低分辨率层次聚合），然后模型可以自行聚焦在完善大尺寸图片的结构上（新的高分辨率层次聚合）。 其他的提升。 另外，该论文提出了新的设计决策来更进一步提升模型的性能。概述如下： 小批量标准差：将标准差运用于这些小批量的所有特征属性，允许每个小批量有相似的统计数据。然后，总结为一个新的层的单一值，嵌入至网络尾端。 均衡的学习速率：通过在训练过程中持续地将每个权重除以一个常量，确保所有权重的学习速度一致。 像素标准化：在生成器上，每一个矢量的特征是根据其卷基层标准化的（论文里的精确公式）。这是为了防止生成器和判别器的梯度量级的逐步上涨。 CelebA-HQ（CelebA高级版）。 值得一提的是，作者为了实现高分辨率训练，改进了原始的CelebA，从而得到了CelebA-HQ，简单来说，它们移除原像，应用高斯滤波器来生成一种景深效果，然后探测到人脸图像，得到一个1024x1024尺寸的裁剪图片，在这一流程之后，他们从202k张图片里保留了最优质的30k张图片。 评估最后，我们介绍一种新的评估方式： 背后的理念是：生成图像的本地图形结构应该与训练图像的结构匹配。 那么如何测量本地结构？ 使用Laplacian pyramid算法，你可以得到不同的空间频段，来作为描述符。 最后，我们从生成图像和原始图像中提取描述符，将其规范化，然后使用著名的Wasserstein距离检测它们有多接近。距离越近越好。 你可能会想在以下场景使用ProGANs的使用场景如下： 假如你希望获得最完美的结果。但是考虑到… 你需要花大量时间搭建模型：我们需要在一个单一的NVIDIA Tesla P100 GPU上花20天训练网络 如果你开始怀疑世界的真实性。GANs的下一轮迭代可能会给你一些比现实生活还真实的样本参考。 循环生成对抗网络（Cycle GANs）论文：https://arxiv.org/pdf/1703.10593.pdf ​ 代码：https://github.com/junyanz/CycleGAN 循环GANs是目前最先进的用于图片互译的生成对抗网络。 这些GANs并不需要配对的数据集来学习不同领域之间的转译，这点很棒，因为配对数据集很难获取。然而CycleGANs仍然需要通过两个不同领域的数据X和Y（例如X是普通的马匹，Y是斑马）来训练。为了将转换限制于从一个领域到另一领域的范畴，他们使用所谓的“循环一致性损失”。大意是，如果可以将马匹A转化成斑马A，那么当你将斑马A逆转化，应该能得到马匹A才对。 这种从一个领域到另一领域的变换与另一热门概念“神经风格转换”是有区别的。后者结合了一副图像的“内容”与另一图像的“样式”。循环GANs则是在一个领域转换至另一领域的过程中学习总结非常高层次的特征。因此，循环GANs更笼统，并且适用于多种映射关系，例如将一个速写转化为真实物品。 总结一下，生成对抗网络在近期取得了两大显著进步： WGANS-GP和BEGANs 尽管理论研究方向不同，但它们提供了相似的优点。其次，我们有ProGANs（基于WGANS-GP），它打开了一条通往生成高清图像的清晰路径。同时，循环GANs让我们看到了GANs从数据集提取有用信息的潜力以及这些信息如何转入至另一非关联的数据分布。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（四）：7-13]]></title>
    <url>%2Farchives%2F2bae0a51.html</url>
    <content type="text"><![CDATA[Fibonacci数列剑7-斐波那契数列大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。n&lt;=39123456789101112131415class Solution: def Fibonacci(self,n): if n == 0: return 0 if n == 1: return 1 if n == 2: return 1 if n &gt;= 3: s = []*n s.append(1) s.append(1) for i in range(2,n): s.append(s[i-1]+s[i-2]) return s[n-1] 剑8-跳台阶一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 分析： 1.假设当有n个台阶时假设有f(n)种走法。2.青蛙最后一步要么跨1个台阶要么跨2个台阶。3.当最后一步跨1个台阶时即之前有n-1个台阶，根据1的假设即n-1个台阶有f(n-1)种走法。 当最后一步跨2个台阶时即之前有n-2个台阶，根据1的假设即n-2个台阶有f(n-2 )种走法。5.显然n个台阶的走法等于前两种情况的走法之和即f(n)=f(n-1)+f(n-2)。6.找出递推公式后要找公式出口，即当n为1、2时的情况，显然n=1时f(1)等于1，f(2)等于2 | 1, (n=1)f(n) = |2, (n=2)| f(n-1)+f(n-2) ,(n&gt;2,n为整数) 12345678910111213141516class Solution: def jumpFloor(self, number): if number &lt;=0: return 0 elif number &lt;= 2: return number else: a = 1 b = 2 #a,b=1,2 for i in range(2,number): temp = a+b a = b b = temp #a,b = b,a+b return b 其中a,b=a,a+b是指：123t=aa=bb=b+t 也就是，此时a加的是未改变之前的a。举个例子：12345678910111213a，b=0,1 #复合赋值 实际上就是a=0,b=1while b&lt;10print(b)a,b=b,a+b #实际上还是复合赋值a=b,b=a+b;那输出结果将是a=0 b=1 1a=1 b=1 1a=1 b=2 2a=2 b=3 3a=3 b=5 5a=5 b=8 8a=8 b=13 #大于了10不做输出 剑9-变跳台阶一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 分析：因为n级台阶，第一步有n种跳法：跳1级、跳2级、到跳n级跳1级，剩下n-1级，则剩下跳法是f(n-1)跳2级，剩下n-2级，则剩下跳法是f(n-2)所以f(n)=f(n-1)+f(n-2)+…+f(1)因为f(n-1)=f(n-2)+f(n-3)+…+f(1)所以f(n)=2*f(n-1) 12345678class Solution: def jumpFloor2(self, number): if number &lt;= 0: return -1 elif number == 1: return 1 else: return 2*self.jumpFloor2(number-1) 剑10-矩形覆盖我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 分析： 逆向分析应为可以横着放或竖着放，多以f(n)可以是2(n-1)的矩形加一个竖着放的21的矩形或2*(n-2)的矩形加2横着放的，即f(n)=f(n-1)+f(n-2)当到了最后，f(1)=1,f(2)=2 1234567891011class Solution: def rectCover(self, number): if number &lt; 0: return -1 elif number &lt;= 2: return number else: a,b = 1,2 for i in range(2,number)： a,b = b,a+b return b 剑11-二进制中1的个数输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 //超级简单容易理解 //&amp;(与)// 把这个数逐次 右移 然后和1 与,//就得到最低位的情况,其他位都为0,//如果最低位是0和1与 之后依旧 是0，如果是1，与之后还是1。//对于32位的整数 这样移动32次 就记录了这个数二进制中1的个数了 123456class Solution: def NumberOf1(self,n): count = 0 for i in range(32): count += (n &gt;&gt; i)&amp;1 return count 剑12-数值整数次方给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 123456789101112class Solution: def Power(self,base,exponent): if base == 0: return 0 elif base == 1: return 1 elif exponent == 0: return 1 elif exponent == 1: return base else: return pow(base,exponent) 剑13-调整数组顺序使奇数位于偶数前面输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 1.要想保证原有次序，则只能顺次移动或相邻交换。 2.i从左向右遍历，找到第一个偶数。 3.j从i+1开始向后找，直到找到第一个奇数。 4.将[i,…,j-1]的元素整体后移一位，最后将找到的奇数放入i位置，然后i++。 5.終止條件：j向後遍歷查找失敗。12345678910class Solution: def reOrderArray(self,array): odd = [] even = [] for i in array: if i%2 == 1: odd.append(i) else: even.append(i) return odd+even]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法（一）]]></title>
    <url>%2Farchives%2Fb04cb3d.html</url>
    <content type="text"><![CDATA[第一题 从1到500的500个数，第一次删除奇数位，第二次删除剩下来的奇数位，以此类推，最后剩下的唯一一位数是__ 分析思路：比如：1,2，删除奇数位，那剩下的是2，1,2,3，删除奇数位，剩下的是2，1,2,3,4,剩下的是4,1,2,3,4,5,6,7,剩下的是4,1,2,3,4,5,6,7,8和1,2,3,4,5,6,7,8,9,10,11,12,13,14,15剩下的是8，总结规律：当1~n，$2^i&lt;n&lt;2^(i+1)$时候，这样删除剩下的是$2^i$。$2^8&lt;500&lt;2^9$，所以剩下的就是$2^8=256$。 边缘算子 常用边缘检测有哪些算子，有什么特性？ Roberts，Sobel，Prewitt，Laplacian，Canny (1)Robert 优点：一种利用局部差分算子寻找边缘的算子，定位比较精确，但由于不包括平滑，所以对于噪声比较敏感。 缺点：对噪声敏感,无法抑制噪声影响。 (2)Sobel 优点：一阶微分算子，加权平均滤波，对低噪声图像有较好检测效果。 缺点：抗噪性差。 (3)Prewitt 优点：一阶微分算子，平均滤波，对低噪声图像有较好检测效果。 缺点：抗噪性差。 (4)Laplacian算子 优点：各向同性，二阶微分，精确定位边缘位置所在。 缺点：无法感知边缘强度。只适用于无噪声图象。存在噪声情况下，使用Laplacian算子检测边缘之前需要先进行低通滤波。 (5)Canny算子 是一个具有滤波，增强，检测的多阶段的优化算子。先利用高斯平滑滤波器来平滑图像以除去噪声，采用一阶偏导的有限差分来计算梯度幅值和方向，然后再进行非极大值抑制。 内存分配 C，C++程序编译的内存分配情况有哪几种，并简要解释。 C，C++程序编译的内存分配情况共有以下五种： (1)栈区（ stack ）:由编译器自动分配释放 ，存放为运行函数而分配的局部变量、函数参数、返回数据、返回地址等。其操作方式类似于数据结构中的栈。 (2)堆区（ heap ）:一般由程序员分配释放， 若程序员不释放，程序结束时可能由 OS 回收。分配方式类似于链表。 (3)全局区（静态区）（ static ）:存放全局变量、静态数据、常量。程序结束后有系统释放 (4)文字常量区: 常量字符串就是放在这里的。 程序结束后由系统释放。 (5)程序代码区:存放函数体（类成员函数和全局函数）的二进制代码。 cnn和fcn 简述CNN和FCN的区别 卷积层是CNN区别于其它类型神经网络的本质特点 不过CNN通常也不仅仅只包含卷积层，其也会包含全连接层，全连接层的坏处就在于其会破坏图像的空间结构，因此人们便开始用卷积层来“替代”全连接层，通常采用1 × 1的卷积核，这种不包含全连接层的CNN称为全卷积网络（FCN）。 FCN最初是用于图像分割任务，之后开始在计算机视觉领域的各种问题上得到应用，事实上，Faster R-CNN中用来生成候选窗口的CNN就是一个FCN。 编程题5（编程题）给出了一个n*n的矩形，编程求从左上角到右下角的路径数（n &gt; =2），并返回走的方法，限制只能向右或向下移动，不能回退。向右走此步骤标记为1， 向下走此步骤标记为2。12Int Solve(int b , std::vector&lt;std::vector&lt;int&gt;&gt;&amp; method) &#123;&#125; 算法分析：这是一个动态规划问题。因为限制只能向右或向下移动，所以当走到某一步时只有两种可能：一是从该处的上面走过来的；二是从该处的左边走过来的。假设我们到达某一处（i,j）, Path[i][j],可以得到Path[i][j] = Path[i - 1][j] + Path[i][j - 1].上述方程的边界条件出现在最左列（P [i] [j-1]不存在），最上一行（P [i-1] [j]不存在）。这些条件可以通过初始化（预处理）来处理 - 对于所有有效的i，j，初始化P [0] [j] = 1，P [i] [0] = 1。注意初始值是1而不是0。 不理解上面给的b和method，这里自己写了个solution：123456789class Solution &#123; int uniquePaths(int m, int n) &#123; vector&lt;vector&lt;int&gt; &gt; path(m, vector&lt;int&gt; (n, 1)); for (int i = 1; i &lt; m; i++) for (int j = 1; j &lt; n; j++) path[i][j] = path[i - 1][j] + path[i][j - 1]; return path[m - 1][n - 1]; &#125;&#125;; 6.（编程题）编程求解a＊x + b * sin x = 0。12Std::vector&lt;double&gt; Solve(double a, double b)&#123;&#125; 依然不知都写的啥，用matlab求解：123syms a b xsolve(a＊x + b * sin x == 0) &gt;&gt;ans.x 7、 （探索题）你会用什么样的方法提取遥感图像中的道路呢（包括主街道、田埂、小路）。示例如下：白色明显道路是大路，深绿色田埂也属于需要提取的区域。 （1） 对含中心线的城区主街道，采取基于模板匹配的半自动道路提取方法，可以实时准确的提取城区主干道路的中心线。以中心线上一点为中心建立对应模板窗，在沿道路前进方向寻找与之匹配的目标窗，将该目标窗中心作为下一个道路种子点，并以此生成新的模板窗，玄幻迭代即可得到一系列中心线上种子点，最后将其连成中心线。 （2） 对于田埂小路，采用基于像素匹配和基于比值直方图匹配的半自动提取算法，提取道路信息，当道路与周围环境对比度降低（周围大量的绿田），仍能保证较好结果。 8、 （随便聊聊题） 聊聊你认为深度学习中最有用的三个trick和三个创造性的idea，并说一下你的理解，为什么有用，为什么有创造性。 一．有用的三个trick （1）loss function: 用于衡量最优的策略。一般由一个损失项和一个正则化项组成。常见的损失函数有：0-1损失函数和绝对值损失函数，log对数损失函数，平方损失函数，指数损失函数 ，Hinge损失函数。 （2）kernel: 核函数是machine learning中最核心的部分的东西, 它有效的描述了点和点之间的关系，或者说是距离，当然这里的距离严格的说应该是广义的距离。当然核函数一般与曼哈顿距离，欧氏距离等以及空间（希尔伯特空间等）关联。 （3）activation function：激活函数不是真的要去激活什么。在神经网络中，激活函数的作用是能够给神经网络加入一些非线性因素，使得神经网络可以更好地解决较为复杂的问题。常用的三类激活函数有： A．Sigmoid函数的输出映射在(0,1)(0,1)之间，单调连续，输出范围有限，优化稳定，可以用作输出层。 B．tanh函数比Sigmoid函数收敛速度更快 C．ReLU比起Sigmoid和tanh能够快速收敛；Sigmoid和tanh涉及了很多很expensive的操作（比如指数），ReLU可以更加简单的实现；有效缓解了梯度消失的问题；在没有无监督预训练的时候也能有较好的表现；提供了神经网络的稀疏表达能力。 二．三个创造性的idea （1）GAN: 生成对抗神经网络。GAN已经被引入到了各种以往深度神经网络的任务中,例如从分割图像恢复原图像，给黑白图片上色，还可以做图像超分辨率,动态场景生成，图像去模糊等等。 （2）开源框架tensorflow: 不仅实现深度学习的可视化，实现了将深度学习算法移植到智能设备或手机应用中去。 （3）人脸识别，目标定位等一系列深度学习技术的成熟使人工智能走向工业智能。小米扫地机器人，物流运载机等等都可以算是深度学习的创造性成果。]]></content>
      <categories>
        <category>算法工程师面试</category>
      </categories>
      <tags>
        <tag>算法面试</tag>
        <tag>深度学习面试</tag>
        <tag>机器学习面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（五）：正则化]]></title>
    <url>%2Farchives%2F91ed9b4a.html</url>
    <content type="text"><![CDATA[前言正则化常和防止过拟合联系在一起，什么是过拟合，为什么会引起过拟合，怎么解决？过拟合产生的原因：模型过于复杂，参数太多什么是过拟合：模型训练时误差小，测试时误差大；也就是模型复杂到可以拟合我们所有的训练样本，但是在实际预测新样本的时候却一塌糊涂 简而言之，就是擅长背诵知识，不善于灵活应用；应试能力好，实际应用能力差。 通常过拟合由以下三种原因产生： 假设过于复杂； 数据存在很多噪音； 数据规模太小。 过拟合的解决方法通常有： early stopping； 数据集扩增； 正则化； Dropout。L0与L1-正则项（LASSO regularizer）在机器学习里，最简单的学习算法可能是所谓的线性回归模型 我们考虑这样一种普遍的情况，即：预测目标背后的真是规律，可能只和某几个维度的特征有关；而其它维度的特征，要不然作用非常小，要不然纯粹是噪声。在这种情况下，除了这几个维度的特征对应的参数之外，其它维度的参数应该为零。若不然，则当其它维度的特征存在噪音时，模型的行为会发生预期之外的变化，导致过拟合。 于是，我们得到了避免过拟合的第一个思路：使尽可能多的参数为零。为此，最直观地我们可以引入$L_0$-范数。令： 这意味着，我们希望绝大多数w⃗ 的分量为零。 通过引入 L0−正则项，我们实际上引入了一种「惩罚」机制，即：若要增加模型复杂度以加强模型的表达能力降低损失函数，则每次使得一个参数非零，则引入 ℓ0的惩罚系数。也就是说，如果使得一个参数非零得到的收益（损失函数上的收益）不足 ℓ0；那么增加这样的复杂度是得不偿失的。 通过引入L0−正则项，我们可以使模型稀疏化且易于解释，并且在某种意义上实现了「特征选择」。这看起来很美好，但是 L0−正则项也有绕不过去坎： 不连续 非凸 不可求导 因此，L0正则项虽好，但是求解这样的最优化问题，难以在多项式时间内找到有效解（NP-Hard 问题）。于是，我们转而考虑 L0-范数最紧的凸放松（tightest convex relaxation）：L1-范数。令： L2正则项（Ridge regularizer）让我们回过头，考虑多项式模型，它的一般形式为： 我们注意到，当多项式模型过拟合时，函数曲线倾向于靠近噪声点。 这意味着，函数曲线会在噪声点之间来回扭曲跳跃。 这也就是说，在某些局部，函数曲线的切线斜率会非常高（函数导数的绝对值非常大）。 对于多项式模型来说，函数导数的绝对值，实际上就是多项式系数的一个线性加和。 这也就是说，过拟合的多项式模型，它的参数的绝对值会非常大（至少某几个参数分量的绝对值非常大）。 因此，如果我们有办法使得这些参数的值，比较稠密均匀地集中在0附近，就能有效地避免过拟合。 于是我们引入L2−正则项，令 L1−正则项与L2−正则项的区别现在，我们考虑这样一个问题：为什么使用L1−正则项，会倾向于使得参数稀疏化；而使用L2−正则项，会倾向于使得参数稠密地接近于0？ 这里引用一张来自周志华老师的著作，《机器学习》（西瓜书）里的插图，尝试解释这个问题。 为了简便起见，我们只考虑模型有两个参数w1和w2的情形。 在图中，我们有三组等值线，位于同一条等值线上的w1与w2映射到相同的平方损失项、L1−范数和L2−范数。并且，对于三组等值线来说，当(w1,w2)(w1,w2)沿着等值线法线方向，向外扩张，则对应的值增大；反之，若沿着法线向内收缩，则对应的值减小。 因此，对于目标函数Obj(F)来说，实际上是要在正则项的等值线与损失函数的等值线中寻找一个交点，使得二者的和最小。 对于L1−正则项来说，因为L1−正则项是一组菱形，这些交点容易落在坐标轴上。因此，另一个参数的值在这个交点上就是0，从而实现了稀疏化。 对于 L2−正则项来说，因为 L2−正则项的等值线是一组圆形。所以，这些交点可能落在整个平面的任意位置。所以它不能实现「稀疏化」。但是，另一方面，由于 (w1,w2)(w1,w2) 落在圆上，所以它们的值会比较接近。这就是为什么 L2−正则项可以使得参数在零附近稠密而平滑。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（三）：1-6]]></title>
    <url>%2Farchives%2F2853aed2.html</url>
    <content type="text"><![CDATA[二维数组中的查找在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 //思路//1：从前往后插入，这样移动·的次数多不建议//2：从后往前插 123456789101112131415161718class Solution:#array 2D-array def Find(self, target, array): # search in row for i in range(len(array)): # search in column for j in range(len(array[i])): # find target if target == array[i][j]: return 'true' return 'false'while True: try: S=Solution() target, array=input() print(S.Find(target,array)) except: break 以下这个是另外一种写法，也能够成功运行，但是这两种普遍蛮力1234567891011121314151617 def Find(self, target, array): for i in range(len(array)): for j in range(len(array[i])): if target == array[i][j]: return 'true' return 'false'flag = Truewhile flag: try: S=Solution() target = 1 array = [[1,2],[3,4]] print(S.Find(target,array)) flag = False except: break 算法思想： 由于数组从左到右，从上到下都是递增，可以从右上角或者左下角开始查找，这里从右上角开始查找 定义数组array，行i，列j，目标target。 若array[i][j]==target,那恭喜你找到目标； 若array[i][j]&gt;target,那向左去找目标–j； 否则，array[i][j]小于target,那向下寻找目标++i； 1234567891011121314class Solution: def Find(self, target, array): rows = len(array)-1 cols = len(array[i])-1 i = rows j = 0 while j &lt;= cols and i &gt;= 0 if target &lt; array[i][j]: i -= 1 else if target &gt; array[i][j]: j += 1 else return True return False 替换空格请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy 以下仍然是从前向后1234567891011121314151617181920212223242526272829# -*- coding:utf-8 -*-class Solution: # s 源字符串 def replaceSpace(self, s): return s.replace(' ', '%20')算法思想：1. 定义字符串下标i（i=0开始），定义空格bankNum,遍历字符串并计算空格个数；2. 总字符串=原始字符串下标+1+2*bankNum；3. 末尾字符串下标=totalNum-1，也就是我们说的放置位置；4. 总体来说：从后向前遍历字符串，如果遇到空格，就加%20；没有空格，就将原字符串的最后一个字符赋给新字符串```python# -*- coding:utf-8 -*-class Solution: # s 源字符串 def replaceSpace(self, s): # write code here str = [] num = s.count(' ') for char in s: if char == ' ' and num &gt; 0: char = '%20' num -= 1 str.append(char) newstr = ''.join(str) return newstr添加笔记 打印链表输入一个链表，从尾到头打印链表每个节点的值。 12345678class Solution: def printListFromTailToHead(self,listNode): l=[] head = listNode while head: l.insert(0,head.val) head=head.next return 1 二分查找1234567891011121314151617181920def search2(a,m): low=0 high=len(a)-1 while(low&lt;=high): mid=(low+high)/2 midval=a[mid] if midval&lt;m: low=mid+1 else if midval&gt;m: high=mid-1 else return mid return -1 if __name__=="__main__" a=[1,2,3,4,5,6,7,8,9] m=5 result=search2(a,m) print result 下面这个程序就会陷入无限循环while中123456789101112131415161718192021#include&lt;studio.h&gt;int bsearch(int a[],int n,int v)&#123; int left, middle, right; left=0, right=n-1; while(left&lt;=right) &#123; middle=left+(right-left)/2; if(a[middle]&gt;v) &#123; right=middle &#125; else if(a[middle]&lt;v) &#123; left=middle &#125; else return middle; &#125; return -1;&#125; 以下是正确写法123456789101112131415161718public static int binarySearch(int[] a,int n,int x)&#123; if(n&gt;0 &amp;&amp; x&gt;=a[0]) &#123; int left=0,right=n-1; while(left&lt;right) &#123; int middle=left+(right-left)/2; if(x&lt;a[middle]) right=middle-1; else left=middle; &#125; if(x==a[left]) return left; &#125; return -1;&#125; 重建二叉树输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。1234567891011121314151617# -*- coding:utf-8 -*-# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: # 返回构造的TreeNode根节点 def reConstructBinaryTree(self, pre, tin): # write code here if len(pre) == 0: return None root = TreeNode(pre[0]) pos = tin.index(pre[0]) root.left = self.reConstructBinaryTree( pre[1:1+pos], tin[:pos]) root.right = self.reConstructBinaryTree( pre[pos+1:], tin[pos+1:]) return root 用两个栈实现队列用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型123456789101112class Solution: def __init__(self): self.stack1=[] self.stack2=[] def push(self,none): self.stack1.append(node) def pop(self): if self.stack2==[]: while self.stack1: self.stack2.append(self.stack1.pop()) return self.stack2.pop() return self.stack2.pop() 旋转数组中的最小数字把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。123456789101112class Solution: def minNumberInRotateArray(self, rotateArray): # write code here pre = -7e20 for num in rotateArray: if num &lt; pre : return num pre = num if len(rotateArray) == 0: return 0 return rotateArray[0]]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法（三）]]></title>
    <url>%2Farchives%2F760c84b7.html</url>
    <content type="text"><![CDATA[简答题 小王在用svm做一个垃圾邮件分类器，如果一个邮件为垃圾邮件，则y=1，否则y=0。（1）小王应该一区那些特征？（10分）（2）在小王的训练集中，有99%都是非垃圾邮件，1%是垃圾邮件，如果最后训练的模型为对所有的邮件，都判定为非垃圾邮件，请问在训练集合中，准确率为多少？召回率为多少？（10分） (3)如果在应用场景中，希望能尽可能的召回垃圾邮件，怎么办？（10分） 算法与程序设计 给定一个长度为N的整数数组（元素有正有负），求所有元素之和最大的一个子数组，分析算法时间复杂度。（10） 百度每天接受用户的搜索查询，总是不停有搜索query进入日志，把query看作一个字符串，搜索日志就是一个字符串的数据流。这个字符串流永不停止。如何在这个不断增加的字符串流序列中，随机选择1个字符串？如果随机选择1000个字符串呢？（15） 在一个无限大平面上，有两组平行线，互相间垂直，每组平行线的间隔都为t，将一根长度为1（1小于t）的针任意掷在这个平面上，求此针与所有平行线都不想交的概率，采用蒙特卡洛方法，模拟计算这个概率值。（15）]]></content>
      <categories>
        <category>算法工程师面试</category>
      </categories>
      <tags>
        <tag>算法面试</tag>
        <tag>深度学习面试</tag>
        <tag>机器学习面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法（二）]]></title>
    <url>%2Farchives%2F3b1227e5.html</url>
    <content type="text"><![CDATA[#1. 基础算法题有序的数组，其中一个数出现一次，其中的数出现两次，找到这个出现一次的数？答：很自然想到hashmap或者异或的做法，时间复杂度O（N）。回答的时候觉得有坑，因为有序的条件没用，心想肯定跟二分有关系，果然面试官要求降低复杂度。没思考出来二分的策略，后来在面试官的提醒下明白了，二分的时候跟数组的位置联系起来，既数组肯定是基数个，二分的时候如果mid不成立的话，要找的值一定落在跟左右两边相等元素的那一侧，时间复杂度O（logN） #2.介绍项目聊天式文本挖掘，主要介绍了针对短文本的特征所做的特征工程 2.1.讲下LR模型答：在线性回归的基础上加了sigmoid函数，所有变成了分类模型，输出可以表示概率。采用似然估计构造目标函数，目标是优化最大似然估计，公式H(x)=-(ylogf(x)+(1-y)log(1-f(x)),一般优化方法采用的是梯度下降法。 2.2.LR模型为什么采用似然估计损失函数答：因为最小二乘法是假设残差服从正太分布的，而LR在sigmoid 作用后就不会服从正态分布了，所以采用的是最大似然估计。 后思考：1.最小二乘法反映的是线性空间上的线性投影的最短距离，在非线性空间上表现不如MLE。（MLE可以看作一种特殊情况下的Bayesian 估计，具体来说，就是在prior 是 diffuse （无知的）情况下，让posterior 分布取得极大值的系数值） 2.如果采用均方差最损失函数的时候，梯度下降求偏导时会有一项导数项，这样会导致梯度在一定阶段会收敛的特别慢，而对数损失函数log正好能和sigmoid的exp抵消掉，会加快收敛速度。 2.3.说下基本主题的LDA模型答：生成式模型， 思想：文档一定概率上从属于某些个主题，主题一定概率上会选中某些相关的词，这样就构造了文档到主题到词的联系，同时可以解决同义词问题，因为同义词可能属于不同主题。算法流程回答的模糊，感觉面试官不太满意。 2.4.说下项目用到的doc2vec怎么产生的？答：介绍了下word2vec的思想，然后讲传统上通常词向量简单的加权求和来表征一篇文档，而doc2vec训练方式是在word2vec的基础上，加入了段落ID，进行了一层训练，这样好处是保留了词的上下文信息。（ps：解释的不清楚，自己不太满意） 2.5.说下论文中频繁序列挖掘prefixspan 算法？答：（ps：因为这个算法不做序列挖掘基本不知道，可能只了解apriori算法）对比apriori算法的过程和缺点，讲解该算法的优势，只需要扫描一次序列数据集，目标是挖掘出满足最小支持度的频繁序列，长度为1的前缀开始挖掘序列模式，搜索对应的投影数据库的频繁序列，然后递归的挖掘长度为2的前缀所对应的频繁序列。以此类推，一直递归到对应的投影数据库为空或者对应投影数据库中各项的支持度计数小于阈值为止。整个过程就是前缀不断的增长，产生1，2…N 频繁序列，对应的投影数据库不断缩小直至为空。 优点：PrefixSpan算法由于不用产生候选序列，且投影数据库缩小的很快，内存消耗比较稳定，作频繁序列模式挖掘的时候效果很高。 3.了解深度学习吗？能否讲下CNN的特点？答：神经网络模型前向传递，反向调节的特点（BP网络）,隐含层我觉得是一个特征做变换的过程，整个过程给人的感觉就是向前是特征拓展阶段，向后是参数调优阶段。 回到CNN，特点是局部感受和权值共享，通过卷积核扫描原始数据能够学习到不同的局部的特征，接着通过池化进一步提取特征，这些做的能够让参数数目有量级的减少，同时权值共享是同一层隐含层共享权值，这样也是减少了隐含层的参数，很多卷积核学习的到特征最后传递到下一层网络，到最后一层采用分类器分类（扯不下去了，开始瞎扯）。 深度学习解决了以往神经网络深度网络很多问题，梯度消失爆炸问题，几个方面： 一是激活函数不光是只用sigmoid函数，还有 ReLU函数 二是在参数并不是初始化的时候并不是随机选择的，而是在前面有自编码器做了特征特征器，这样避免了梯度下降法求解陷入局部最优解； 三，深度学习一些手段，权值共享，卷积核，pooling等都能抑制梯度消失问题； 四，二次代价函数换成交叉熵损失函数或者选用softmax+对数似然代价函数的组合。4.说说RBM编码器答：）一种特征探测器，每一层学习的特征向上传递，然后反过来微调。好吧，只能回答这么多了。 补充：RBM包括隐层，可见层和偏置层。可见层和隐含层可以双向传播。标准的RBM，隐含层和可见层都是二进制表示，既激活函数的激活值服从二项分布。每一层的节点没有链接，如果假设所有的节点都只能取0或者1，同时全概率分布p(v,h)满足伯努利分布。 几个参数：一可视层和隐含层的权重矩阵 二是可是节点的偏移量 三是隐层的偏移量。这几个参数决定将N维的样本编码M维的样本。 用途：1.降维，类似稀疏自动编码器2.用RBM训练得到的权重举证和偏移量作为BP神经网路的初始值，避免陷入局部极小值3.可以估计联合分布P(v,h)，进而求出p（h|v）。生成式模型4.直接计算p（h|v）进行分类。判别式模型]]></content>
      <categories>
        <category>算法工程师面试</category>
      </categories>
      <tags>
        <tag>算法面试</tag>
        <tag>深度学习面试</tag>
        <tag>机器学习面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[别人的算法题]]></title>
    <url>%2Farchives%2F9c49b8cc.html</url>
    <content type="text"><![CDATA[#1. 基础算法题有序的数组，其中一个数出现一次，其中的数出现两次，找到这个出现一次的数？答：很自然想到hashmap或者异或的做法，时间复杂度O（N）。回答的时候觉得有坑，因为有序的条件没用，心想肯定跟二分有关系，果然面试官要求降低复杂度。没思考出来二分的策略，后来在面试官的提醒下明白了，二分的时候跟数组的位置联系起来，既数组肯定是基数个，二分的时候如果mid不成立的话，要找的值一定落在跟左右两边相等元素的那一侧，时间复杂度O（logN） #2.介绍项目聊天式文本挖掘，主要介绍了针对短文本的特征所做的特征工程 2.1.讲下LR模型答：在线性回归的基础上加了sigmoid函数，所有变成了分类模型，输出可以表示概率。采用似然估计构造目标函数，目标是优化最大似然估计，公式H(x)=-(ylogf(x)+(1-y)log(1-f(x)),一般优化方法采用的是梯度下降法。 2.2.LR模型为什么采用似然估计损失函数答：因为最小二乘法是假设残差服从正太分布的，而LR在sigmoid 作用后就不会服从正态分布了，所以采用的是最大似然估计。 后思考：1.最小二乘法反映的是线性空间上的线性投影的最短距离，在非线性空间上表现不如MLE。（MLE可以看作一种特殊情况下的Bayesian 估计，具体来说，就是在prior 是 diffuse （无知的）情况下，让posterior 分布取得极大值的系数值） 2.如果采用均方差最损失函数的时候，梯度下降求偏导时会有一项导数项，这样会导致梯度在一定阶段会收敛的特别慢，而对数损失函数log正好能和sigmoid的exp抵消掉，会加快收敛速度。 2.3.说下基本主题的LDA模型答：生成式模型， 思想：文档一定概率上从属于某些个主题，主题一定概率上会选中某些相关的词，这样就构造了文档到主题到词的联系，同时可以解决同义词问题，因为同义词可能属于不同主题。算法流程回答的模糊，感觉面试官不太满意。 2.4.说下项目用到的doc2vec怎么产生的？答：介绍了下word2vec的思想，然后讲传统上通常词向量简单的加权求和来表征一篇文档，而doc2vec训练方式是在word2vec的基础上，加入了段落ID，进行了一层训练，这样好处是保留了词的上下文信息。（ps：解释的不清楚，自己不太满意） 2.5.说下论文中频繁序列挖掘prefixspan 算法？答：（ps：因为这个算法不做序列挖掘基本不知道，可能只了解apriori算法）对比apriori算法的过程和缺点，讲解该算法的优势，只需要扫描一次序列数据集，目标是挖掘出满足最小支持度的频繁序列，长度为1的前缀开始挖掘序列模式，搜索对应的投影数据库的频繁序列，然后递归的挖掘长度为2的前缀所对应的频繁序列。以此类推，一直递归到对应的投影数据库为空或者对应投影数据库中各项的支持度计数小于阈值为止。整个过程就是前缀不断的增长，产生1，2…N 频繁序列，对应的投影数据库不断缩小直至为空。 优点：PrefixSpan算法由于不用产生候选序列，且投影数据库缩小的很快，内存消耗比较稳定，作频繁序列模式挖掘的时候效果很高。 3.了解深度学习吗？能否讲下CNN的特点？答：神经网络模型前向传递，反向调节的特点（BP网络）,隐含层我觉得是一个特征做变换的过程，整个过程给人的感觉就是向前是特征拓展阶段，向后是参数调优阶段。 回到CNN，特点是局部感受和权值共享，通过卷积核扫描原始数据能够学习到不同的局部的特征，接着通过池化进一步提取特征，这些做的能够让参数数目有量级的减少，同时权值共享是同一层隐含层共享权值，这样也是减少了隐含层的参数，很多卷积核学习的到特征最后传递到下一层网络，到最后一层采用分类器分类（扯不下去了，开始瞎扯）。 深度学习解决了以往神经网络深度网络很多问题，梯度消失爆炸问题，几个方面： 一是激活函数不光是只用sigmoid函数，还有 ReLU函数 二是在参数并不是初始化的时候并不是随机选择的，而是在前面有自编码器做了特征特征器，这样避免了梯度下降法求解陷入局部最优解； 三，深度学习一些手段，权值共享，卷积核，pooling等都能抑制梯度消失问题； 四，二次代价函数换成交叉熵损失函数或者选用softmax+对数似然代价函数的组合。4.说说RBM编码器答：）一种特征探测器，每一层学习的特征向上传递，然后反过来微调。好吧，只能回答这么多了。 补充：RBM包括隐层，可见层和偏置层。可见层和隐含层可以双向传播。标准的RBM，隐含层和可见层都是二进制表示，既激活函数的激活值服从二项分布。每一层的节点没有链接，如果假设所有的节点都只能取0或者1，同时全概率分布p(v,h)满足伯努利分布。 几个参数：一可视层和隐含层的权重矩阵 二是可是节点的偏移量 三是隐层的偏移量。这几个参数决定将N维的样本编码M维的样本。 用途：1.降维，类似稀疏自动编码器2.用RBM训练得到的权重举证和偏移量作为BP神经网路的初始值，避免陷入局部极小值3.可以估计联合分布P(v,h)，进而求出p（h|v）。生成式模型4.直接计算p（h|v）进行分类。判别式模型]]></content>
      <categories>
        <category>算法工程师面试</category>
      </categories>
      <tags>
        <tag>算法面试</tag>
        <tag>深度学习面试</tag>
        <tag>机器学习面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（六）：SVM]]></title>
    <url>%2Farchives%2F46254cea.html</url>
    <content type="text"><![CDATA[适用于初学SVM 了解SVM支持向量机，因其英文名为support vector machine，故一般简称SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。 1. 分类标准的起源：Logistic回归理解SVM，咱们必须先弄清楚一个概念：线性分类器。 给定一些数据点，它们分别属于两个不同的类，现在要找到一个线性分类器把这些数据分成两类。如果用x表示数据点，用y表示类别（y可以取1或者-1，分别代表两个不同的类），一个线性分类器的学习目标便是要在n维的数据空间中找到一个超平面（hyperplane），这个超平面的方程可以表示为（ wT中的T代表转置）$$w^Tx+ b = 0$$可能有读者对类别取1或-1有疑问，事实上，这个1或-1的分类标准起源于logistic回归。$$h_\theta (x) = g(\theta^Tx) = \frac{1}{1+e^-\theta^Tx} $$ 其中x是n维特征向量，函数g就是logistic函数。 $$g(z) = \frac{1}{1+e^-z}$$的图像是： 可以看到，上图将无穷映射到了(0,1)。 假设函数就是特征属于y=1的概率。$$P(y=1|x; \theta) = h_\theta(x)$$$$P(y=0|x; \theta) = 1-h_\theta(x)$$ 从而，当我们要判别一个新来的特征属于哪个类时，只需求即可，若大于0.5就是y=1的类，反之属于y=0类。 此外，$h_\theta(x)$只和$\theta^Tx$有关，$\theta^Tx&gt;0$，那么$h_\theta(x)&gt;0.5$，而g(z)只是用来映射，真实的类别决定权还是在于$\theta^Tx$。再者，当$\theta^Tx&gt;&gt;0$时，$h_\theta(x)=1$，反之$h_\theta(x)=0$。如果我们只从$\theta^Tx$出发，希望模型达到的目标就是让训练数据中y=1的特征t$\theta^Tx&gt;&gt;0$，而是y=0的特征。Logistic回归就是要学习得到$\theta$，使得正例的特征远大于0，负例的特征远小于0，而且要在全部训练实例上达到这个目标。 接下来，尝试把logistic回归做个变形。首先，将使用的结果标签y = 0和y = 1替换为y = -1,y = 1，然后将$\theta^Tx=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n(x_0=1)$中的$\theta_0$替换为b，最后将后面的$\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$替换为$\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$（即$w^Tx$）。如此，则有了$\theta^Tx=w^Tx+ b$。也就是说除了y由y=0变为y=-1外，线性分类函数跟logistic回归的形式化表示$h_\theta (x) = g(\theta^Tx) =g(w^Tx+b)$没区别。 进一步，可以将假设函数中的g(z)做一个简化，将其简单映射到y=-1和y=1上。映射关系如下： 2. 线性分类的一个例子下面举个简单的例子。如下图所示，现在有一个二维平面，平面上有两种不同的数据，分别用圈和叉表示。由于这些数据是线性可分的，所以可以用一条直线将这两类数据分开，这条直线就相当于一个超平面，超平面一边的数据点所对应的y全是-1 ，另一边所对应的y全是1。 这个超平面可以用分类函数表示，当f(x) 等于0的时候，x便是位于超平面上的点，而f(x)大于0的点对应 y=1 的数据点，f(x)小于0的点对应y=-1的点，如下图所示： 注：有的资料上定义特征到结果的输出函数，与这里定义的$w^Tx+ b$实质是一样的。为什么？因为无论是哪个，不影响最终优化结果。下文你将看到，当我们转化到优化 的时候，为了求解方便，会把yf(x)令为1，即yf(x)是y(w^x + b)，还是y(w^x - b)，对我们要优化的式子max1/||w||已无影响。（有一朋友飞狗来自Mare_Desiderii，看了上面的定义之后，问道：请教一下SVM functional margin 为=y(wTx+b)=yf(x)中的Y是只取1和-1 吗？y的唯一作用就是确保functional margin的非负性？真是这样的么？当然不是，详情请见本文评论下第43楼） 换言之，在进行分类的时候，遇到一个新的数据点x，将x代入f(x) 中，如果f(x)小于0则将x的类别赋为-1，如果f(x)大于0则将x的类别赋为1。 接下来的问题是，如何确定这个超平面呢？从直观上而言，这个超平面应该是最适合分开两类数据的直线。而判定“最适合”的标准就是这条直线离直线两边的数据的间隔最大。所以，得寻找有着最大间隔的超平面。 3. 函数间隔function margin和集合间隔geometrical margin在超平面wx+b=0确定的情况下，|wx+b|能够表示点x到距离超平面的远近，而通过观察wx+b的符号与类标记y的符号是否一致可判断分类是否正确，所以，可以用(y(w*x+b))的正负性来判定或表示分类的正确性。于此，我们便引出了函数间隔（functional margin）的概念。 定义函数间隔（用表示）为：而超平面(w，b)关于T中所有样本点(xi，yi)的函数间隔最小值（其中，x是特征，y是结果标签，i表示第i个样本），便为超平面(w, b)关于训练数据集T的函数间隔： 但这样定义的函数间隔有问题，即如果成比例的改变w和b（如将它们改成2w和2b），则函数间隔的值f(x)却变成了原来的2倍（虽然此时超平面没有改变），所以只有函数间隔还远远不够。 事实上，我们可以对法向量w加些约束条件，从而引出真正定义点到超平面的距离–几何间隔（geometrical margin）的概念。 假定对于一个点 x ，令其垂直投影到超平面上的对应点为 x0 ，w 是垂直于超平面的一个向量，为样本x到超平面的距离，如下图所示 根据平面几何知识，有 其中||w||为w的二阶范数（范数是一个类似于模的表示长度的概念），是单位向量（一个向量除以它的模称之为单位向量）。 又由于 x0 是超平面上的点，满足 f(x0)=0 ，代入超平面的方程$w^Tx+ b = 0$，可得$w^Tx_0+ b = 0$，即$w^Tx_0= -b$。 随即让此式的两边同时乘以$w^T$，再根据$w^Tx_0= -b$和$w^Tw= ||w||^2$，即可算出： 为了得到r的绝对值，令r乘上对应的类别 y，即可得出几何间隔（用表示）的定义： 从上述函数间隔和几何间隔的定义可以看出：几何间隔就是函数间隔除以||w||，而且函数间隔y(wx+b) = yf(x)实际上就是|f(x)|，只是人为定义的一个间隔度量，而几何间隔|f(x)|/||w||才是直观上的点到超平面的距离。 4. 最大间隔分类器Maximum Margin Classifier的定义对一个数据点进行分类，当超平面离数据点的“间隔”越大，分类的确信度（confidence）也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化这个“间隔”值。这个间隔就是下图中的Gap的一半。 通过由前面的分析可知：函数间隔不适合用来最大化间隔值，因为在超平面固定以后，可以等比例地缩放w的长度和b的值，这样可以使得$f(x)=w^Tx+ b$的值任意大，亦即函数间隔可以在超平面保持不变的情况下被取得任意大。但几何间隔因为除上了||w||，使得在缩放w和b的时候几何间隔的值是不会改变的，它只随着超平面的变动而变动，因此，这是更加合适的一个间隔。换言之，这里要找的最大间隔分类超平面中的“间隔”指的是几何间隔。 于是最大间隔分类器（maximum margin classifier）的目标函数可以定义为：$$max\hat{\gamma}$$ 同时需满足一些条件，根据间隔的定义，有 其中，s.t.，即subject to的意思，它导出的是约束条件。 回顾下几何间隔的定义 可知：如果令函数间隔等于1（之所以令等于1，是为了方便推导和优化，且这样做对目标函数的优化没有影响，至于为什么，请见本文评论下第42楼回复），则有$\gamma = 1 / ||w||$且，从而上述目标函数转化成了 相当于在相应的约束条件下，最大化这个1/||w||值，而1/||w||便是几何间隔$\hat{\gamma}$。 如下图所示，中间的实线便是寻找到的最优超平面（Optimal Hyper Plane），其到两条虚线边界的距离相等，这个距离便是几何间隔$\hat{\gamma}$，两条虚线间隔边界之间的距离等于2$\hat{\gamma}$，而虚线间隔边界上的点则是支持向量。由于这些支持向量刚好在虚线间隔边界上，所以它们满足（还记得我们把 functional margin 定为 1 了吗？上节中：处于方便推导和优化的目的，我们可以令$\hat{\gamma}$=1），而对于所有不是支持向量的点，则显然有。 OK，到此为止，算是了解到了SVM的第一层，对于那些只关心怎么用SVM的朋友便已足够，不必再更进一层深究其更深的原理。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构（二）]]></title>
    <url>%2Farchives%2F266a3580.html</url>
    <content type="text"><![CDATA[线性数据结构例：以下数据结构中，（）是非线性数据结构A.树B.字符串C.队D.栈 线性结构 是一个有序数据元素的集合。 a. 其中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。 b. 常用的线性结构有：线性表，栈，队列，双队列，数组，串 非线性结构 中各个数据元素不再保持在一个线性序列中，每个数据元素可能与零个或者多个其他数据元素发生联系。 a. 根据关系的不同，可分为层次结构和群结构。 b. 常见的非线性结构有：二维数组，多维数组，广义表，树(二叉树等)，图 字符串输出有字符数组 a[80] 和 b[80]，则正确的输出语句是（）A.puts(a); puts(b);B.printf(“%s,%s”, a[], b[]);C.putchar(a, b);D.puts(a, b); puts（）输出一个字符串，遇到’\0’结束，putchar（）输出单个字符 puts()函数用来向标准输出设备（屏幕）写字符串并换行，其调用方式为，puts(s)；其中s为字符串字符（字符串数组名或字符串指针）。 用法：int puts(const char *string); 则程序的输出结果是: H 91234567main( ) &#123; char c1,c2; c1 ='C'+'8'－'3'; c2 ='9'－'0'; printf("%c %d\n",c1,c2);&#125; 分析： string 和 int 型都支持直接加减 ‘C’+’8’-‘3’= ‘C’+’5’,由于’C’+1=’D’，所以结果为char ‘H’ =&gt; %c； ‘9’-‘0’：平时写代码的时候经常int（0~9）转换char就用的+’0’,因此结果直接就是int 9 =&gt; %d。 本题考查字符变量以及printf( )函数相关知识,字符变量c1被赋值为’C’+’8’－’3’,即ASSCII码的运算,67十54－49=72,即H;字符变量 c2被赋值为’9’－’0’,但输出时,需要注意的是c1以字符变量输出,而c2是以十进制整型变量输出。 栈设栈的初始状态为空，当字符序列a3_作为栈的输入时，输出长度为3的且可以用作C语言标识符的字符串序列有（3）个。 首先，栈的顺序是先进后出字符序列为a3_ 1)a入栈，再出栈，然后3入栈，再出栈，—入栈，再出栈 序列是a3_ 2)a入栈，再出栈,然后3,—入栈，再出栈，序列是a_3 3)a入栈，3入栈，再出栈，a出栈， —入栈，再出栈 序列是3a_ 4) a入栈，3入栈，再出栈, —入栈,序列是3_a 5) a入栈，3入栈,_入栈，序列是3a其次，C语言的标识符不能以数字开头，去除3a和3_a 答案为3 补充一下卡特兰数公式 h(n)=C(2n，n)/(n+1)，适用于出栈情况求和.】 根据卡特兰数公式，所有的输出总数为5次，减掉3开头的2个为3个。 栈和队栈：先进后出；栈只能在栈顶插入和删除数据。 栈的应用： 1、符号匹配； 2、表达式求值； 3、实现函数调用 4、栈是解决封闭对应问题的有效方法。 栈是限定在一端进行插入与删除的线性表，允许插入与删除的一端称为栈顶，不允许插入与删除的另一端称为栈底。栈按照“先进后出”(FILO)或“后进先出”(LIFO)组织数据，栈具有记忆作用 队：先进先出；队列只能在队尾插入数据，在队首删除数据 在递归算法执行过程中，计算机系统必定会用到的数据结构是（ 栈） 递归的过程，利用栈保存现场地址，然后将数据入栈，运算，后出栈，返回结果。 中缀表达式已知-算术表达式的中缀表达式为a-(b+c/d)e,其后缀形式为()A. -a+bc/dB.-a+bcd/eC.-+abc/deD.abcd/+e*- 后缀表达式不包含括号，运算符 放在两个运算对象的后面，所有的计算按运算符出现的顺序，严格从左向右进行（不再考虑运算符的优先规则）先是c/d写为cd/，(b+c/d)写为bcd/+，(b+c/d)e写为bcd/+e,a- ( b+c/d)e写为abcd/+e-。 这里我给出一个中缀表达式：a+bc-(d+e)第一步：按照运算符的优先级对所有的运算单位加括号：式子变成了：((a+(bc))-(d+e))第二步：转换前缀与后缀表达式前缀：把运算符号移动到对应的括号前面则变成了：-( +(a (bc)) +(de))把括号去掉：-+abc+de 前缀式子出现后缀：把运算符号移动到对应的括号后面则变成了：((a(bc) )+ (de)+ )-把括号去掉：abc+de+- 后缀式子出现 中序遍历，运算符一定是父节点。 sql若要删除 book 表中的所有数据，如下哪些语法是错误的？A.drop table book;B.truncate table book;C.delete from book;D.delelet *from book; A： drop table book 是删除整个表，题目的潜在意思是删除表中的数据而并非删除整个表。因此A错。B： truncate table book 是删除表中的数据，删除速度比delete更快，无法撤回（回退）。C： delete from book 删除数据表中的数据，可以回退，可添加where 子句。D：语法错误。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>堆</tag>
        <tag>栈</tag>
        <tag>图</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构（四）]]></title>
    <url>%2Farchives%2Fdc598fb7.html</url>
    <content type="text"><![CDATA[字符串例：下面 是‘ abcd321ABCD ’的子串。DA.abcdB.321abC.‘abc ABC’D.‘21AB’ 串中任意个连续的字符组成的子序列称为该串的子串。 空串和本身都算做本字符串的字串。 将两个字符串连接起来组成一个字符串时，选用（ ）函数。A.strlen()B.strcap()C.strcat()D.strcmp() strcat()字符串连接字符 strcmp()字符串大小比较 赋值不能把字符串”HELLO!”赋给数组b的语句是（）A.char b[10]={‘H’，’E’，’L’，’L’，’O’，’!’，’\0’};B.char b[10];b=”HELLO!”;C.char b[10];strcpy(b，”HELLO!”);D.char b[10]=”HELLO!”; 字符数组初始化有两种方法：一种是逐个字符赋值，另一种是用字符常量对整个数组赋值。 A是第一种，D是第二种。显然第一种比第二种繁琐复杂。 选项B并没有将数组b赋值为 hello！ 因子b是数组的首地址，b=”HELLO!”;是改变了这个指针的指向，是错误的。 C是字符串拷贝函数。函数格式： char strcpy (char s1, const char *s2);功能： 将S2所指的字符串拷贝到S1所指的字符串中。说明：（1）参数S1S2都是指向字符串的指针。S1可以是字符数组名或字符指针，但不能是字符型常量，S2可以是字符串常量、字符数组或字符指针。（2）将S2所指的字符串拷贝到S1所指的字符串中，用赋值语句S1=S2;是不行的，赋值语句要求左边是左值，S1是常量。 （3）要保证S1的长度足够大，以便能容纳下S2所指的字符串，否则引起错误。 C 对于非strtic型数组不初始化，其元素值不能确定。对strtic数组元素不赋初值，系统会自动赋以0值。（参考） 安全值？判断下述语句的对错：MFC中CString是类型安全的类。（对） 类型安全就是说，如果两个类型直接要相互转换，必须要显示的转换，不能偷偷摸摸的只用一个等于号就隐式转换了。 MFC数据类型转换标准库std的string 和MFC类库CString之间可以通过CString的format方法进行转换 类型安全不是一种类型，是有关类型操作一种规范。 如：不让不同类型的数据相互转换int Num =3;string Str=”3”;Num =Str; //错Num=int.Parse(Str);//对类型安全要求可以相互转换的不同类型数据在转换时 显式转换 字符串倒序请找出下面代码中的所有错误。说明：以下代码是把一个字符串倒序，如“abcd”倒序后变为“dcba”。 123456789101112131415#include "string.h" int main() &#123; char *src = "hello,world"; char *dest = NULL; int len = strlen(src); dest = (char *)malloc(len); char *d = dest; char *s = src[len]; while (len-- != 0) *d++ = *s--; printf("%s", dest); return 0; &#125; 第7行要为’\0’分配一个空间 第9行改成char * s = &amp;src[len-1] 第12行前要加上*d = ‘\0’ 第13行前要加上free(dest)释放空间 方法一：1234567891011121314int main()&#123; char *src = "hello,world"; int len = strlen(src); char *dest = (char *)malloc(len + 1); //要为\0分配一个空间 char *d = dest; char *s = &amp;src[len - 1]; //指向最后一个字符 while ( len-- != 0 ) *d++ = *s--; *d = 0; //尾部要加\0 printf("%s\n", dest); free(dest);// 使用完，应当释放空间，以免造成内存汇泄露 return 0;&#125; 方法二1234567891011121314int main()&#123; char str[] = "hello,world"; int len = strlen(str); char t; for (int i = 0; i &lt; len; i++) &#123; t = str[i]; str[i] = str[len - i - 1]; str[len - i - 1] = t; &#125; printf("%s", str); return 0;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>堆</tag>
        <tag>栈</tag>
        <tag>图</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串]]></title>
    <url>%2Farchives%2Ffc81fbfd.html</url>
    <content type="text"><![CDATA[字符串例：下面 是‘ abcd321ABCD ’的子串。DA.abcdB.321abC.‘abc ABC’D.‘21AB’ 串中任意个连续的字符组成的子序列称为该串的子串。 空串和本身都算做本字符串的字串。 将两个字符串连接起来组成一个字符串时，选用（ ）函数。A.strlen()B.strcap()C.strcat()D.strcmp() strcat()字符串连接字符 strcmp()字符串大小比较 赋值不能把字符串”HELLO!”赋给数组b的语句是（）A.char b[10]={‘H’，’E’，’L’，’L’，’O’，’!’，’\0’};B.char b[10];b=”HELLO!”;C.char b[10];strcpy(b，”HELLO!”);D.char b[10]=”HELLO!”; 字符数组初始化有两种方法：一种是逐个字符赋值，另一种是用字符常量对整个数组赋值。 A是第一种，D是第二种。显然第一种比第二种繁琐复杂。 选项B并没有将数组b赋值为 hello！ 因子b是数组的首地址，b=”HELLO!”;是改变了这个指针的指向，是错误的。 C是字符串拷贝函数。函数格式： char strcpy (char s1, const char *s2);功能： 将S2所指的字符串拷贝到S1所指的字符串中。说明：（1）参数S1S2都是指向字符串的指针。S1可以是字符数组名或字符指针，但不能是字符型常量，S2可以是字符串常量、字符数组或字符指针。（2）将S2所指的字符串拷贝到S1所指的字符串中，用赋值语句S1=S2;是不行的，赋值语句要求左边是左值，S1是常量。 （3）要保证S1的长度足够大，以便能容纳下S2所指的字符串，否则引起错误。 C 对于非strtic型数组不初始化，其元素值不能确定。对strtic数组元素不赋初值，系统会自动赋以0值。（参考） 安全值？判断下述语句的对错：MFC中CString是类型安全的类。（对） 类型安全就是说，如果两个类型直接要相互转换，必须要显示的转换，不能偷偷摸摸的只用一个等于号就隐式转换了。 MFC数据类型转换标准库std的string 和MFC类库CString之间可以通过CString的format方法进行转换 类型安全不是一种类型，是有关类型操作一种规范。 如：不让不同类型的数据相互转换int Num =3;string Str=”3”;Num =Str; //错Num=int.Parse(Str);//对类型安全要求可以相互转换的不同类型数据在转换时 显式转换 字符串倒序请找出下面代码中的所有错误。说明：以下代码是把一个字符串倒序，如“abcd”倒序后变为“dcba”。 123456789101112131415#include "string.h" int main() &#123; char *src = "hello,world"; char *dest = NULL; int len = strlen(src); dest = (char *)malloc(len); char *d = dest; char *s = src[len]; while (len-- != 0) *d++ = *s--; printf("%s", dest); return 0; &#125; 第7行要为’\0’分配一个空间 第9行改成char * s = &amp;src[len-1] 第12行前要加上*d = ‘\0’ 第13行前要加上free(dest)释放空间 方法一：1234567891011121314int main()&#123; char *src = "hello,world"; int len = strlen(src); char *dest = (char *)malloc(len + 1); //要为\0分配一个空间 char *d = dest; char *s = &amp;src[len - 1]; //指向最后一个字符 while ( len-- != 0 ) *d++ = *s--; *d = 0; //尾部要加\0 printf("%s\n", dest); free(dest);// 使用完，应当释放空间，以免造成内存汇泄露 return 0;&#125; 方法二1234567891011121314int main()&#123; char str[] = "hello,world"; int len = strlen(str); char t; for (int i = 0; i &lt; len; i++) &#123; t = str[i]; str[i] = str[len - i - 1]; str[len - i - 1] = t; &#125; printf("%s", str); return 0;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>堆</tag>
        <tag>栈</tag>
        <tag>图</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构（三）]]></title>
    <url>%2Farchives%2F6b7496d2.html</url>
    <content type="text"><![CDATA[折半查找与顺序查找两者查找速度比较：例如在一个数组中有10个元素. 第一个是要找的元素.折半查找：先找第六（下标为5）个,再找第三个（下标为2）,然后是第二个（下标为1）,最后是第一个（下标为0）…顺序查找：只要找一次就ok了. 第10个是要找的元素.折半查找：先找第六（下标为5）个,再找第八个（下标为7）,然后是第九个（下标为8）,最后是第十个（下标为9）…顺序查找：需要10次. 第三个是要找的元素.折半查找：先找第六（下标为5）个,再找第三个（下标为2）顺序查找：需要三次（效率一样）. 折半查找用向量和单链表示的有序表均可使用折半查找方法来提高查找速度(错) 折半查找属于随机访问特性 链表不行 堆排序也不能用链表 因为调整堆时没法随机访问底层孩子节点 快速排序可以链表 归并排序可用链表 基数排序可用链表 插入排序链表比数组要快一些 减少移动次数 具有12个关键字的有序表,折半查找的平均查找长度() 将12个数画成完全二叉树，第一层有1个、第二次2个、第三层4个，第四层只有5个。二分查找时：第一层需要比较1次第二两个数，每个比较2次第三层四个数，每个比较3次第四层五个数，每个比较4次则平均查找长度即为：（1+22+34+4*5）/12 = 37/12 = 3.0833 即为 A、3.1 动态查找与静态查找适于对动态查找表进行高效率查找的组织结构是分块有序表(错) 分块查找是静态查找 动态查找有二叉排序树查找，最优二叉树查找，键树查找，哈希表查找 静态查找表只进行以下2个操作： 1.查找某个“特定”数据元素是否在查找表中 2.查找某个“特定”数据元素的各种属性 有序表、分块有序表、线性链表都是静态查找表性能分析：平均查找长度：（当查找关键字等概率时）ASL = 1/(n+1) 动态查找表:表结构是在查找过程中动态生成的，通俗解释，对于给定key,若表中存在某关键字与key相等则查找成功返回，若未找到则插入关键字等于key的记录。 二叉排序树、平衡二叉树、B树、B+树都是动态查找。（对查找表进行插入和删除操作—即为动态的） 平均查找长度就平均查找长度而言,分块查找最小,折半查找次之,顺序查找最大(错) 分快查找，是将顺序表分为若干块，块内元素顺序任意，块间有序，即前一块中的最大值小于后一块中的最小值。并且有一张索引表，每一项存放每一块的最大值和指向该块第一个元素的指针。索引表有序，块内无序。所以，块间查找用二分查找，块内用顺序查找，效率介于顺序和二分之间。 分块查找：1.将顺序表分为若干块，除最后一块，前面每块元素相等，块间有序，块内无序2.索引表内元素有序，用二分折半查找，每块内元素无序，用顺序查找3.所以分块查找介于折半查找和顺序查找之间 判断是否有环判断是否有环方法：1.拓扑排序2.深度优先遍历3.广度优先遍历]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>堆</tag>
        <tag>栈</tag>
        <tag>图</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（二）:栈，队，数组]]></title>
    <url>%2Farchives%2Fc071cc58.html</url>
    <content type="text"><![CDATA[用两个栈来实现一个队列用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型 &lt;分析&gt;： 入队：将元素进栈A 出队：判断栈B是否为空，如果为空，则将栈A中所有元素pop，并push进栈B，栈B出栈； 如果不为空，栈B直接出栈。 用两个队列实现一个栈的功能?要求给出算法和思路! &lt;分析&gt;： 入栈：将元素进队列A 出栈：判断队列A中元素的个数是否为1，如果等于1，则出队列，否则将队列A中的元素 以此出队列并放入队列B，直到队列A中的元素留下一个，然后队列A出队列，再把 队列B中的元素出队列以此放入队列A中。1234567891011121314151617181920212223class Solution&#123;public: void push(int node)&#123; stack1.push(node); &#125; int pop()&#123; int a; if(stack2.empty())&#123; while(!stack1.empty())&#123; a=stack1.top(); stack2.push(a); stack1.pop(); &#125; &#125; a=stack2.top(); stack2.pop(); return a; &#125;private: stack&lt;int&gt; stack1; stack&lt;int&gt; stack2; &#125;; 算法思路： 栈A用来作入队列栈B用来出队列，当栈B为空时，栈A全部出栈到栈B,栈B再出栈（即出队列）12345678910111213# -*- coding:utf-8 -*-class Solution: def __init__(self): self.stack1=[] self.stack2=[] def push(self,node): self.stack1.append(node) def pop(self,node): if self.stack2==[]: while self.stack1: self.stack2.append(self.stack1,pop()) return stack2.pop() return stack2.pop() 旋转数组的最小数字把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。12345678910111213141516171819# -*- coding:utf-8 -*-class Solution: def minNumberInRotateArray(self, rotateArray): # write code here if len(rotateArray) == 0: return 0 ret = rotateArray[0] if len(rotateArray) == 1: return ret for i in range(1,len(rotateArray)): now = rotateArray[i] if now &lt; ret: ret = now break return ret 剑指Offer中有这道题目的分析。这是一道二分查找的变形的题目。 旋转之后的数组实际上可以划分成两个有序的子数组：前面子数组的大小都大于后面子数组中的元素 注意到实际上最小的元素就是两个子数组的分界线。本题目给出的数组一定程度上是排序的，因此我们试着用二分查找法寻找这个最小的元素。 思路： （1）我们用两个指针left,right分别指向数组的第一个元素和最后一个元素。按照题目的旋转的规则，第一个元素应该是大于最后一个元素的（没有重复的元素）。 但是如果不是旋转，第一个元素肯定小于最后一个元素。 （2）找到数组的中间元素。 中间元素大于第一个元素，则中间元素位于前面的递增子数组，此时最小元素位于中间元素的后面。我们可以让第一个指针left指向中间元素。 移动之后，第一个指针仍然位于前面的递增数组中。 中间元素小于第一个元素，则中间元素位于后面的递增子数组，此时最小元素位于中间元素的前面。我们可以让第二个指针right指向中间元素。 移动之后，第二个指针仍然位于后面的递增数组中。 这样可以缩小寻找的范围。 （3）按照以上思路，第一个指针left总是指向前面递增数组的元素，第二个指针right总是指向后面递增的数组元素。 最终第一个指针将指向前面数组的最后一个元素，第二个指针指向后面数组中的第一个元素。 也就是说他们将指向两个相邻的元素，而第二个指针指向的刚好是最小的元素，这就是循环的结束条件。 到目前为止以上思路很耗的解决了没有重复数字的情况，这一道题目添加上了这一要求，有了重复数字。 因此这一道题目比上一道题目多了些特殊情况： 我们看一组例子：｛1，0，1，1，1｝ 和 ｛1，1， 1，0，1｝ 都可以看成是递增排序数组｛0，1，1，1，1｝的旋转。 这种情况下我们无法继续用上一道题目的解法，去解决这道题目。因为在这两个数组中，第一个数字，最后一个数字，中间数字都是1。 第一种情况下，中间数字位于后面的子数组，第二种情况，中间数字位于前面的子数组。 因此当两个指针指向的数字和中间数字相同的时候，我们无法确定中间数字1是属于前面的子数组（绿色表示）还是属于后面的子数组（紫色表示）。 也就无法移动指针来缩小查找的范围。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;stack&gt;#include &lt;algorithm&gt;using namespace std; class Solution &#123;public: int minNumberInRotateArray(vector&lt;int&gt; rotateArray) &#123; int size = rotateArray.size(); if(size == 0)&#123; return 0; &#125;//if int left = 0,right = size - 1; int mid = 0; // rotateArray[left] &gt;= rotateArray[right] 确保旋转 while(rotateArray[left] &gt;= rotateArray[right])&#123; // 分界点 if(right - left == 1)&#123; mid = right; break; &#125;//if mid = left + (right - left) / 2; // rotateArray[left] rotateArray[right] rotateArray[mid]三者相等 // 无法确定中间元素是属于前面还是后面的递增子数组 // 只能顺序查找 if(rotateArray[left] == rotateArray[right] &amp;&amp; rotateArray[left] == rotateArray[mid])&#123; return MinOrder(rotateArray,left,right); &#125;//if // 中间元素位于前面的递增子数组 // 此时最小元素位于中间元素的后面 if(rotateArray[mid] &gt;= rotateArray[left])&#123; left = mid; &#125;//if // 中间元素位于后面的递增子数组 // 此时最小元素位于中间元素的前面 else&#123; right = mid; &#125;//else &#125;//while return rotateArray[mid]; &#125;private: // 顺序寻找最小值 int MinOrder(vector&lt;int&gt; &amp;num,int left,int right)&#123; int result = num[left]; for(int i = left + 1;i &lt; right;++i)&#123; if(num[i] &lt; result)&#123; result = num[i]; &#125;//if &#125;//for return result; &#125;&#125;; int main()&#123; Solution s; //vector&lt;int&gt; num = &#123;0,1,2,3,4,5&#125;; //vector&lt;int&gt; num = &#123;4,5,6,7,1,2,3&#125;; vector&lt;int&gt; num = &#123;2,2,2,2,1,2&#125;; int result = s.minNumberInRotateArray(num); // 输出 cout&lt;&lt;result&lt;&lt;endl; return 0;&#125;]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer（一）]]></title>
    <url>%2Farchives%2F8ad708de.html</url>
    <content type="text"><![CDATA[二维数组中的查找在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 算法思想： 由于数组从左到右，从上到下都是递增，可以从右上角或者左下角开始查找，这里从右上角开始查找 定义数组array，行i，列j，目标target。 若array[i][j]==target,那恭喜你找到目标； 若array[i][j]&gt;target,那向左去找目标–j； 否则，array[i][j]小于target,那向下寻找目标++i； 1234567891011121314151617181920class Solution&#123;public: bool Find(int target,vector&lt;vector&lt;int&gt; &gt; array)&#123; if(array.size()!=0) &#123; int i=0; int j=array[0].size()-1; while(i&lt; array.size()&amp;&amp; j&gt;= 0) &#123; if(array[i][j]== target) return true; else if(array[i][j]&gt;target) --j; else ++i; &#125; &#125; return false; &#125;&#125;; 替换空格请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy 算法思想： 定义字符串下标i（i=0开始），定义空格bankNum,遍历字符串并计算空格个数； 总字符串=原始字符串下标+1+2*bankNum； 末尾字符串下标=totalNum-1，也就是我们说的放置位置； 总体来说：从后向前遍历字符串，如果遇到空格，就加%20；没有空格，就将原字符串的最后一个字符赋给新字符串 123456789101112131415161718192021222324252627class Solution&#123;public: void replaceSpaca(char *str,int length) &#123; int bankNum=0; int i=0; for(;str[i]!='\0';++i) if(str[i]==' ') ++bankNum; &#125; int totalNum=i+1+2*bankNum; int pos=totalNum-1; for(;i&gt;=0;--i) &#123; if(str[i]==' ') &#123; str[pos--]='0'; str[pos--]='2'; str[pos--]='%'; &#125; else str[pos--]=str[i]; &#125;; &#125; 打印链表输入一个链表，从尾到头打印链表每个节点的值。 12345678class Solution: def printListFromTailToHead(self,listNode): l=[] head = listNode while head: l.insert(0,head.val) head=head.next return 1 二分查找1234567891011121314151617181920def search2(a,m): low=0 high=len(a)-1 while(low&lt;=high): mid=(low+high)/2 midval=a[mid] if midval&lt;m: low=mid+1 else if midval&gt;m: high=mid-1 else return mid return -1 if __name__=="__main__" a=[1,2,3,4,5,6,7,8,9] m=5 result=search2(a,m) print result 下面这个程序就会陷入无限循环while中123456789101112131415161718192021#include&lt;studio.h&gt;int bsearch(int a[],int n,int v)&#123; int left, middle, right; left=0, right=n-1; while(left&lt;=right) &#123; middle=left+(right-left)/2; if(a[middle]&gt;v) &#123; right=middle &#125; else if(a[middle]&lt;v) &#123; left=middle &#125; else return middle; &#125; return -1;&#125; 以下是正确写法123456789101112131415161718public static int binarySearch(int[] a,int n,int x)&#123; if(n&gt;0 &amp;&amp; x&gt;=a[0]) &#123; int left=0,right=n-1; while(left&lt;right) &#123; int middle=left+(right-left)/2; if(x&lt;a[middle]) right=middle-1; else left=middle; &#125; if(x==a[left]) return left; &#125; return -1;&#125; 重建二叉树输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。1234567891011121314151617# -*- coding:utf-8 -*-# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: # 返回构造的TreeNode根节点 def reConstructBinaryTree(self, pre, tin): # write code here if len(pre) == 0: return None root = TreeNode(pre[0]) pos = tin.index(pre[0]) root.left = self.reConstructBinaryTree( pre[1:1+pos], tin[:pos]) root.right = self.reConstructBinaryTree( pre[pos+1:], tin[pos+1:]) return root]]></content>
      <categories>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>查找</tag>
        <tag>替换空格</tag>
        <tag>打印链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构（一）]]></title>
    <url>%2Farchives%2F167cd958.html</url>
    <content type="text"><![CDATA[字符串设字符串S=’ABCDEFG’,T=’PQRST’,则运算CONCAT(SUBSTR(S,2，LENGTH(T),SUBSTR(S,LENGTH(T),2) ))后的结果为（）A.’BCQR’B.’BCDEF’C.’BCDEFG’D.’BCDEFEF’ oracle中取得字符串中指定起始位置和长度的字符串substr( string, start_position, [ length ] )，计数从1开始，字符串长度不带“\0” concat() 方法用于连接两个或多个数组。 substr是C++语言函数，主要功能是复制子字符串，要求从指定位置开始，并具有指定的长度。 SUBSTR(S,2，LENGTH(T) ) 如果没有指定长度_Count或_Count+_Off超出了源字符串的长度，则子字符串将延续到源字符串的结尾。oracle中字符下标从1开始，此处为从字符串S的第2个开始，截取长度为LENGTH(T)即5的字符串结果为：BCDEFSUBSTR(S,LENGTH(T),2)，从字符串S的第LENGTH(T)即第5个开始，截取长度为2的字符串结果为：EFCONCAT结果为：BCDEFEF 下面关于字符串的描述正确的是：【多选】（ ）A.通过String s1=new String(“abc”)和String s2=”abc”，则s1==s2为true。B.”abc”+”def”则会创建三个字符串对象，第三个是”abcdef”。也就是说，在Java中对字符串的一切操作，都会产生一个新的字符串对象。C.StringBuffer是线程安全的，它比String快。D.StringBuilder是线程安全的，它比String快 三者执行速度：StringBuilder &gt; StringBuffer &gt; String ； StringBuilder：线程非安全的； StringBuffer：线程安全的； 用String操作字符串时，实际上是在不断地创建新对象，而原来的对象会作为垃圾被回收； 对于A： s1利用new 操作后，为该对象在堆（Heap）区分配了一块内存； s2是字符串常量，存放在内存的”文字常量区“ ；虽然两个对象的值相同，但由于两者位于不同的地址，不是相同的对象，因此 s1==s2 为false。 A错 多型数据类型 多型数据类型是指包含的数据元素的类型并不确定。 比如栈可以是整数栈、字符栈、对象栈等等。 但是字符串，它的元素必然是字符。 设模式串的长度为m,目标串的长度为n,当n≈m且处理只匹配一次的模式时,朴素的匹配(即子串定位函数)算法所花的时间代价可能会更为节省()A.对B.错 朴素的匹配只匹配一次，不用计算next数组，所以速度更快 字符串的朴素算法(就是暴力搜索） 子串 n 个字符构成的字符串，假设每个字符都不一样，问有多少个子串？A. n+1B.n(n+1)/2 + 1C.2^n-1D.n! 这么想就很简单：长度为 1 的字符串 n 个长度为 2 的 n-1 个长度为 3 的 n-2 个…长度为 n 的 1 个然后 n+(n-1)+(n-2)+…+1 =n(n+1)/2 下面程序段的输出结果是D 123char *p1 = ”123”, *p2 = ”ABC”, str[50] = “xyz”;strcpy(str + 2, strcat(p1, p2));printf(“%s\n”, str); A.xyz123ABCB.z123ABCC.xy123ABCD.出错 原代码有错： p1和p2都指向常量字符串，在常量区，所以不能对其进行操作； 改为数组即可，但是用字符串初始化数组时要记得将数组长度加1，因为字符串默认的末尾有一个‘\0’； 第二点要注意的是，strcat函数的p1要有足够的空间来容纳p1和p2连接后的串长。 修改为以下代码将可以：12345char p1[7] = "123";char p2[] = "ABC";char str[50] = "xyz";strcpy(str + 2, strcat(p1, p2));printf("%s\n", str); char *p1=”123” 声明了个字符串指针p1，指向字符串“ 123 ”，此时的“ 123 ”存放在常量区，并没有在拷贝到栈中，所以不能修改，如修改p1[0] = ‘2’就是错误的。建议改为char p1[10] = “123”，就可以修改p1的值。 空串和由空格组成的串 空串：a=“没有东西”； 空格串：b=“空格空格” 所以空串和空格串是不一样的 想像使用split()方法时，这两个参数得到的结果肯定不一样 #有关赋值不能所字符串“Good!”存放到数组 s 中的代码是（D）A.char s[8] = {‘G’,’o’,’o’,’d’,’!’, ‘\0’};B.char s[8];strcpy(s, “Good!”);C.char s[8];s = “Good!”;D.char s[8] = “Good!”; char数组只有在初始化的时候才能整体赋值 char s[8],表示s是一个不可修改的左值，s实际上是char *const s 类型的值 KMP KMP算法的特点是在模式匹配时指示主串的指针不会变小 KMP算法最大的特点就是指示主串的指针不需要回溯，因此指针不可能变小 NEXT数组串′ababaaababaa′的next数组为(011234223456) 第一种方法： next数组的求解方法是：第一位的next值为0，第二位的next值为1，后面求解每一位的next值时，根据前一位进行比较。 首先将前一位与其next值对应的内容进行比较，如果相等，则该位的next值就是前一位的next值加上1； 如果不等，向前继续寻找next值对应的内容来与前一位进行比较，直到找到某个位上内容的next值对应的内容与前一位相等为止，则这个位对应的值加上1即为需求的next值； 如果找到第一位都没有找到与前一位相等的内容，那么需求的位上的next值即为1。 第二种解释：next数组下标从1开始计算next[1] 肯定是 0next[2] 肯定是 1next[n] 的情况，将前面n-1个字符，计算从首尾开始组成最大的相同子串的长度，如果找到，那么next值是该长度加1，否则next值是1。 举例next[6]的计算，字符串第六位是 a ，( ababa a ababaa)将前面的5个字符，从头尾开始取4个组成子串比较，如果不相等，则从首尾取3个字符组成子串继续比较，并以此类推， 如果一直比较到最后一个字符都不相等，那么该next值为1。4个字符的情况：abab : baba3个字符的情况：aba : aba 此时相等，那么next[6] = 3+1 = 4 第三种（在看不懂我就没办法了） 123 i 0 1 2 3 4 5 6 7 8 9 10 11 s a b a b a a a b a b a a next[i] -1 0 0 1 2 3 1 1 2 3 4 5 先计算前缀next[i]的值： （字符串匹配是 从头开始的 和 从尾开始的字符串进行匹配是否重复 ） next[i]的值主要是看s[i]之前的字符串中重复的子串长度。next[0] = -1，定值。 next[1]是看s[1]之前的字符串“a”中重复的子串长度为0，故next[1] = 0。 next[2]是看s[2]之前的字符串“ab”中重复的子串长度为0，故next[2] = 0。 next[3]是看s[3]之前的字符串”aba”中重复的子串长度，s[0]与s[2]重复，长度为1，故next[3] = 1。 next[4]是看s[4]之前的字符串”abab”中重复的子串长度，s[01]与s[23]重复，长度为2，故next[4] = 2。 next[5]是看s[5]之前的字符串”ababa”中重复的子串长度，s[012]与s[234]重复，长度为3，故next[5] = 3。 next[6]是看s[6]之前的字符串”ababaa”中重复的子串长度，s[0]与s[5]重复(因为多了一个a，无法找到长度为3的重复字符串，这只能是s[0]和s[5]重复)，长度为1，故next[6] = 1。 同样的，求next[7]和next[8]、next[9]、 next[10]、 next[11] 分别为1和2、3、4、5。 指针和数组12345678910111213141516#include&lt;stdio.h&gt;char *myString()&#123; char buffer[6] = &#123;0&#125;; char *s = &quot;Hello World!&quot;; for (int i = 0; i &lt; sizeof(buffer) - 1; i++) &#123; buffer[i] = *(s + i); &#125; return buffer;&#125;int main(int argc, char **argv)&#123; printf(&quot;%s\n&quot;, myString()); return 0;&#125; 输出结果？ 函数char *myString()中没有使用new或者malloc分配内存，所有buffer数组的内存区域在栈区 随着char *myString()的结束，栈区内存释放，字符数组也就不存在了，所以会产生野指针，输出结果未知]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>堆</tag>
        <tag>栈</tag>
        <tag>图</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（四）：AdaBoost算法 Boosting和Bagging等]]></title>
    <url>%2Farchives%2F919c217.html</url>
    <content type="text"><![CDATA[SVM以下关于SVM说法正确的是（）A.L2正则项，作用是最大化分类间隔，使得分类器拥有更强的泛化能力B.Hinge 损失函数，作用是最小化经验分类错误C.分类间隔为1/||w||，||w||代表向量的模D.当参数C越小时，分类间隔越大，分类错误越多，趋于欠学习 (1). 考虑加入正则化项的原因：想象一个完美的数据集，y&gt;1是正类，y&lt;-1是负类，决策面y=0，加入一个y=-30的正类噪声样本，那么决策面将会变“歪”很多，分类间隔变小，泛化能力减小。A正确。 (2). 加入正则项之后，对噪声样本的容错能力增强，前面提到的例子里面，决策面就会没那么“歪”了，使得分类间隔变大，提高了泛化能力。 B正确。 (3). C错误。间隔应该是2/||w||才对，后半句应该没错，向量的模通常指的就是其二范数。 (4). D正确。考虑软间隔的时候，C对优化问题的影响就在于把a的范围从[0，+inf]限制到了[0,C]。C越小，那么a就会越小，目标函数拉格朗日函数导数为0可以求出w=求和a_iy_ix_i，a变小使得w变小，因此间隔2/||w||变大 过拟合在其他条件不变的前提下，以下哪种做法容易引起机器学习中的过拟合问题（）A.增加训练集量B.减少神经网络隐藏层节点数C.删除稀疏的特征SD.SVM算法中使用高斯核/RBF核代替线性核 (1). 一般认为，增加隐层数可以降低网络误差（也有文献认为不一定能有效降低），提高精度，但也使网络复杂化，从而增加了网络的训练时间和出现“过拟合”的倾向， (2). 引起过拟合的应该是太多的参数引起的。神经网络减少隐藏层节点，就是在减少参数啊，只会将训练误差变高，怎么会过拟合呢。 B错误。 (3). 径向基(RBF)核函数/高斯核函数的说明 a. 这个核函数可以将原始空间映射到无穷维空间。 b. 对于参数 ，如果选的很大，高次特征上的权重实际上衰减得非常快，实际上（数值上近似一下）相当于一个低维的子空间；反过来，如果选得很小，则可以将任意的数据映射为线性可分——当然，这并不一定是好事，因为随之而来的可能是非常严重的过拟合问题。 c. 不过，总的来说，通过调整参数 ，高斯核实际上具有相当高的灵活性，也是 使用最广泛的核函数 之一。 (4). D正确。SVM高斯核函数比线性核函数模型更复杂，容易过拟合。 数据清理数据清理中，处理缺失值的方法有两种： 删除法： 1）删除观察样本 2）删除变量：当某个变量缺失值较多且对研究目标影响不大时，可以将整个变量整体删除 3）使用完整原始数据分析：当数据存在较多缺失而其原始数据完整时，可以使用原始数据替代现有数据进行分析 4）改变权重：当删除缺失数据会改变数据结构时，通过对完整数据按照不同的权重进行加权，可以降低删除缺失数据带来的偏差 查补法：均值插补、回归插补、抽样填补等成对删除与改变权重为一类估算与查补法为一类 由于调查、编码和录入误差，数据中可能存在一些无效值和缺失值，需要给予适当的处理。常用的处理方法有：估算，整例删除，变量删除和成对删除。 估算(estimation)。最简单的办法就是用某个变量的样本均值、中位数或众数代替无效值和缺失值。这种办法简单，但没有充分考虑数据中已有的信息，误差可能较大。另一种办法就是根据调查对象对其他问题的答案，通过变量之间的相关分析或逻辑推论进行估计。例如，某一产品的拥有情况可能与家庭收入有关，可以根据调查对象的家庭收入推算拥有这一产品的可能性。 整例删除(casewise deletion)是剔除含有缺失值的样本。由于很多问卷都可能存在缺失值，这种做法的结果可能导致有效样本量大大减少，无法充分利用已经收集到的数据。因此，只适合关键变量缺失，或者含有无效值或缺失值的样本比重很小的情况。 变量删除(variable deletion)。如果某一变量的无效值和缺失值很多，而且该变量对于所研究的问题不是特别重要，则可以考虑将该变量删除。这种做法减少了供分析用的变量数目，但没有改变样本量。 成对删除(pairwise deletion)是用一个特殊码(通常是9、99、999等)代表无效值和缺失值，同时保留数据集中的全部变量和样本。但是，在具体计算时只采用有完整答案的样本，因而不同的分析因涉及的变量不同，其有效样本量也会有所不同。这是一种保守的处理方法，最大限度地保留了数据集中的可用信息。 采用不同的处理方法可能对分析结果产生影响，尤其是当缺失值的出现并非随机且变量之间明显相关时。因此，在调查中应当尽量避免出现无效值和缺失值，保证数据的完整性。 分支定界法 分支定界法（branch and bound）是一种求解 整数规划 问题的最常用算法。 这种方法不但可以求解纯整数规划，还可以求解混合整数规划问题。 分支定界法是计算机最擅长 的广义搜索穷举算法。 分支定界法是一种搜索与迭代的方法，选择不同的分支变量和子问题进行分支。 对于两个变量的整数规划问题，使用网格的方法有时更为简单。 分支定界法类似决策树的决策特征，要选择那些具有强可分辨性的少量特征。 线性回归关于线性回归的描述,以下正确的有:2,3,5 基本假设包括随机干扰项是均值为0,方差为1的标准正态分布 基本假设包括随机干扰项是均值为0的同方差正态分布 在违背基本假设时,普通最小二乘法估计量不再是最佳线性无偏估计量 在违背基本假设时,模型不再可以估计 可以用DW检验残差是否存在序列相关性 多重共线性会使得参数估计值方差减小 一元线性回归的基本假设有: 随机误差项是一个期望值或平均值为0的随机变量； 对于解释变量的所有观测值，随机误差项有相同的方差； 随机误差项彼此不相关； 解释变量是确定性变量，不是随机变量，与随机误差项彼此之间相互独立； 解释变量之间不存在精确的（完全的）线性关系，即解释变量的样本观测值矩阵是满秩矩阵； 随机误差项服从正态分布 注意： 违背基本假设的计量经济学模型还是可以估计的，只是不能使用普通最小二乘法进行估计。 当存在异方差时，普通最小二乘法估计存在以下问题： 参数估计值虽然是无偏的，但不是最小方差线性无偏估计。 杜宾-瓦特森（DW）检验，计量经济，统计分析中常用的一种检验序列一阶 自相关 最常用的方法。 所谓多重共线性（Multicollinearity）是指线性回归模型中的解释变量之间由于存在精确相关关系或高度相关关系而使模型估计失真或难以估计准确。影响 （1）完全共线性下参数估计量不存在 （2）近似共线性下OLS估计量非有效 多重共线性使参数估计值的方差增大，1/(1-r2)为方差膨胀因子(Variance Inflation Factor, VIF) （3）参数估计量经济含义不合理 （4）变量的显著性检验失去意义，可能将重要的解释变量排除在模型之外 （5）模型的预测功能失效。变大的方差容易使区间预测的“区间”变大，使预测失去意义。 SVM AdaBoost算法 Boosting和Bagging以下说法中正确的是(BD)A.SVM对噪声(如来自其他分布的噪声样本)鲁棒B.在AdaBoost算法中,所有被分错的样本的权重更新比例相同C.Boosting和Bagging都是组合多个分类器投票的方法,二者都是根据单个分类器的正确率决定其权重D.给定n个数据点,如果其中一半用于训练,一般用于测试,则训练误差和测试误差之间的差别会随着n的增加而减少 Adaboost目的是从训练数据中学习一系列弱分类器，然后将其按一定权重累加起来得到强分类器。刚开始每个样本对应的权重是相等的，在此样本分布下训练一个基本分类器c1.对于c1错分的样本增加其权重，对正确分类的样本降低其权重。这样使得错分的样本突出出来，并得到一个新的样本分布。同时根据分类情况赋予c1一个权重，表示其重要程度，分类正确率越高权重越大。然后在新的样本分布下对分类器进行训练，得到c2及其权重。依此类推，得到M个基本分类器及其权重。将这些弱分类器按照权重累加起来就是所期望的强分类器。（B对） Bagging是对训练样本多次抽样训练多个分类器，然后对测试集进行投票所得到的优胜结果就是最终的分类结果。在投票时每个分类器的权重是相等的。（所以C错） SVM对噪声（如来自其他分布的噪声样本）鲁棒。SVM本身对噪声具有一定的鲁棒性，但实验证明，是当噪声率低于一定水平的噪声对SVM没有太大影响，但随着噪声率的不断增加，分类器的识别率会降低。 在AdaBoost算法中所有被分错的样本的权重更新比例相同。AdaBoost算法中不同的训练集是通过调整每个样本对应的权重来实现的。开始时，每个样本对应的权重是相同的，即其中n为样本个数，在此样本分布下训练出一弱分类器。对于分类错误的样本，加大其对应的权重；而对于分类正确的样本，降低其权重，这样分错的样本就被凸显出来，从而得到一个新的样本分布。在新的样本分布下，再次对样本进行训练，得到弱分类器。以此类推，将所有的弱分类器重叠加起来，得到强分类器。 Boost和Bagging都是组合多个分类器投票的方法，二者均是根据单个分类器正确率决定其权重。 Bagging与Boosting的区别：取样方式不同。 Bagging采用均匀取样，而Boosting根据错误率取样。 Bagging的各个预测函数没有权重，而Boosting是由权重的，Bagging的各个预测函数可以并行生成，而Boosing的哥哥预测函数只能顺序生成。 判别式模型与生成式模型生成式模型(Generative Model)与判别式模型(Discrimitive Model)是分类器常遇到的概念，它们的区别在于：（对于输入x，类别标签y） 生成式模型估计它们的联合概率分布P(x,y) 判别式模型估计决策函数F(X)或条件概率分布P(y|x) 生成式式模型可以根据贝叶斯公式得到判别式模型，但反过来不行 生成式模型 判别式分析 朴素贝叶斯Native Bayes 混合高斯型Gaussians K近邻KNN 隐马尔科夫模型HMM 贝叶斯网络 sigmoid belief networks 马尔科夫随机场Markov random fields 深度信念网络DBN 隐含狄利克雷分布简称LDA(Latent Dirichlet allocation) 多专家模型（the mixture of experts model） 判别式模型 线性回归linear regression 逻辑回归logic regression 神经网络NN 支持向量机SVM 高斯过程Gaussian process 条件随机场CRF CART(Classification and regression tree) Boosting 线性分类器线性分类器有三大类：感知器准则函数、SVM、Fisher准则，而贝叶斯分类器不是线性分类器。 感知器准则函数：代价函数J=-(W*X+w0).分类的准则是最小化代价函数。感知器是神经网络（NN）的基础，网上有很多介绍。 SVM：支持向量机也是很经典的算法，优化目标是最大化间隔（margin），又称最大间隔分类器，是一种典型的线性分类器。（使用核函数可解决非线性问题） Fisher准则：更广泛的称呼是线性判别分析（LDA），将所有样本投影到一条远点出发的直线，使得同类样本距离尽可能小，不同类样本距离尽可能大，具体为最大化“广义瑞利商”。 贝叶斯分类器：一种基于统计方法的分类器，要求先了解样本的分布特点（高斯、指数等），所以使用起来限制很多。在满足一些特定条件下，其优化目标与线性分类器有相同结构（同方差高斯分布等），其余条件下不是线性分类。 分类问题在分类问题中,我们经常会遇到正负样本数据量不等的情况,比如正样本为10w条数据,负样本只有1w条数据,以下最合适的处理方法是()A.将负样本重复10次,生成10w样本量,打乱顺序参与分类B.直接进行分类,可以最大限度利用数据C.从10w正样本中随机抽取1w参与分类D.将负样本每个权重设置为10,正样本权重为1,参与训练过程 解决这类问题主要分： 重采样。A可视作重采样的变形。改变数据分布消除不平衡，可能导致过拟合。 欠采样。C的方案 提高少数类的分类性能，可能丢失多数类的重要信息。 权值调整。 如果1：10算是均匀的话，可以将多数类分割成为1000份。然后将每一份跟少数类的样本组合进行训练得到分类器。而后将这1000个分类器用assemble的方法组合位一个分类器。A选项可以看作此方式，因而相对比较合理。 另：如果目标是 预测的分布 跟训练的分布一致，那就加大对分布不一致的惩罚系数。 D方案也是其中一种方式。 类域界面方程法类域界面方程法中，不能求线性不可分情况下分类问题近似或精确解的方法是？A.伪逆法B.感知器算法C.基于二次准则的H-K算法D.势函数法 伪逆法：径向基（RBF）神经网络的训练算法，径向基解决的就是线性不可分的情况。 感知器算法：线性分类模型。线性不可分时，感知器算法不收敛。 H-K算法：在最小均方误差准则下求得权矢量，二次准则解决非线性问题。 基于二次准则函数的H-K算法较之于感知器算法的优点是:可以判别问题是否线性可分,其解的适应性更好. 势函数法：势函数非线性。 主分量（主成分）分析PCA已知一组数据的协方差矩阵P,下面关于主分量说法错误的是(C)A.主分量分析的最佳准则是对一组数据进行按一组正交基分解, 在只取相同数量分量的条件下,以均方误差计算截尾误差最小B.在经主分量分解后,协方差矩阵成为对角矩阵C.主分量分析就是K-L变换D.主分量是通过求协方差矩阵的特征值得到 K-L变换与PCA变换是不同的概念 PCA的变换矩阵是协方差矩阵 K-L变换的变换矩阵可以有很多种（二阶矩阵、协方差矩阵、总类内离散度矩阵等等） 当K-L变换矩阵为协方差矩阵时，等同于PCA。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（三）：SVM核函数等]]></title>
    <url>%2Farchives%2F8823626c.html</url>
    <content type="text"><![CDATA[SVMSVM核函数包括： 线性核函数、 多项式核函数、 径向基核函数、 高斯核函数、 幂指数核函数、 拉普拉斯核函数、 ANOVA核函数、 二次有理核函数、 多元二次核函数、 逆多元二次核函数 Sigmoid核函数 支持向量机是建立在统计学习理论基础之上的新一代机器学习算法，支持向量机的优势主要体现在解决线性不可分问题，它通过引入核函数，巧妙地解决了在高维空间中的内积运算，从而很好地解决了非线性分类问题。 构造出一个具有良好性能的SVM，核函数的选择是关键．核函数的选择包括两部分工作：一是核函数类型的选择，二是确定核函数类型后相关参数的选择． 因此如何根据具体的数据选择恰当的核函数是SVM应用领域遇到的一个重大难题，也成为科研工作者所关注的焦点，即便如此，却依然没有得到具体的理论或方法来指导核函数的选取． 1、经常使用的核函数核函数的定义并不困难，根据泛函的有关理论，只要一种函数 K ( x i , x j ) 满足Mercer条件，它就对应某一变换空间的内积．对于判断哪些函数是核函数到目前为止也取得了重要的突破，得到Mercer定理和以下常用的核函数类型： (1)线性核函数 K ( x , x i ) = x ⋅ x i (2)多项式核 K ( x , x i ) = ( ( x ⋅ x i ) + 1 ) d (3)径向基核（RBF） K ( x , x i ) = exp ( − ∥ x − x i ∥ 2 σ 2 ) Gauss径向基函数则是局部性强的核函数，其外推能力随着参数 σ 的增大而减弱。多项式形式的核函数具有良好的全局性质。局部性较差。 (4)傅里叶核 K ( x , x i ) = 1 − q 2 2 ( 1 − 2 q cos ( x − x i ) + q 2 ) (5)样条核 K ( x , x i ) = B 2 n + 1 ( x − x i ) (6)Sigmoid核函数 K ( x , x i ) = tanh ( κ ( x , x i ) − δ ) 采用Sigmoid函数作为核函数时，支持向量机实现的就是一种多层感知器神经网络，应用SVM方法，隐含层节点数目(它确定神经网络的结构)、隐含层节点对输入节点的权值都是在设计(训练)的过程中自动确定的。而且支持向量机的理论基础决定了它最终求得的是全局最优值而不是局部最小值，也保证了它对于未知样本的良好泛化能力而不会出现过学习现象。 2、核函数的选择在选取核函数解决实际问题时，通常采用的方法有： 一是利用专家的先验知识预先选定核函数； 二是采用Cross-Validation方法，即在进行核函数选取时，分别试用不同的核函数，归纳误差最小的核函数就是最好的核函数．如针对傅立叶核、RBF核，结合信号处理问题中的函数回归问题，通过仿真实验，对比分析了在相同数据条件下，采用傅立叶核的SVM要比采用RBF核的SVM误差小很多; 三是采用由Smits等人提出的混合核函数方法，该方法较之前两者是目前选取核函数的主流方法，也是关于如何构造核函数的又一开创性的工作．将不同的核函数结合起来后会有更好的特性，这是混合核函数方法的基本思想． HMMQ:如果已知观察序列和产生观察序列的状态序列,那么可用以下哪种方法直接进行参数估计(D)A.EM算法B.维特比算法C.前向后向算法D.极大似然估计 EM算法： 只有观测序列，无状态序列时来学习模型参数，即Baum-Welch算法 维特比算法： 用动态规划解决HMM的预测问题，不是参数估计 维特比算法解决的是给定 一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题 Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现； 前向后向：用来算概率 极大似然估计：即观测序列和相应的状态序列都存在时的监督学习算法，用来估计参数 在给定观测序列和对应的状态序列估计模型参数，可以利用极大似然发估计。 如果给定观测序列，没有对应的状态序列，才用EM，将状态序列看不不可测的隐数据 特征提取算法特征提取算法分为特征选择和特征抽取两大类 特征选择常采用特征选择方法。常见的六种特征选择方法： DF(Document Frequency) 文档频率DF:统计特征词出现的文档数量，用来衡量某个特征词的重要性 MI(Mutual Information) 互信息法互信息法用于衡量特征词与文档类别直接的信息量。如果某个特征词的频率很低，那么互信息得分就会很大，因此互信息法倾向”低频”的特征词。相对的词频很高的词，得分就会变低，如果这词携带了很高的信息量，互信息法就会变得低效。 (Information Gain) 信息增益法通过某个特征词的缺失与存在的两种情况下，语料中前后信息的增加，衡量某个特征词的重要性。 CHI(Chi-square) 卡方检验法利用了统计学中的”假设检验”的基本思想：首先假设特征词与类别直接是不相关的如果利用CHI分布计算出的检验值偏离阈值越大，那么更有信心否定原假设，接受原假设的备则假设：特征词与类别有着很高的关联度。 WLLR(Weighted Log Likelihood Ration)加权对数似然 WFO（Weighted Frequency and Odds）加权频率和可能性 特征抽取（降维） PCA logit 回归和 SVM关于 logit 回归和 SVM 不正确的是（A） A.Logit回归目标函数是最小化后验概率B.Logit回归可以用于预测事件发生概率的大小C.SVM目标是结构风险最小化D.SVM可以有效避免模型过拟合 A. Logit回归本质上是一种根据样本对权值进行极大似然估计的方法，而后验概率正比于先验概率和似然函数的乘积。logit仅仅是最大化似然函数，并没有最大化后验概率，更谈不上最小化后验概率。A错误 B. Logit回归的输出就是样本属于正类别的几率，可以计算出概率，正确 C. SVM的目标是找到使得训练数据尽可能分开且分类间隔最大的超平面，应该属于结构风险最小化，严格来说也是错误的。 D. SVM可以通过正则化系数控制模型的复杂度，避免过拟合。 L0范数与L1范数，L2范数L0范数L0范数是指向量中非0的元素的个数。 如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。这太直观了，太露骨了吧，换句话说，让参数W是稀疏的。OK，看到了“稀疏”二字，大家都应该从当下风风火火的“压缩感知”和“稀疏编码”中醒悟过来，原来用的漫山遍野的“稀疏”就是通过这玩意来实现的。 但你又开始怀疑了，是这样吗？看到的papers世界中，稀疏不是都通过L1范数来实现吗？脑海里是不是到处都是||W||1影子呀！几乎是抬头不见低头见。没错，这就是这节的题目把L0和L1放在一起的原因，因为他们有着某种不寻常的关系。那我们再来看看L1范数是什么？它为什么可以实现稀疏？为什么大家都用L1范数去实现稀疏，而不是L0范数呢？ L1范数L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。 现在我们来分析下这个价值一个亿的问题：为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。 实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。 这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微，但这还是不够直观。这里因为我们需要和L2范数进行对比分析。所以关于L1范数的直观理解，请待会看看第二节。 对了，上面还有一个问题：既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解 一是因为L0范数很难优化求解（NP难问题）二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 一句话总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。 为什么要稀疏？让我们的参数稀疏有什么好处呢？这里扯两点： 特征选择(Feature Selection)： 大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。 一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。 稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。 可解释性(Interpretability)： 另一个青睐于稀疏的理由是，模型更容易解释。 例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。 假设我们这个是个回归模型： y=w1x1+w2x2+…+w1000*x1000+b （当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。 通过学习，如果最后学习到的w*就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。 L2范数除了L1范数，还有一种更受宠幸的规则化范数是L2范数: ||W||2。它也不逊于L1范数，它有两个美称，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”。 这用的很多吧，因为它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。 至于过拟合是什么，上面也解释了，就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。 通俗的讲就是应试能力很强，实际应用能力很差。擅长背诵知识，却不懂得灵活利用知识。 L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。 而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？ 我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。 一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。 L2范数的好处是什么呢？这里也扯上两点：1）学习理论的角度： 从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力。 2）优化计算的角度： 从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。哎，等等，这condition number是啥？我先google一下哈。 这里我们也故作高雅的来聊聊优化问题。优化有两大难题，一是：局部最小值，二是：ill-condition病态问题。 前者俺就不说了，大家都懂吧，我们要找的是全局最小值，如果局部最小值太多，那我们的优化算法就很容易陷入局部最小而不能自拔，这很明显不是观众愿意看到的剧情。 那下面我们来聊聊ill-condition。ill-condition对应的是well-condition。那他们分别代表什么？假设我们有个方程组AX=b，我们需要求解X。如果A或者b稍微的改变，会使得X的解发生很大的改变，那么这个方程组系统就是ill-condition的，反之就是well-condition的。 一句话总结：conditionnumber是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，如果一个矩阵的condition number在1附近，那么它就是well-conditioned的，如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的，它的输出结果就不要太相信了。 从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。 总结吧：L2范数不但可以防止过拟合，还可以让我们的优化求解变得稳定和快速。 L1和L2的差别为什么一个让绝对值最小，一个让平方最小，会有那么大的差别呢？我看到的有两种几何上直观的解析： 下降速度： 我们知道，L1和L2都是规则化的方式，我们将权值参数以L1或者L2的方式放到代价函数里面去。然后模型就会尝试去最小化这些权值参数。而这个最小化就像一个下坡的 过程，L1和L2的差别就在于这个“坡”不同，如下图：L1就是按绝对值函数的“坡”下降的，而L2是按二次函数的“坡”下降。所以实际上在0附近，L1的下降速度比L2的下 降速度要快。所以会非常快得降到0。不过我觉得这里解释的不太中肯，当然了也不知道是不是自己理解的问题。 模型空间的限制： 实际上，对于L1和L2规则化的代价函数来说，也就是说，我们将模型空间限制在w的一个L1-ball 中。为了便于可视化，我们考虑两维的情况，在(w1, w2)平面上可以 画出目标函数的等高线，而约束条件则成为平面上半径为C的一个 norm ball 。等高线与 norm ball 首次相交的地方就是最优解 一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（二）：常识性知识]]></title>
    <url>%2Farchives%2Ffe892b9e.html</url>
    <content type="text"><![CDATA[计算输出特征图大小Q： 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为多少？ 公式：输出尺寸=(输入尺寸-filter尺寸+2*padding）/stride+1 A: 输出为97×97 1层卷积,输出为99×99：（200-5+2）/2+1=99.5 池化,输出为97×97： （99-3+0）/1+1=97 2层卷积,输出为97×97： （97-3+2）/1+1=97 计算尺寸不被整除只在GoogLeNet中遇到过。卷积向下取整，池化向上取整。 研究过网络的话看到stride为1的时候，当kernel为 3 padding为1或者kernel为5 padding为2 一看就是卷积前后尺寸不变。 计算GoogLeNet全过程的尺寸也一样。 SPSS（Statistical Product and Service Solutions） 统计产品与服务解决方案 SPSS为IBM公司推出的一系列用于统计学分析运算、数据挖掘、预测分析和决策支持任务的软件产品及相关服务的总称。 SPSS是世界上最早采用图形菜单驱动界面的统计软件，它最突出的特点就是操作界面极为友好，输出结果美观漂亮。。 SPSS的界面中，主窗口是: 数据编辑窗口。 在spss的基础分析模块中，作用是“以行列表的形式揭示数据之间的关系”的是交叉表。 spss中交叉分析主要用来检验两个变量之间是否存在关系，或者说是否独立，其零假设为两个变量之间没有关系。在实际工作中，经常用交叉表来分析比例是否相等。例如分析不同的性别对不同的报纸的选择有什么不同。 有关过拟合与逻辑回归Q: 在Logistic Regression 中,如果同时加入L1和L2范数,会产生什么效果？ A: 可以做特征选择,并在一定程度上防止过拟合. 做特征选择看可以使用L1，L2范数，具体如下： L1范数具有系数解的特性，但是要注意的是，L1没有选到的特征不代表不重要，原因是两个高相关性的特征可能只保留一个。如果需要确定哪个特征重要，再通过交叉验证。 在代价函数后面加上正则项，Ｌ１即是Ｌｏｓｓｏ回归，Ｌ２是岭回归. 但是它为什么能防止过拟合呢？ 奥卡姆剃刀原理：能很好的拟合数据且模型简单 模型参数在更新时，正则项可使参数的绝对值趋于０，使得部分参数为０，降低了模型的复杂度（模型的复杂度由参数决定），从而防止了过拟合。提高模型的泛化能力. L1范数是指向量中各个元素绝对值之和，用于特征选择 L2范数 是指向量各元素的平方和然后求平方根，用于 防止过拟合，提升模型的泛化能力 矩阵相乘Q: 现在需要计算三个稠密矩阵A,B,C的乘积ABC，假设三个矩阵的尺寸分别为mn,np,p*q,且m&lt;n&lt;p&lt;q，以下计算顺序效率最高的是：A. A(BC) B.(AB)C C.(AC)B D.所有效率都相同A: B ab,bc两矩阵相乘效率为acbABC=(AB)C=A(BC).(AB)C = mnp + mpq,A(BC)=npq + mnq.$$mnp&lt;mnq,mpq&lt; npq$$所以 (AB)C 最小 首先，根据简单的矩阵知识，因为 AB ， A 的列数必须和 B 的行数相等。因此，排除C ;然后，再看 A 、 B 选项。在 A 选项中， mn 的矩阵 A 和 np 的矩阵 B 的乘积，得到 mp 的矩阵 AB ，而 AB 的每个元素需要 n 次乘法和 n-1 次加法，忽略加法，共需要 mnp 次乘法运算。同样情况分析 AB 之后再乘以 C 时的情况，共需要 mpq次乘法运算。因此， A 选项的(AB)C 需要的乘法次数是 mnp+mpq 。同理分析， B 选项的 A (BC)需要的乘法次数是 npq+mn*q 。 k-NN最近邻方法Q: 一般，k-NN最近邻方法在(B)的情况下效果较好A. 样本较多但典型性不好B. 样本较少但典型性好C. 样本呈团状分布D. 样本呈链状分布 A: 样本呈团状颇有迷惑性，这里应该指的是整个样本都是呈团状分布，这样kNN就发挥不出其求近邻的优势了，整体样本应该具有典型性好，样本较少，比较适宜。 常见分类方法（监督学习）：k-NN最近邻方法，支持向量机，决策树 kmeans Kmeans是聚类方法，典型的无监督学习方法 复习一下K-means算法，主要分为赋值阶段和更新阶段。 算法步骤： （1）随机选择K个点作为初始的质心 （2）将每个点指配到最近的质心 （3）重新计算簇的质心，直到质心不再发生变化。 K均值容易陷入局部最小值，无法表示类的形状，大小和宽度，是一种硬分类算法，针对它的这些缺点，提出了二分K均值和软K均值 CRF模型HMM和MEMM模型Q: 下列哪个不属于CRF模型对于HMM和MEMM模型的优势(B)A. 特征灵活B. 速度快C. 可容纳较多上下文信息D. 全局最优 CRF模型:条件随机场（Conditional Random Field，CRF）隐马尔可夫模型（Hidden Markov Model，HMM）最大熵马尔可夫模型（Maximum Entropy Markov Model，MEMM） CRF没有HMM那样严格的独立性假设条件，因而可以容纳任意的上下文信息。特征设计灵活（与ME一样） -与HMM比较 同时，由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔可夫模型标记偏置（Label-bias）的缺点。 ­­——与MEMM比较 CRF是在给定需要标记的观察序列的条件下，计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布。—与ME比较 缺点：训练代价大、复杂度高 CRF 的优点：特征灵活，可以容纳较多的上下文信息，能够做到全局最优CRF 的缺点：速度慢 时间序列模型时间序列模型中,哪一个模型可以较好地拟合波动性的分析和预测（D） A. AR模型B. MA模型C. ARMA模型D. GARCH模型 AR模型：自回归模型，是一种线性模型MA模型：移动平均法模型，其中使用趋势移动平均法建立直线趋势的预测模型ARMA模型：自回归滑动平均模型，拟合较高阶模型GARCH模型：广义回归模型，对误差的方差建模，适用于波动性的分析和预测 AR模型是一种线性预测，即已知N个数据，可由模型推出第N点前面或后面的数据（设推出P点），所以其本质类似于插值。 MA模型(moving average model)滑动平均模型，模型参量法谱分析方法之一。 ARMA模型(auto regressive moving average model)自回归滑动平均模型，模型参量法高分辨率谱分析方法之一。这种方法是研究平稳随机过程有理谱的典型方法。它比AR模型法与MA模型法有较精确的谱估计及较优良的谱分辨率性能，但其参数估算比较繁琐。 GARCH模型称为广义ARCH模型，是ARCH模型的拓展,GARCH对误差的方差进行了进一步的建模，特别适用于波动性的分析和 预测。GARCH模型是一个专门针对金融数据所量体订做的回归模型，除去和普通回归模型相同的之处，GARCH对误差的方差进行了进一步的建模。特别适用于波动性的分析和预测，这样的分析对投资者的决策能起到非常重要的指导性作用，其意义很多时候超过了对数值本身的分析和预测。 Naive Bayesian（NB）Q: 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是: 模型效果相比无重复特征的情况下精确度会降低 当两列特征高度相关时，无法用两列特征相同时所得到的结论来分析问题 A: NB的核心在于它假设向量的所有分量之间是独立的。 在贝叶斯理论系统中，都有一个重要的条件独立性假设：假设所有特征之间相互独立，这样才能将联合概率拆分. 主要原因就是由于存在重复的类别之后，破坏了原本的独立性假设。 Q: 位势函数法的积累势函数K(x)的作用相当于Bayes判决中的: 1.后验概率 2.类概率密度与先验概率的乘积(其实二者含义相同) 在贝叶斯决策中对于先验概率p(y)，分为已知和未知两种情况。 p(y)已知，直接使用贝叶斯公式求后验概率即可； p(y)未知，可以使用聂曼-皮尔逊决策(N-P决策)来计算决策面。 而最大最小损失规则主要就是使用解决最小损失规则时先验概率未知或难以计算的问题的。 高维数据进行降维: LASSO PCA 聚类分析 小波分析 线性判别法 拉普拉斯特征映射]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记（一）：NG的课程]]></title>
    <url>%2Farchives%2Fe6655ec0.html</url>
    <content type="text"><![CDATA[梯度下降 梯度下降的特点：梯度下降的结果一定会结束，也就是会收敛；但是收敛结果依赖于参数初始值。 局部最优值：当接近局部最小值时，步子会越来越小，直到快速收敛到全局最小值。 在局部最小值处，梯度是0；所以在接近局部最小值处，梯度越来越小，梯度下降每步变小。 Batch gradient descent批梯度下降 梯度下降算法的每一次迭代都要遍历整个训练集合。 每次迭代之后要更新参数，这对大规模数据集不利。 引入随机梯度下降或叫增量梯度下降。 注意到，这里激励函数不再用sigmoid{斜率也就是梯度近似都是0，难么梯度下降学习就会很慢}，而是用RULE。 Incremental gradient descent：随机梯度下降(一)好处： 为了开始修改参数，查看并利用第一个训练样本进行更新，这样依次使用第二个样本进行更新，不需要在调整之前便利所有训练数据集合。 对于特定或者普通的最小二乘回归问题，梯度下降可以给出参数向量的解析表达式，这样为了求参数的值就不需要进行迭代了。 (二)坏处： 不会精确的收敛到全局最小值，而是向着全局最小值附近徘徊，可能会一直徘徊。 但是通常情况下，得到的结果很接近全局最小值，特别是在大规模数据训练集时，至少比批梯度下降算法要快很多。 (三) 无人驾驶: 监督学习中的回归问题（梯度下降也是回归问题）。 汽车尝试预测表示行驶方向的连续变量的值。 局部加权回归locally weighted regression线性回归linear regression 逻辑回归logic regression 牛顿法 Underfitting欠拟合：数据中某些非常明显的模式没有被成功的拟合出来 Overfitting过拟合：算法拟合出的结果显示所给的特定数据的特质。而不是隐藏在其下的房屋价格随房屋大小变化的一般规律。 过小的特征集合使得模型过于简单；过大的特征集合使得模型过于复杂 parametric learning algorithm参数学习算法：有固定的参数的数目进行数据拟合的算法 Non-parametric learning algorithm无参数学习算法：参数数目随着训练集合的大小线性增长 局部加权线性回归locally weighted regression：特定的无参数学习算法缺点： 并不能完全避免过拟合和欠拟合的问题。 每次进行预测，要在一次根据整个训练集合拟合出。 若数据集大，代价高，但是可以KDtree来改善效率。 应用：用在了直升机自动驾驶上。 为什选择最小二乘回归作为误差项的估计方法？待更 似然性，中心极限定律待更 logic function=sigmoid function待更 感知器学习算法待更 牛顿学习法Newton’S Method 是一种不同的用来进行模型拟合的算法，例如可以对逻辑回归模型进行拟合。这类方法通常比梯度上升算法快得多。 收敛速度非常快，它的收敛速度用术语可以描述为：二次收敛。也就是，牛顿方法的每一次迭代都会使你正在逼近的解的有效数字的数目加倍。 通常需要迭代十几次就可以收敛，比上述梯度上升等算法要快得多 但是，每次迭代需要重新计算一次Hession矩阵的逆（n*n, n代表特征的数量） 因此，如果要处理的问题中有大量的特征，比如说几千个，那么Hession矩阵的逆的求解要花费很大的代价。 但对于规模较小，特征数量合理的很合适。 伯努利分布和高斯分布，都属于指数分布族 广义线性模型GLM，逻辑回归算法待更]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何提交博客]]></title>
    <url>%2Farchives%2F59ba8169.html</url>
    <content type="text"><![CDATA[如何提交博客第一步编辑markdown文档，在开头最前面加上1234567---title: sql基础语句categories: [sql,基础语句]tags: [sql,多个,选填]description: sql基础语句date: 2017-07-29 15:12:02--- 第1行是你的博客标题；第2行是文章分类，可以写多级分类，例子中的就是一级分类sql”下的二级分类”基础语句”；第4行是附加标签，有几个就填几个；第5行是文章描述；第6行是提交时间，按格式写就行；这里categories、tags、description都可以不写，空的话就不分配相应信息；注意每个冒号后空一个，上下的---不能掉 然后下一行开始写博客内容，完成后存储为xxxx.md格式。 第二步打开你的github仓库，选择xxx.github.io.source的一个进去打开source/_posts然后上传文件，填写commit的信息和描述，然后commit changes，等待上传完成 第三步博客上传好了，等待几分钟，你的博客就会提交成功，等待刷新成功，或者你可以登录AppVeyor，看你的上传进度，在console可以看到脚本的部署过程。]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
  </entry>
</search>
